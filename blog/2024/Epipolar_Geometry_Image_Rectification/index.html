<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Epipolar Geometry and Image Rectification | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="Epipolar Geometry &amp; Image Rectification"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/Epipolar_Geometry_Image_Rectification/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8.0.6/dist/styles.min.css"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-bundle.min.css" integrity="sha256-yUoNxsvX+Vo8Trj3lZ/Y5ZBf8HlBFsB6Xwm7rH75/9E=" crossorigin="anonymous"> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Epipolar Geometry and Image Rectification",
            "description": "Epipolar Geometry & Image Rectification",
            "published": "April 01, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Epipolar Geometry and Image Rectification</h1> <p>Epipolar Geometry &amp; Image Rectification</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#"></a> </div> <div> <a href="#"></a> </div> </nav> </d-contents> <h2 id="epipolar-geometry">Epipolar Geometry</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/1.JPG-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/1.JPG-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/1.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/1.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/2-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/2-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="image-plane--epipolar-plane--baseline--epipole--epipolar-line">image plane / epipolar plane / baseline / epipole / epipolar line</h3> <p>X : 3D point<br> \(x_L, x_R\) : projected 2D point in left and right image<br> 파란색 면 : image plane<br> 초록색 면 : <code class="language-plaintext highlighter-rouge">epipolar plane</code><br> \(O_L, O_R\) : center of left and right camera<br> 직선 \(O_L O_R\) : <code class="language-plaintext highlighter-rouge">baseline</code><br> epipolar pencil : set of epipolar planes<br> <code class="language-plaintext highlighter-rouge">epipole</code> : intersection of baseline and image plane<br> \(e_L, e_R\) : epipole of left and right camera<br> <code class="language-plaintext highlighter-rouge">epipolar line</code> :</p> <ul> <li>intersection of image plane and epipolar plane</li> <li>빨간 선 \(l_R\) : 직선 \(x_R e_R\) (projected 2D point와 epipole은 epipolar line 위에 있다)</li> <li>left image plane 위의 같은 점 \(x_L\)로 project 되는 모든 3D points \(X, X_1, X_2, \cdots\)를 right image plane에 project했을 때 그려지는 선</li> </ul> <h4 id="normalized-coordinates-pixel-coordinates--intrinsic-extrinsic-parameters--homography-matrix--projection-matrix">normalized coordinates, pixel coordinates / intrinsic, extrinsic parameters / homography matrix / projection matrix</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/3.JPG-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/3.JPG-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/3.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/3.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>real-world의 3D 좌표 (X, Y, Z) 에 있는 물체를 카메라에 투영하기 위해 Z (= 깊이) 값을 1로 정규화한 평면을 <code class="language-plaintext highlighter-rouge">normalized plane</code>이라 하고, \((\frac{X}{Z}, \frac{Y}{Z}, 1)\)의 좌표값을 갖는다. 이를 image로서 나타내기 위해 초점거리를 곱해주고 원점을 정중앙에서 좌상단으로 바꿔서 normalized plane 상의 normalized coordinates \((\frac{X}{Z}, \frac{Y}{Z}, 1)\)을 <code class="language-plaintext highlighter-rouge">image plane 상의 pixel coordinates</code> \((\frac{X}{Z} \ast f_x - \frac{W}{2}, \frac{Y}{Z} \ast f_y - \frac{H}{2}, 1)\) 로 변환할 수 있는데, 이 때 곱하게 되는 행렬이 바로 intrinsic matrix (= calibration matrix) K 이다. 그리고 이렇게 intrinsic parameters를 구하는 과정을 Camera Calibration 이라 부른다.</p> <p>그런데, 카메라의 각도 혹은 위치가 달라지면 맺히는 이미지 자체도 달라지기 때문에 intrinsic matrix를 곱하기 전에 camera의 rotation 및 translation을 먼저 고려해주어야 하는데, 이 때 곱하게 되는 행렬이 바로 extrinsic marix \([R \vert t]\) 이다.</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">K : intrinsic parameters</code> (3x3 calibration matrix) (초점거리 곱하고 원점 바꾸는 등 카메라 자체의 특성)</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">R, t : extrinsic parameters</code> (3x3 rotation, 3x1 translation matrix) (두 카메라의 상대적인 위치, 각도)</p> </li> </ul> <p>즉, 정리하면 3D point [X, Y, Z]가 image plane [x, y]에 맺히는 projection 과정은 아래의 수식을 따른다.</p> <p>\(\begin{bmatrix} x \\ y \\ z \end{bmatrix}\) = \(\begin{bmatrix} f_x &amp; 0 &amp; -W/2 \\ 0 &amp; f_y &amp; -H/2 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\) \([R \vert t]\) \(\begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}\)</p> <p>\(x_L \Leftrightarrow x_R\) : homography matrix H (projection of 2D point to 2D point)<br> \(x_R = H x_L\)<br> \(X \Leftrightarrow x_L\) : projection matrix \(P_L\)<br> \(x_L = P_LX\) where \(P_L = K_L[R \vert t]\)</p> <h3 id="fundamental-matrix">Fundamental matrix</h3> <ol> <li> \[x_R = H x_L\] </li> <li>\(e_R\)과 \(x_R\)은 직선 \(l_R\) 위에 있으므로 \(e_{R}^{T} l_R = 0\) and \(x_{R}^{T} l_R = 0\)<br> 예를 들어, 직선 2x+y-2z = 0에 대해 \(l_R\)은 (2, 1, -2)이고, \(e_R\) 및 \(x_R\)은 직선 위에 있는 점 (x, y, z)이다.</li> <li>위의 1.과 2.로부터 \(l_R = e_R \circledast x_R = e_R \circledast H x_L = F x_L\)<br> where F = fundamental matrix = \(e_R \circledast H\)</li> <li>위의 2.와 3.으로부터 \(x_{R}^{T} l_R = x_{R}^{T} F x_L = 0\)</li> <li>위의 2.와 3.으로부터 \(e_{R}^{T} l_R = e_{R}^{T} F x_L = 0\) 이고, 모든 \(x_L\)에 대해 \(e_{R}^{T} F = 0\)을 만족하므로 \(e_R\)은 F의 left null vector이다. (유사한 방법으로 \(e_L\)은 F의 right null vector이다.)</li> </ol> <p>즉, fundamental matrix와 관련된 식을 정리하면</p> <ul> <li> <code class="language-plaintext highlighter-rouge">fundamental matrix</code> : \(F = e_R \circledast H\)</li> <li> <code class="language-plaintext highlighter-rouge">correspondence condition</code> : \(x_{R}^{T} F x_L = 0\)</li> <li> <code class="language-plaintext highlighter-rouge">epipolar line</code> : \(l_R = F x_L\)</li> <li> <code class="language-plaintext highlighter-rouge">epipole</code> : \(e_{R}^{T} F = 0\) (\(e_R\)은 F의 left null vector)</li> </ul> <h3 id="essential-matrix">Essential matrix</h3> <p>essential matrix는 fundamental matrix의 specialization으로, pixel coordinates이 특별히 <code class="language-plaintext highlighter-rouge">calibrated camera들을 다루는 normalized image coordinates (K = I)인 경우</code>에 사용된다. 즉, K = I 여서 \(x^{\ast} = PX = K[R \vert t]X = [R \vert t]X\) 를 만족하는 \(x^{\ast}\)을 normalized coordinates에 있는 image point라 부른다.</p> <p>그리고 epipolar constraint란, vector \(x_L O_L\)과 vector \(x_R O_R\)과 vector \(O_L O_R\)이 같은 평면 epipolar plane 위에 있다는 것이다. 이를 normalized coordinates에서 생각하면, \(x_R^{\ast}\)과 \(Rx_L^{\ast}\)과 t가 <code class="language-plaintext highlighter-rouge">같은 평면 epipolar plane 위에 있다</code>는 뜻이므로 (그 이유는 아래의 Algebraic derivation을 참고하자) 이를 간단하게 수식으로 표현하면 \(x_R^{\ast T}(t \circledast Rx_L^{\ast}) = 0\) 이다.</p> <p>즉, essential matrix와 관련된 식을 정리하면</p> <ul> <li> <code class="language-plaintext highlighter-rouge">essential matrix</code> : \(E = t \circledast R\)</li> <li> <code class="language-plaintext highlighter-rouge">correspondence condition</code> : \(x_R^{\ast T} E x_L^{\ast} = 0\)</li> </ul> <h3 id="relationship-between-fundamental-matrix-and-essential-matrix">​Relationship between fundamental matrix and essential matrix</h3> <p>이제 intrinsic parameters인 calibration matrix <code class="language-plaintext highlighter-rouge">K를 이용하여 uncalibrated camera들을 다루는 general case로 확장</code>해보자. \(x_L^{\ast}\) 이 normalized coordinates에서의 image point였고, \(x_L\)은 일반적인 pixel coordinates에서의 image point라고 할 때,</p> <ol> <li>\(x_L = K_L x_L^{\ast}\) 이고, \(x_R = K_R x_R^{\ast}\) 이므로 \(x_L^{\ast} = K_L^{-1}x_L\) 이고, \(x_R^{\ast} = K_R^{-1}x_R\)</li> <li> \[x_R^{\ast T} E x_L^{\ast} = 0\] </li> <li>위의 1.과 2.로부터 \(x_R^{T} (K_R^{-T} E K_L{-1}) x_L = 0\)</li> </ol> <p>이 때, 위의 3.은 \(x_{R}^{T} F x_L = 0\) 꼴과 같으므로</p> <p>즉, fundamental matrix와 essential matrix 간의 관계식을 정리하면</p> <ul> <li> <code class="language-plaintext highlighter-rouge">fundamental matrix</code> : \(F = e_R \circledast H\)</li> <li> <code class="language-plaintext highlighter-rouge">essential matrix</code> : \(E = t \circledast R\)</li> <li> <code class="language-plaintext highlighter-rouge">relationshiop</code> : \(F = K_R^{-T} E K_L^{-1} = K_R^{-T} t \circledast R K_L^{-1}\)<br> (F는 \(K_L, K_R, R, t\) 만으로 표현 가능)</li> </ul> <p>​즉, fundamental matrix F는 각 camera의 calibration matrix \(K_L, K_R\)과 두 camera 사이의 상대적인 rotation R 및 translation t에 의존한다는 것을 알 수 있다.</p> <h3 id="algebraic-derivation">Algebraic derivation</h3> <p>\(F = K_R^{-T} E K_L^{-1} = K_R^{-T} t \circledast R K_L^{-1}\) 임을 조금 더 수학적으로 유도해보자.</p> <p>상대적인 카메라의 위치인 extrinsic parameters의 경우 <code class="language-plaintext highlighter-rouge">left camera에 world origin이 있다고 가정하여 이에 대해 상대적인 right camera의 위치를 R, t로 지정</code>하자.</p> <p>\(ax_L = K_L[I \vert 0]X\)<br> \(bx_R = K_R[R \vert t]X\)<br> (여기서 a, b는 단순히 scale factor)</p> <p>\(X = [x, y, z, 1]^T = [X^{\ast}, 1]^T\) 에 대해<br> \(ax_L = K_{L}X^{\ast}\)<br> \(bx_R = K_{R}(RX^{\ast}+t)\)</p> <p>\(X^{\ast} = aK_{L}^{-1}x_L\)을 \(bK_{R}^{-1}x_R = RX^{\ast}+t\)에 대입하면,</p> <ol> <li>\(bK_{R}^{-1}x_R = aRK_{L}^{-1}x_L + t\)<br> 이 때, vector \(bK_{R}^{-1}x_R\)은 vector \(aRK_{L}^{-1}x_L\)와 vector t의 합이므로 기하학적으로 \(bK_{R}^{-1}x_R\)과 \(aRK_{L}^{-1}x_L\)과 t는 <code class="language-plaintext highlighter-rouge">같은 평면 위에 있다. (그리고 그 평면은 epipolar plane이다.)</code><br> 따라서 vector \(v = t \circledast RK_{L}^{-1}x_L\) 는 epipolar plane에 수직이므로 \(b(K_{R}^{-1}x_R)^{T}v = a(RK_{L}^{-1}x_L)^{T}v + t^{T}v = 0\) 이라 쓸 수 있다.<br> \(b(K_R^{-1}x_R)^{T}v = 0\)을 정리하면 \(x_R^{T} (K_R^{-T} (t \circledast R) K_L^{-1}) x_L = 0\) 이다.</li> <li>\(bx_R = aK_{R}RK_L^{-1}x_L + K_{R}t\)<br> 이와 비슷하게 vector \(w = K_{R}t \circledast K_{R}RK_{L}^{-1}x_L\)는 \(bx_R = aK_{R}RK_{L}^{-1}x_L + K_{R}t\) 에 수직이므로 \(bx_{R}^{T}w = a(K_{R}RK_{L}^{-1}x_L)^{T}w + (K_{R}t)^{T}w = 0\) 이라 쓸 수 있다.<br> \(bx_{R}^{T}w = 0\)을 정리하면 \(x_{R}^{T} (K_{R} t \circledast K_{R}RK_{L}^{-1}) x_L = 0\) 이다.</li> <li>위의 1., 2.에서 유도한 \(x_R^{T} (K_R^{-T} (t \circledast R) K_L^{-1}) x_L = 0\)과 \(x_{R}^{T} (K_{R} t \circledast K_{R}RK_{L}^{-1}) x_L = 0\)을 통해<br> \(F = K_{R}^{-T} t \circledast R K_{L}^{-1}\) 임을 유도할 수 있다.<br> (F 유도에 \(x_R^{T} (K_R^{-T} (t \circledast R) K_L^{-1}) x_L = 0\) 은 왜 필요한 거지..? <code class="language-plaintext highlighter-rouge">조금 더 공부 필요</code>)</li> </ol> <h2 id="image-rectification">Image Rectification</h2> <p><code class="language-plaintext highlighter-rouge">Image rectification은 주어진 images를 common image plane에 project하는 것</code>이다. 여러 각도에서 찍은 <code class="language-plaintext highlighter-rouge">이미지들 간에 매칭되는 점들을 쉽게 찾기 위해</code> computer stereo vision 분야에서 널리 사용되는 transform 기법이다. 이 때, 매칭되는 점들을 찾는 것은 위에서 설명한 epipolar geometry에 의해 수행된다.<br> (<code class="language-plaintext highlighter-rouge">epipolar geometry 요약 : 한 image의 어떤 pixel에 매칭되는 3D 상의 점들은 다른 image의 epipolar line 위에 있다</code>.)</p> <blockquote> <p>parallel stereo cameras : e.g. 두 카메라 사이의 관계가 t = [T; 0; 0] (shifted in x-direction)<br> 만약 두 image plane이 같은 평면 상에 있다면 optical axes가 parallel하여 <code class="language-plaintext highlighter-rouge">모든 epipolar line은 horizontal axis에 평행하고 epipoles는 infinite point in [1, 0, 0]T direction in homogeneous coordinates로 mapping되며, 매칭되는 점들이 같은 vertical coordinates를 가진다.</code> 그리고 이 때 매칭되는 점들을 찾는 것은 matching cost(minimize SSD or maximize normalized correlation)를 찾기 위해 horizontal scan만 하면 되므로 쉬운 문제이다.<br> 예를 들어, left image의 어떤 pixel (\(x_l, y_l\))에 대응되는 점을 right image에서 찾는다고 가정하자. 이 때, right image에서의 horizontal scan이 \(x_l\) 의 위치(아래 오른쪽 사진의 빨간 점)을 넘어가서는 안 된다. right image에서 \(x_l\) 의 오른쪽에 matching point가 있다면 연장선을 그었을 때 3D point가 camera center의 뒤쪽에 있다는 것을 의미하기 때문이다.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/4-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/4-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>그런데 horizontal scan을 하며 모든 pixel에 대해 matching cost를 일일이 찾는 건 inefficient하므로 positive matches &amp; negative matches 만들어서 classifier training 할 수 있다.<br> (smaller patch size : more detail, but noisy)<br> (bigger patch size : less detail, but smooth)<br> 이를 통해 disparity map을 얻을 수 있고, depth map을 얻을 수 있다.</p> <p>For <code class="language-plaintext highlighter-rouge">post-processing, MRF(Markov Random Field) or CRF(Conditional Random Field)</code> : energy minimization</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/5-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/5-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/6-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/6-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <blockquote> <p>general stereo cameras : 두 카메라 사이의 관계가 [R|t]<br> 하지만, 두 카메라는 보통 서로 rotate, translate 되어 있기 때문에 <code class="language-plaintext highlighter-rouge">두 image를 warp해서라도 두 image plane이 같은 평면 상에 있던 것처럼 (모든 epipolar line이 수평선이 되도록) 만들 필요가 있고, 이것이 바로 image rectification</code>이다.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/7-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/7-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Image rectification은 두 images에 대해 동시에 수행되며, 일반적으로 셋 이상의 images에 대해서는 simultaneous rectification이 불가능하다.</p> <p>calibrated cameras에 대해서는 essential matrix가 두 camera 사이의 관계를 설명(\(x_{R}^{\ast T} E x_{L}^{\ast} = 0\))하고, uncalibrated cameras (general case)에 대해서는 fundamental matrix가 두 camera 사이의 관계를 설명(\(x_{R}^{T} F x_L = 0\))한다.</p> <p>Image rectification 알고리즘은 대표적으로 세 가지가 있다. : <code class="language-plaintext highlighter-rouge">planar, cylindrical, and polar rectification</code><br> Image rectification을 수행하기 위해서는 projective transformation을 위해 homography matrix \(H_L, H_R\)를 찾아야 하는데, 여러 방법 중 하나를 아래에서 소개하겠다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/8.JPG-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/8.JPG-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/8.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/8.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>우선 left camera에 world origin이 있다고 가정하여 이에 대해 상대적인 right camera의 위치를 R, t로 지정하자. 그러면 \(O_{L} = 0, O_{R} = -R^{t} t\) 라 쓸 수 있고, \(P_{L} = K_{L}[I \vert 0], P_{R} = K_{R}[R \vert t]\) 라 쓸 수 있다.<br> <code class="language-plaintext highlighter-rouge">(왜 OR = -R^t t 이지?)</code></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/9.JPG-480.webp 480w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/9.JPG-800.webp 800w,/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/9.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-04-01-Epipolar_Geometry_Image_Rectification/9.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>첫 번째로, <code class="language-plaintext highlighter-rouge">epipole의 위치를 구한다.</code><br> \(O_R\)을 left image plane에 project한 게 \(e_L\) 이고, \(O_L\)을 right image plane에 project한 게 \(e_R\) 이므로<br> \(e_{L} = P_{L} [O_{R} ; 1] = P_{L} [-R^{t} t ; 1] = K_{L}[I \vert 0][-R^{t} t ; 1] = - K_{L} R^{t} t\)<br> \(e_{R} = P_{R} [O_{L} ; 1] = P_{R} [0 ; 1] = K_{R}[R \vert t][0 ; 1] = K_{R} t\)</li> <li>두 번째로, <code class="language-plaintext highlighter-rouge">left image plane이 baseline에 평행해지도록 rotate시키는 projective transformation HL1 을 구한다. 이는 original optical axis와 desired optical axis 간의 외적</code>으로 구할 수 있다.</li> <li>세 번째로, <code class="language-plaintext highlighter-rouge">horizontal axis가 baseline 및 epipolar line과 평행해지도록 twist시키는 projective transformation</code> \(H_{L2}\) 를 구한다. 맞게 구했다면 twist 후 epipoles가 infinity in x-direction로 mapping되어야 한다.</li> <li>네 번째로, left image를 rectify하는 <code class="language-plaintext highlighter-rouge">최종 projective transformation</code> \(H_{L} = H_{L2}H_{L1}\) 을 구한다.</li> <li>다섯 번째로, 같은 방법으로 right image를 rectify하는 <code class="language-plaintext highlighter-rouge">최종 projective transformation</code> \(H_{R} = H_{R2}H_{R1}\)을 구한다. 여기서 주의할 점은, left image와 right image를 각각 \(H_{L1}\)과 \(H_{R1}\)으로 <code class="language-plaintext highlighter-rouge">rotate한 후에 optical axis가 서로 평행해야 한다</code>.<br> One strategy is to pick a plane parallel to the line where the two original optical axes intersect to minimize distortion from the reprojection process. 또는 We simply define as \(H_{R} = H_{L} R^{t}\)<br> (<code class="language-plaintext highlighter-rouge">위의 두 가지 strategy 이해 못 했음. 추가 공부 필요</code>)</li> <li>마지막으로, two images가 same resolution을 갖도록 <code class="language-plaintext highlighter-rouge">scale</code>해준다. 그러면 horizontal epipoles가 align되어 매칭되는 점들이 같은 <code class="language-plaintext highlighter-rouge">vertical coordinates를 가지므로 매칭되는 점들을 찾기 위해 horizontal scan만 하면 되는 쉬운 문제로 바뀐다</code>.<br> 추가로, 꼭 \(K_{L}, K_{R}\) <code class="language-plaintext highlighter-rouge">intrinsic parameter를 모르더라도 a set of seven or more image-to-image correspondences만 알면 fundamental matrix와 epipoles를 계산할 수 있어서 image rectification을 수행할 수 있다고 한다.</code><br> (<code class="language-plaintext highlighter-rouge">a set of seven or more correspondences로 fundamental matrix, epipole 구해서 rectification 하는 거 이해 못 했음. 추가 공부 필요</code>)<br> (fundamental matrix와 epipole 알면 image rectification 수행 가능)</li> </ul> <blockquote> <p>참고 사이트 :<br> <a href="https://blog.naver.com/hms4913/220043661788" rel="external nofollow noopener" target="_blank">https://blog.naver.com/hms4913/220043661788</a><br> <a href="https://en.wikipedia.org/wiki/Image_rectification#cite_note-HARTLEY2003-9" rel="external nofollow noopener" target="_blank">https://en.wikipedia.org/wiki/Image_rectification#cite_note-HARTLEY2003-9</a><br> <a href="https://csm-kr.tistory.com/64" rel="external nofollow noopener" target="_blank">https://csm-kr.tistory.com/64</a><br> CSC420: Intro to Image Understanding 수업 내용</p> </blockquote> <p>중간중간에 있는 질문들은 아직 이해하지 못해서 남겨놓은 코멘트입니다.<br> 추후에 다시 읽어보고 이해했다면 업데이트할 예정입니다.<br> 혹시 알고 계신 분이 있으면 댓글로 남겨주시면 감사하겠습니다!</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"semyeong-yu/semyeong-yu.github.io","data-repo-id":"R_kgDOLmVJXQ","data-category":"Comments","data-category-id":"DIC_kwDOLmVJXc4CeSwc","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>