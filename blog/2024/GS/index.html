<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 3D Gaussian Splatting | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="3D GS for Real-Time Radiance Field Rendering"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/GS/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "3D Gaussian Splatting",
            "description": "3D GS for Real-Time Radiance Field Rendering",
            "published": "July 11, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>3D Gaussian Splatting</h1> <p>3D GS for Real-Time Radiance Field Rendering</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#related-work">Related Work</a> </div> <div> <a href="#overview">Overview</a> </div> <div> <a href="#differentiable-3d-gaussian-splatting">Differentiable 3D Gaussian Splatting</a> </div> <div> <a href="#parameters-to-train">Parameters to train</a> </div> <div> <a href="#fast-differentiable-rasterizer-for-gaussians">Fast Differentiable Rasterizer for Gaussians</a> </div> <div> <a href="#optimization-with-adaptive-density-control-of-3d-gaussians">Optimization with Adaptive Density Control of 3D Gaussians</a> </div> <div> <a href="#results">Results</a> </div> <div> <a href="#discussion">Discussion</a> </div> </nav> </d-contents> <h2 id="3d-gaussian-splatting-for-real-time-radiance-field-rendering">3D Gaussian Splatting for Real-Time Radiance Field Rendering</h2> <h4 id="bernhard-kerbl-georgios-kopanas-thomas-leimkühler-george-drettakis">Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, George Drettakis</h4> <blockquote> <p>paper :<br> <a href="https://arxiv.org/abs/2308.04079" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2308.04079</a><br> project website :<br> <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" rel="external nofollow noopener" target="_blank">https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/</a><br> code :<br> <a href="https://github.com/graphdeco-inria/gaussian-splatting" rel="external nofollow noopener" target="_blank">https://github.com/graphdeco-inria/gaussian-splatting</a><br> referenced blog :<br> <a href="https://xoft.tistory.com/51" rel="external nofollow noopener" target="_blank">https://xoft.tistory.com/51</a></p> </blockquote> <blockquote> <p>핵심 요약 :</p> <ol> <li>TBD</li> </ol> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/2-480.webp 480w,/assets/img/2024-07-11-GS/2-800.webp 800w,/assets/img/2024-07-11-GS/2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="abstract">Abstract</h2> <ul> <li>novel 3D Gaussian scene representation with real-time differentiable renderer<br> <code class="language-plaintext highlighter-rouge">수많은 3D Gaussian이 모여 scene을 구성</code>하고 있다!</li> <li>Very Fast rendering (\(\geq\) 100 FPS) :<br> real-time as \(\geq\) 30 FPS<br> rasterization이 optimization의 main bottleneck인데, 3DGS는 fast rasterization 가짐</li> <li>Higher Quality than SOTA Mip-NeRF360(2022)</li> <li>Faster Training than SOTA InstantNGP(2022)</li> </ul> <h2 id="introduction">Introduction</h2> <h3 id="why-3d-gaussian">Why 3D Gaussian?</h3> <p>3D scene representation 방법</p> <ol> <li> <code class="language-plaintext highlighter-rouge">Mesh or Point</code> <ul> <li>explicit</li> <li>good for fast GPU/CUDA-based rasterization(3D \(\rightarrow\) 2D)</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">NeRF</code> method <ul> <li>implicit (MLP로 geometry 및 appearance를 표현)</li> <li>ray marching</li> <li>continuous coordinate-based representation</li> <li>interpolate values stored in voxels, hash grids, or points</li> <li>But,,, continuous ray로부터 discrete points를 뽑아 내는 <code class="language-plaintext highlighter-rouge">stochastic sampling</code> for rendering 때문에 <code class="language-plaintext highlighter-rouge">연산량이 많고 noise</code> 생김</li> <li>MLP는 dot product 및 더하기(kernel regression)의 특성상 <code class="language-plaintext highlighter-rouge">orthogonality</code>를 흐리기 때문에 high-freq. output을 잘 표현할 수 없어서 따로 미리 positional encoding을 수행</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">3D Gaussian</code> method <ul> <li>explicit (3D Gaussian으로 geometry를, SH coeff.로 appearance를 표현)</li> <li>differentiable volumetric representation</li> <li>efficient rasterization(projection and \(\alpha\)-blending)</li> <li>3D Gaussian(ellipsoid)이나 SH coeff.라는 explicit 표현 자체가 <code class="language-plaintext highlighter-rouge">orthogonality</code>를 잘 살리기 때문에 high-freq. output 잘 표현 가능</li> </ul> </li> </ol> <h3 id="rendering-nerf-vs-3dgs">Rendering (NeRF vs 3DGS)</h3> <ul> <li>NeRF : <ul> <li>ray per pixel 쏴서 coarse(stratified) and fine(PDF) sampling하고,</li> <li>MLP로 sampled points의 color 및 volume density를 구하고,</li> <li>이 값들을 volume rendering 식으로 summation</li> </ul> </li> <li>3DGS : <ul> <li>image를 tile(14 \(\times\) 14 pixel)들로 나누고,</li> <li>tile마다 Gaussian을 Depth에 따라 정렬한 뒤</li> <li>앞에서부터 뒤로 \(\alpha\)-blending</li> </ul> </li> </ul> <h2 id="related-work">Related Work</h2> <p>생략 (추후에 다시 볼 수도)</p> <h2 id="overview">Overview</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/1-480.webp 480w,/assets/img/2024-07-11-GS/1-800.webp 800w,/assets/img/2024-07-11-GS/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>For unbounded and complete scenes,<br> For 1080p high resolution and real-time(\(\geq\) 30 fps) rendering,</p> <ol> <li> <code class="language-plaintext highlighter-rouge">input</code> : <ul> <li>Most point-based methods require <code class="language-plaintext highlighter-rouge">MVS</code>(Multi-View Stereo) data,<br> but 3DGS only needs <code class="language-plaintext highlighter-rouge">SfM points</code> for initialization</li> <li>COLMAP 등 SfM(Structure-from-Motion) camera calibration으로 얻은 <code class="language-plaintext highlighter-rouge">sparse point cloud</code>에서 시작해서<br> scene을 3D Gaussians로 나타냄으로써<br> <code class="language-plaintext highlighter-rouge">empty space에서의 불필요한 계산을 하지 않도록</code> continuous volumetric radiance fields 정보를 저장</li> <li>NeRF-synthetic dataset의 경우 bg가 없어서 3DGS random initialization으로도 좋은 퀄리티 달성</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">optimization</code> interleaved with <code class="language-plaintext highlighter-rouge">adaptive density control</code> : <ul> <li>optimize 4 parameters :<br> 3D position(mean), anisotropic covariance, opacity, and spherical harmonic coeff.(color)<br> <code class="language-plaintext highlighter-rouge">highly anisotropic volumetric splats</code>는 <code class="language-plaintext highlighter-rouge">fine structures</code>를 compact하게 나타낼 수 있음!!<br> <code class="language-plaintext highlighter-rouge">spherical harmonics</code>를 통해 <code class="language-plaintext highlighter-rouge">directional appearance(color)</code>를 잘 나타낼 수 있음!!<d-cite key="Plenoxels">[1]</d-cite>, <d-cite key="InstantNGP">[2]</d-cite> </li> <li>adaptive density control :<br> gradient 기반으로 Gaussian 형태를 변화시키기 위해, add and occasionally remove 3D Gaussians during optimization</li> </ul> </li> <li>differentiable visibility-aware <code class="language-plaintext highlighter-rouge">real-time rendering</code> :<br> perform \(\alpha\)-blending of <code class="language-plaintext highlighter-rouge">anisotropic splats</code> respecting visibility order<br> by fast <code class="language-plaintext highlighter-rouge">GPU sorting</code> algorithm and <code class="language-plaintext highlighter-rouge">tile-based rasterization</code>(projection and \(\alpha\)-blending)<br> 한편, accumulated \(\alpha\) values를 tracking함으로써 <code class="language-plaintext highlighter-rouge">Gaussians 수에 제약 없이</code> 빠른 backward pass도 가능</li> </ol> <hr> <h3 id="pseudo-code">Pseudo-Code</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/3-480.webp 480w,/assets/img/2024-07-11-GS/3-800.webp 800w,/assets/img/2024-07-11-GS/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>빨간 박스 : initialization<br> 파란 박스 : optimization<br> 초록 박스 : 특정 iter.마다 Gaussian을 clone, split, remove</p> <h2 id="differentiable-3d-gaussian-splatting">Differentiable 3D Gaussian Splatting</h2> <h3 id="3d-gaussian">3D Gaussian</h3> <ul> <li> <p><code class="language-plaintext highlighter-rouge">differentiable</code> volumetric representation의 특성을 가지고 있으면서도 빠른 rendering을 위해 <code class="language-plaintext highlighter-rouge">unstructured and explicit</code>한 게 무엇이 있을까?<br> \(\rightarrow\) 3D Gaussian !!</p> </li> <li> <p>a point를 a small planar circle with a normal이라고 가정하는 이전 Point-based rendering 논문들 <d-cite key="Point1">[3]</d-cite> <d-cite key="Point2">[4]</d-cite> 과 달리<br> <code class="language-plaintext highlighter-rouge">SfM points는 sparse해서 normals(법선)를 estimate하기 어려울</code> 뿐만 아니라, estimate 한다 해도 very noisy normals를 optimize하는 것은 매우 어렵<br> \(\rightarrow\) normals 필요 없는 3D Gaussians !!<br> k-dim. Gaussian : \(G(\boldsymbol x) = (2\pi)^{-\frac{k}{2}}det(\Sigma)^{-\frac{1}{2}}e^{-\frac{1}{2}(\boldsymbol x - \boldsymbol \mu)^T\Sigma^{-1}(\boldsymbol x - \boldsymbol \mu)}\)</p> </li> </ul> <h2 id="parameters-to-train">Parameters to train</h2> <ol> <li> <code class="language-plaintext highlighter-rouge">scale vector</code> \(s\) and <code class="language-plaintext highlighter-rouge">quaternion</code> \(q\) for <code class="language-plaintext highlighter-rouge">covariance matrix</code> </li> <li> <code class="language-plaintext highlighter-rouge">spherical harmonics</code>(SH) coeff. for <code class="language-plaintext highlighter-rouge">color</code> </li> <li> <code class="language-plaintext highlighter-rouge">opacity</code> \(\alpha\)</li> <li> <code class="language-plaintext highlighter-rouge">3D position</code> for <code class="language-plaintext highlighter-rouge">mean</code> </li> </ol> <h3 id="parameter-1-covariance-matrix">Parameter 1. Covariance matrix</h3> <blockquote> <p>scale vector(scale) and quaternion(rotation) for covariance matrix</p> </blockquote> <ul> <li>covariance matrix는 positive semi-definite \(x^T M x \geq 0\) for all \(x \in R^n\)이어야만 physical meaning을 가지는데,<br> \(\Sigma\) 를 직접 바로 optimize하면 invalid covariance matrix가 될 수 있음<br> 그렇다면!!</li> </ul> <p>\(\Sigma\) 가 <code class="language-plaintext highlighter-rouge">symmetric</code> and <code class="language-plaintext highlighter-rouge">positive semi-definite</code>이도록 \(\Sigma = R S S^T R^T\) 로 정의해서<br> \(\Sigma\) 대신 <code class="language-plaintext highlighter-rouge">x,y,z-axis scale</code>을 나타내는 <code class="language-plaintext highlighter-rouge">3D vector</code> \(s\) 와 <code class="language-plaintext highlighter-rouge">rotation</code>을 나타내는 <code class="language-plaintext highlighter-rouge">4D quaternion</code> \(q\) 를 optimize 하자!!<br> quaternion에 대한 설명은 <a href="https://semyeong-yu.github.io/blog/2024/Quaternion">Quaternion</a> 블로그 참고!!</p> <ul> <li> <code class="language-plaintext highlighter-rouge">scale</code> 3D vector \(s\) <code class="language-plaintext highlighter-rouge">초기값</code> :<br> <a href="https://github.com/graphdeco-inria/gaussian-splatting/blob/b2ada78a779ba0455dfdc2b718bdf1726b05a1b6/scene/gaussian_model.py#L134C1-L134C1" rel="external nofollow noopener" target="_blank">GaussianModel().create_from_pcd()</a><br> SfM sparse point cloud의 각 점에 대해 가장 가까운 점 3개까지의 거리의 평균을 각 axis(\(x, y, z\))별로 구한 것을 3 \(\times\) 1 \(s\)라 할 때<br> normalize 효과를 위해 log, sqrt 씌운 뒤<br> 3 \(\times\) 1 \(log(\sqrt{s})\) 의 값을 3번 복사하여 3 \(\times\) 3 scale matrix \(S\)를 초기화 <pre><code class="language-Python">dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)
scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3)
</code></pre> </li> <li> <p><code class="language-plaintext highlighter-rouge">scale</code> 3D vector \(s\) <code class="language-plaintext highlighter-rouge">activation function</code> :<br> smooth gradient 얻기 위해 exponential activation function을 씌움</p> </li> <li> <code class="language-plaintext highlighter-rouge">quaternion</code> \(q\) <code class="language-plaintext highlighter-rouge">초기값</code> :<br> 각 점에 대해 \(\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix}\) 으로 quaternion을 초기화하고<br> 이를 이용하여 rotation matrix \(R\) 초기화 <pre><code class="language-Python">rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")
rots[:, 0] = 1
</code></pre> </li> <li> <code class="language-plaintext highlighter-rouge">anisotropic covariance</code>는 다양한 모양의 geometry를 나타내기 위해 optimize하기에 적합!</li> </ul> <blockquote> <p>param. gradient 직접 유도 (Appendix A.)</p> </blockquote> <p>training할 때 automatic differentiation으로 인한 <code class="language-plaintext highlighter-rouge">overhead를 방지</code>하기 위해 <code class="language-plaintext highlighter-rouge">param. gradient를 직접 유도</code>함!</p> <ol> <li> <p>By chain rule, \(\frac{d\Sigma^{\ast}}{ds} = \frac{d\Sigma^{\ast}}{d\Sigma}\frac{d\Sigma}{ds}\) and \(\frac{d\Sigma^{\ast}}{dq} = \frac{d\Sigma^{\ast}}{d\Sigma}\frac{d\Sigma}{dq}\)</p> </li> <li> <p>By covariance dimension reduction, \(\Sigma^{\ast}\) 는 \(U \Sigma U^T\) 의 좌상단 2-by-2 matrix<br> where \(U = JW\)<br> So, 편미분 값은 \(\frac{d\Sigma^{\ast}}{d\Sigma_{ij}} = \begin{bmatrix} U_{1, i} U_{1, j} &amp; U_{1, i} U_{2, j} \\ U_{1, j} U_{2, i} &amp; U_{2, i} U_{2, j} \end{bmatrix}\)</p> </li> <li> <p>For symmetric and positive semi-definite property of covariance matrix, we set \(\Sigma = MM^T\)<br> where \(M = RS\)<br> So, \(\frac{d\Sigma}{ds} = \frac{d\Sigma}{dM} \frac{dM}{ds}\) and \(\frac{d\Sigma}{dq} = \frac{d\Sigma}{dM} \frac{dM}{dq}\)<br> where \(\frac{d\Sigma}{dM} = 2M^T\)</p> </li> <li> <p>\(M = RS\)<br> where \(S = \begin{bmatrix} s_x &amp; s_x &amp; s_x \\ s_y &amp; s_y &amp; s_y \\ s_z &amp; s_z &amp; s_z \end{bmatrix}\)<br> So, \(\frac{dM_{i, j}}{ds_k} = \begin{cases} R_{i, k} &amp; \text{if j=k} \\ 0 &amp; O.W. \end{cases}\)</p> </li> <li> <p>\(M = RS\) and \(R(q) = \begin{bmatrix} 1 - 2 \cdot (q_j^2 + q_k^2) &amp; 2 \cdot (q_iq_j - q_rq_k) &amp; 2 \cdot (q_iq_k + q_rq_j) \\ 2 \cdot (q_iq_j + q_rq_k) &amp; 1 - 2 \cdot (q_i^2 + q_k^2) &amp; 2 \cdot (q_jq_k - q_rq_i) \\ 2 \cdot (q_iq_k - q_rq_j) &amp; 2 \cdot (q_jq_k + q_rq_i) &amp; 1 - 2 \cdot (q_i^2 + q_j^2) \end{bmatrix}\)<br> where \(q = \begin{bmatrix} q_r \\ q_i \\ q_j \\ q_k \end{bmatrix}\)<br> So, \(\frac{dM}{dq_r} = 2 \begin{bmatrix} 0 &amp; -s_y q_k &amp; s_z q_j \\ s_x q_k &amp; 0 &amp; -s_z q_i \\ -s_x q_j &amp; s_y q_i &amp; 0 \end{bmatrix}\)<br> and \(\frac{dM}{dq_i} = 2 \begin{bmatrix} 0 &amp; s_y q_j &amp; s_z q_k \\ s_x q_j &amp; -2 s_y q_i &amp; -s_z q_r \\ s_x q_k &amp; s_y q_r &amp; -2 s_z q_i \end{bmatrix}\)<br> and \(\frac{dM}{dq_j} = 2 \begin{bmatrix} -2 s_x q_j &amp; s_y q_i &amp; s_z q_r \\ s_x q_i &amp; 0 &amp; s_z q_k \\ -s_x q_r &amp; s_y q_k &amp; -2 s_z q_j \end{bmatrix}\)<br> and \(\frac{dM}{dq_k} = 2 \begin{bmatrix} -2 s_x q_k &amp; -s_y q_r &amp; s_z q_i \\ s_x q_r &amp; -2 s_y q_k &amp; s_z q_j \\ s_x q_i &amp; s_y q_j &amp; 0 \end{bmatrix}\)</p> </li> <li> <p>gradient for quaternion normalization is straightforward</p> </li> </ol> <blockquote> <p>EWA volume splatting (2001) :<br> world-to-camera 는 linear transformation 이지만,<br> <code class="language-plaintext highlighter-rouge">camera-to-image (projection)</code> 는 <code class="language-plaintext highlighter-rouge">non-linear transformation</code> 이다!!</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/4-480.webp 480w,/assets/img/2024-07-11-GS/4-800.webp 800w,/assets/img/2024-07-11-GS/4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 위 그림 : camera coordinate / 아래 그림 : image coordinate (ray space) </div> <ul> <li> <code class="language-plaintext highlighter-rouge">world</code> coordinate (3D) : <ul> <li> \[\boldsymbol u = \begin{bmatrix} u_0 \\ u_1 \\ u_2 \end{bmatrix}\] </li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">camera</code> coordinate (3D) : <ul> <li>\(\boldsymbol t = \begin{bmatrix} t_0 \\ t_1 \\ t_2 \end{bmatrix}\)<br> \(= W \boldsymbol u + d\)<br> where \(W\) : <code class="language-plaintext highlighter-rouge">viewing transformation</code> affine matrix from world coordinate to camera coordinate</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">image</code> coordinate (2D) : <ul> <li>\(\boldsymbol x = \begin{bmatrix} x_0 \\ x_1 \\ x_2 \end{bmatrix}\)<br> \(= \phi(\boldsymbol t) = \begin{bmatrix} \frac{t_0}{t_2} \\ \frac{t_1}{t_2} \\ \| (t_0, t_1, t_2)^T \| \end{bmatrix}\)</li> <li>function \(\phi\) 는 non-linear하므로 Affine transformation이 불가능하다.</li> <li> <code class="language-plaintext highlighter-rouge">Local Affine (Linear) transform으로 Approx.</code>하기 위해 \(\boldsymbol t = \boldsymbol t_{k}\) 에서의 <code class="language-plaintext highlighter-rouge">Taylor Approx.</code>를 이용하면,<br> \(\phi_{k}(\boldsymbol t) = \phi(\boldsymbol t_{k}) + \boldsymbol J_{k} \cdot (\boldsymbol t - \boldsymbol t_{k})\)<br> where<br> \(\boldsymbol J_{k} = \frac{d\phi}{d \boldsymbol t}(\boldsymbol t_{k}) = \begin{bmatrix} \frac{d\phi}{d \boldsymbol t_{0}}(\boldsymbol t_{k}) &amp; \frac{d\phi}{d \boldsymbol t_{1}}(\boldsymbol t_{k}) &amp; \frac{d\phi}{d \boldsymbol t_{2}}(\boldsymbol t_{k}) \end{bmatrix} = \begin{bmatrix} \frac{1}{t_{k, 2}} &amp; 0 &amp; -\frac{t_{k, 0}}{t_{k, 2}^2} \\ 0 &amp; \frac{1}{t_{k, 2}} &amp; -\frac{t_{k, 1}}{t_{k, 2}^2} \\ \frac{t_{k, 0}}{l} &amp; \frac{t_{k, 1}}{l} &amp; \frac{t_{k, 2}}{l} \end{bmatrix}\)<br> and ray distance \(l = \| (t_{k, 0}, t_{k, 1}, t_{k, 2})^T \|\)<br> Here, \(J\) : <code class="language-plaintext highlighter-rouge">Jacobian</code>(각 axis로 편미분한 matrix) of the <code class="language-plaintext highlighter-rouge">affine approx.</code> of the <code class="language-plaintext highlighter-rouge">projective transformation</code> from camera coordinate to image coordinate</li> <li>즉, camera coordinate에서 임의의 좌표 \(\boldsymbol t_{k}\) 주변에 존재하는 입력 좌표 \(\boldsymbol t\)에 대해서는 image coordinate으로의 affine(linear) transformation이 충족된다.</li> <li>Gaussian Splatting 논문의 경우 <code class="language-plaintext highlighter-rouge">Gaussian의 중심점</code>을 \(\boldsymbol t_{k}\) 로 두면 그 주변의 \(\boldsymbol t\)에 대해서는 Jacobian을 이용한 affine(linear) transformation 가능!</li> </ul> </li> </ul> <blockquote> <p><code class="language-plaintext highlighter-rouge">Projection</code> of 3D Gaussian <code class="language-plaintext highlighter-rouge">covariance</code> to 2D</p> </blockquote> <ul> <li> <p><code class="language-plaintext highlighter-rouge">world coordinate</code> :<br> \(\Sigma\) : 3 \(\times\) 3 covariance matrix of 3D Gaussian</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">image coordiante</code> (z=1) :<br> \(\Sigma^{\ast} = J W \Sigma W^T J^T\) : covariance matrix of 2D splat</p> <ul> <li>Step 1. world-to-camera (<code class="language-plaintext highlighter-rouge">affine</code>) :<br> \(\boldsymbol u \rightarrow W \boldsymbol u + d\)</li> <li>Step 2. camera-to-image (<code class="language-plaintext highlighter-rouge">local affine approx.</code>) :<br> Projection<br> \(W \boldsymbol u + d \rightarrow \phi_{k}(W \boldsymbol u + d) = x_k + \boldsymbol J_{k} W \boldsymbol u + \boldsymbol J_{k} (d - \boldsymbol t_{k})\)<br> 상수 부분을 제외하면 \(\boldsymbol x = \boldsymbol J_{k} W \boldsymbol u\)</li> <li>Step 3. covariance 특성 :<br> \(Cov[Ax] = E[(Ax - E[Ax])(Ax - E[Ax])^T]\)<br> \(= E[A(x - E[x])(x - E[x])^TA^T] = A Cov[x] A^T\)</li> <li>Step 4. <code class="language-plaintext highlighter-rouge">world-to-image covariance</code> :<br> \(\boldsymbol u \rightarrow \boldsymbol J_{k} W \boldsymbol u\) 이므로<br> \(\Sigma \rightarrow \boldsymbol J \boldsymbol W \Sigma \boldsymbol W^T \boldsymbol J^T\)</li> <li>Step 5. <code class="language-plaintext highlighter-rouge">covariance dimension reduction</code> :<br> 추가로, \(\boldsymbol J \boldsymbol W \Sigma \boldsymbol W^T \boldsymbol J^T\) 로 계산한 \(\Sigma^{\ast}\) 는 3-by-3 matrix 인데,<br> 3D Gaussian을 한쪽 축으로 적분하면 2D Gaussian과 동일한 값을 가지게 되므로<br> 3-by-3 covariance matrix의 3번째 행과 열의 값을 버린<br> 2-by-2 matrix를 projected 2D covariance matrix 로 사용!</li> </ul> </li> </ul> <h3 id="parameter-2-spherical-harmonicssh-coeff">Parameter 2. Spherical Harmonics(SH) coeff.</h3> <ul> <li> <code class="language-plaintext highlighter-rouge">Spherical Harmonics</code> (SH) :<br> spherical coordinate 에서 <code class="language-plaintext highlighter-rouge">각도</code> (\(\theta, \phi\))를 입력받아 <code class="language-plaintext highlighter-rouge">구의 표면 위치에서의 값</code>을 출력하는 함수<br> spherical coordinate 에서 라플라스 방정식을 풀면 아래 수식과 같음</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/5-480.webp 480w,/assets/img/2024-07-11-GS/5-800.webp 800w,/assets/img/2024-07-11-GS/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/6-480.webp 480w,/assets/img/2024-07-11-GS/6-800.webp 800w,/assets/img/2024-07-11-GS/6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/7-480.webp 480w,/assets/img/2024-07-11-GS/7-800.webp 800w,/assets/img/2024-07-11-GS/7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> l이 같은 함수들은 same band l에 있다고 말함 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/8-480.webp 480w,/assets/img/2024-07-11-GS/8-800.webp 800w,/assets/img/2024-07-11-GS/8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 가로축 : theta, 세로축 : phi, 채도 : SH magnitude, 색상 : SH phase </div> <ul> <li> <p>SH coeff. <code class="language-plaintext highlighter-rouge">초기값</code> :<br> 0-band SH (\(\theta, \phi\) 와 관계없는 view-independent color) 의 경우 SfM으로 얻은 point cloud의 RGB color값과 RGB2SH 이용하여 초기화<br> 다른 band의 경우 0으로 초기화</p> </li> <li>SH 의 역할 : <ul> <li>SH에서 band 수를 제한해서 쓴다는 것은 높은 band (high freq. 또는 detail info.)는 자른다는 의미이므로 <code class="language-plaintext highlighter-rouge">smoothing</code> 역할</li> <li>적은 비용(coeff. 몇 개만 사용)으로 SH function을 <code class="language-plaintext highlighter-rouge">approx.</code> </li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">SH coeff.</code>로 <code class="language-plaintext highlighter-rouge">color</code> 나타내는 법 :<br> Fourier Series 에서처럼,<br> SH coeff. \(k_{l}^{m}\) 의 optimal 값을 구해서<br> \(k_{l}^{m}\) 와 \(Y_l^m(\theta, \phi)\) 의 weighted sum!<br> \(C = \Sigma_{l=0}^{l_{max}} \Sigma_{m=-l}^{l} k_l^m Y_l^m(\theta, \phi)\)<br> 즉, <code class="language-plaintext highlighter-rouge">trainable parameter</code> : SH coeff.인 \(k_{l}^{m}\)<br> (<code class="language-plaintext highlighter-rouge">light source</code>마다 SH coeff. \(k_{l}^{m}\) 다르므로 find optimal value)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/9-480.webp 480w,/assets/img/2024-07-11-GS/9-800.webp 800w,/assets/img/2024-07-11-GS/9-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="parameter-3-opacity">Parameter 3. opacity</h3> <ul> <li> <p>opacity \(\alpha\) <code class="language-plaintext highlighter-rouge">초기값</code> :<br> 임의의 실수값으로 초기화<br> inverse_sigmoid(0.1 * torch.ones(…))</p> </li> <li> <p>opacity \(\alpha\) <code class="language-plaintext highlighter-rouge">range</code> :<br> \(\alpha \in [0, 1)\) 이므로<br> 마지막에 sigmoid activation function을 씌워서 smooth gradient를 얻음</p> </li> </ul> <h3 id="parameter-4-3d-positionmean">Parameter 4. 3D position(mean)</h3> <h2 id="fast-differentiable-rasterizer-for-gaussians">Fast Differentiable Rasterizer for Gaussians</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/10-480.webp 480w,/assets/img/2024-07-11-GS/10-800.webp 800w,/assets/img/2024-07-11-GS/10-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <blockquote> <p>Tile Rasterizer</p> </blockquote> <ul> <li> <p>기능 : 3D Gaussians로 구성된 3D model을 특정 camera pose에 대해 2D rendering</p> </li> <li> <code class="language-plaintext highlighter-rouge">input</code> : <ul> <li>image의 rendering할 width, height</li> <li>3D Gaussian의 xyz-mean, covariance in world-coordinate</li> <li>3D Gaussian의 color, opacity</li> <li>current camera pose</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Frustum Culling</code> :<br> 주어진 camera pose에서 view frustum을 그려서<br> view frustum과 교차하는 확률이 99% confidence interval 범위 밖에 있는 3D Gaussians는 제거(culling)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/16-480.webp 480w,/assets/img/2024-07-11-GS/16-800.webp 800w,/assets/img/2024-07-11-GS/16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Guard Band</code> :<br> 아래의 경우 projected 2D covariance 계산이 불안정하기 때문에 개별적으로 제거 <ul> <li> <code class="language-plaintext highlighter-rouge">view frustum의 near plane에 가까이 있는</code> Gaussian의 경우,<br> EWA Volume Splatting에서 언급된 cam-to-img projection <code class="language-plaintext highlighter-rouge">nonlinearity</code>가 심하기 때문에<br> projection matrix를 Jacobian으로 approx.한 값에 더 큰 artifact가 생김</li> <li>view frustum 밖에 멀리 떨어진 경우 <code class="language-plaintext highlighter-rouge">?????</code><br> 코드에서는 이 경우는 빼버렸음 (주석 처리)<br> (diff-gaussian-rasterization/cuda_rasterizer/auxiliary.h)</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Create Tiles</code> :<br> <code class="language-plaintext highlighter-rouge">CUDA 병렬 처리</code>를 위해<br> \(w \times h\)의 image를 \(16 \times 16\) pixel의 tiles로 쪼갬</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/11-480.webp 480w,/assets/img/2024-07-11-GS/11-800.webp 800w,/assets/img/2024-07-11-GS/11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p><code class="language-plaintext highlighter-rouge">Parallelism</code> :<br> <code class="language-plaintext highlighter-rouge">tile마다</code> 개별 <code class="language-plaintext highlighter-rouge">CUDA thread</code> block으로 실행하여<br> forward/backward processing, data loading/sharing을 병렬처리<br> (여러 threads가 Gaussian points를 shared memory에 collaboratively load)<br> (VRAM과 DRAM 사이의 이동은 overhead 발생하기 때문에 <code class="language-plaintext highlighter-rouge">VRAM</code>에서 모두 처리해버릴 수 있도록 <code class="language-plaintext highlighter-rouge">CUDA Functions</code>(.cu)를 직접 짬!)</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Duplicate with Keys</code> :</p> <ul> <li> <code class="language-plaintext highlighter-rouge">view-space-depth</code>와 <code class="language-plaintext highlighter-rouge">tile-ID</code>를 이용하여 tile마다 각 Gaussian의 key를 생성<br> tile-ID 쪽이 MSB<br> view-space-depth 쪽이 LSB<br> 각 Gaussian의 value는 Gaussian’s index</li> <li> <code class="language-plaintext highlighter-rouge">CUDA 병렬처리</code> 덕분에 2D Gaussian 하나가 3개의 tiles에 걸쳐 있다면, 3개의 2D Gaussians로 복제(<code class="language-plaintext highlighter-rouge">instance화</code>)되는 것처럼 작동</li> <li>tile1-depth1, tile1-depth2, tile1-depth3, tile2-depth1, tile2-depth2, … 순으로 정렬됨</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/12-480.webp 480w,/assets/img/2024-07-11-GS/12-800.webp 800w,/assets/img/2024-07-11-GS/12-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Sort by Keys</code> : <ul> <li>tile마다 Depth 기준으로 <code class="language-plaintext highlighter-rouge">Radix Sort</code> </li> <li> <code class="language-plaintext highlighter-rouge">처음에 한 번</code> sort 하고 나면 끝!! 추가로 per-pixel sorting 할 필요 없음</li> <li>tile마다 개별 thread로 parallel하게 실행하므로 single radix sort 만으로 all splats are ordered</li> <li>pixel-wise sorting이 아니라 Gaussians sort라서 \(\alpha\)-blending approx.이긴 한데, <code class="language-plaintext highlighter-rouge">splats가 각 pixel size 정도로 작기 때문에</code> 해당 approx. 오차는 무시 가능!</li> <li>쨌든 이 덕분에 visible artifacts 없이 training, rendering performance 베리베리 굳</li> </ul> </li> </ul> <pre><code class="language-Python">from collections import deque
# 양방향에서 삽입/삭제 가능한 queue형 자료구조

# 1의 자릿수 기준으로 정렬한 뒤
# 10의 자릿수 기준으로 정렬한 뒤
# ...
def radixSort():
    nums = list(map(int, input().split(' ')))
    buckets = [deque() for _ in range(10)] # 각 자릿수(0~9)에 대응되는 10개의 empty deque()
    
    max_val = max(nums)
    queue = deque(nums) # 정렬할 숫자들
    digit = 1 # 정렬 기준이 되는 자릿수
    
    while (max_val &gt;= digit): # 가장 큰 수의 자릿수일 때까지만 실행
        while queue:
            num = queue.popleft() # 정렬할 숫자
            buckets[(num // digit) % 10].append(num) # 각 자릿수(0~9)에 따라 buckets에 num을 넣는다.
        
        # 해당 정렬 기준 자릿수에서 buckets에 다 넣었으면, buckets에 담겨있는 순서대로 꺼내와서 정렬한다.
        for bucket in buckets:
            while bucket:
                queue.append(bucket.popleft())

        digit *= 10 # 정렬 기준이 되는 자릿수 증가시키기
    
    print(list(queue))
</code></pre> <ul> <li> <code class="language-plaintext highlighter-rouge">Identify Tile Ranges</code> : <ul> <li>tile별 Gaussian list를 효율적으로 관리하기 위해<br> tile마다 Gaussian list 범위 식별</li> <li>이 또한 <code class="language-plaintext highlighter-rouge">parallel</code>하게 이루어짐<br> 64-bit key(Gaussian)마다 개별 thread를 launch하여 상위 32-bit(tile-ID)를 two neighbors와 비교</li> </ul> </li> <li> <p><code class="language-plaintext highlighter-rouge">Get Tile Ranges</code> :<br> i-th tile에 대한 Gaussian list 범위 읽어옴</p> </li> <li>\(\alpha\)-Blending in Order (<code class="language-plaintext highlighter-rouge">forward process</code>) : <ul> <li>tile별 CUDA 병렬처리에 의해 각 pixel에 대해 <code class="language-plaintext highlighter-rouge">color</code> 및 <code class="language-plaintext highlighter-rouge">opacity</code> \(\alpha\) 값을 Gaussian list의 <code class="language-plaintext highlighter-rouge">앞에서 뒤로</code> accumulate<br> \(c = \alpha_{1}c_{1} + (1 - \alpha_{1})(\alpha_{2}c_{2} + (1 - \alpha_{2})(\cdots)) = \alpha_{1}c_{1} + (1 - \alpha_{1})\alpha_{2}c_{2} + (1 - \alpha_{1})(1 - \alpha_{2})(\cdots) = \cdots = \sum_{i=1}^{N}(\alpha_{i}c_{i}\prod_{j=1}^{i-1}(1-\alpha_{j}))\) where \(\alpha_{0} = 0\)</li> <li>i-th tile에 있는 pixels 중 a pixel’s accumulated opacity 값이 target saturation threshold를 넘어서면, 해당 i-th thread STOP (유일한 STOP 조건)</li> <li> <code class="language-plaintext highlighter-rouge">Gaussian의 개수를 제한하지 않음</code>으로써 scene-specific hyper-param. tuning 없이 arbitrary depth complexity를 가지는 scene을 커버 가능<br> (GPU Radix Sort 덕분에 parallelism(병렬) 및 amortized(분할상환) 가능하여 Gaussian 개수 늘릴 수 있었음)</li> <li> <code class="language-plaintext highlighter-rouge">기존 기법들은 pixel마다 정렬이 필요</code>해서 inefficient했지만<br> 본 논문은 tile별 CUDA 병렬처리 덕분에 efficient<br> (e.g. NeRF : ray per pixel 쏴서 t-distance를 pixel별로 정렬해야 함)</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Backward process</code> : <ul> <li>각 tile의 Gaussian list에 대해 Gaussian의 <code class="language-plaintext highlighter-rouge">opacity 비율에 따라</code> <code class="language-plaintext highlighter-rouge">뒤에서 앞으로</code> gradient update</li> <li>직접 backward gradient update 식을 구해서 이용</li> <li>backward process를 위해 <d-cite key="Point1">[3]</d-cite>처럼 <code class="language-plaintext highlighter-rouge">pixel마다</code> global memory에 blended points list를 저장할 수도 있지만<br> dynamic memory management overhead가 생기기 때문에<br> forward process에서 <code class="language-plaintext highlighter-rouge">tile마다</code> 구했던 range 및 sorted Gaussian list를 <code class="language-plaintext highlighter-rouge">재사용</code> </li> <li>\(\alpha\)-blending으로 합쳤던 각 Gaussian으로 gradient back-propagation을 해주려면<br> \(\alpha\)-blending 각 step에서의 accumulated opacity 값이 필요한데,<br> 이를 따로 list에 저장해두고 훑는 게 아니라,<br> \(\alpha\)-blending을 할 때 그때그때 각 \(l\) -th Gaussian point에 지금까지의 accumulated opacity 값인 \(\alpha_{l}\)을 저장해두고,<br> \(\alpha\)-blending final step에서의 total accumulated opacity 값 \(\alpha_{N}\)만 backward process에 넘겨 주면<br> backward process할 때 \(\alpha_{N}\)를 \(\alpha_{l}\)로 나눈 값을 gradient 계산에 사용 <code class="language-plaintext highlighter-rouge">?????</code> </li> <li>0으로 나눠지는 경우를 방지하기 위해 \(\alpha\) 값이 \(\frac{1}{255}\)보다 작다면 blending update 안 함</li> <li>rasterization 중에 blending 값이 0.9999를 초과하기 전에 STOP</li> </ul> </li> <li> <p>Primitives :<br> 본 논문의 Gaussians는 <code class="language-plaintext highlighter-rouge">Euclidean space</code>에 <code class="language-plaintext highlighter-rouge">primitives</code>를 남김 <code class="language-plaintext highlighter-rouge">?????</code><br> \(\rightarrow\) <d-cite key="Plenoxels">[1]</d-cite>, <d-cite key="MipNeRF360">[10]</d-cite>과 달리 distant or large Gaussians 처리를 위해 space compaction, warping, or projection 할 필요가 없음</p> </li> <li>Efficient Rasterization : <ul> <li>Pulsar 논문<d-cite key="Pulsar">[5]</d-cite> 에서처럼<br> an entire image에 대해 가장 작은 원소(<code class="language-plaintext highlighter-rouge">primitives</code>)를 미리 정렬(<code class="language-plaintext highlighter-rouge">pre-sort</code>)하여 <code class="language-plaintext highlighter-rouge">primitives = Gaussians ?????</code><br> pixel-wise sorting 비용을 절감</li> <li>differentiable</li> <li>arbitrary number of Gaussians에 대해 backpropagation 가능<br> with low additional memory : O(1) per pixel</li> <li>2D projection 가능</li> </ul> </li> </ul> <h2 id="optimization-with-adaptive-density-control-of-3d-gaussians">Optimization with Adaptive Density Control of 3D Gaussians</h2> <h3 id="optimization">Optimization</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/13-480.webp 480w,/assets/img/2024-07-11-GS/13-800.webp 800w,/assets/img/2024-07-11-GS/13-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>Loss :<br> predicted image와 GT image를 비교하는<br> <code class="language-plaintext highlighter-rouge">L1 loss</code> 및 <code class="language-plaintext highlighter-rouge">D-SSIM loss</code><br> D-SSIM : Directional Structural Similarity Index Measure</p> </li> <li> <p>3D Gaussian의 xyz-mean에 대해서만 <d-cite key="Plenoxels">[1]</d-cite>에서처럼 <code class="language-plaintext highlighter-rouge">standard exponential decay scheduling</code> 사용</p> </li> <li>Adam optimizer로 네 가지 param. 업데이트 <ul> <li>3D xyz-mean</li> <li>3D covariance</li> <li>color</li> <li>opacity</li> </ul> </li> <li>optimization 세부 사항 : <ul> <li>연산을 <code class="language-plaintext highlighter-rouge">low resol.부터 warm-up</code> :<br> 목적 : model이 효율적으로 coarse info.부터 학습하도록 하여 <code class="language-plaintext highlighter-rouge">stability</code> 향상<br> 초기에 4배 작은 image로 optimization 진행하고 250, 500 iter.에서 2배씩 upsampling</li> <li>Spherical Harmonics <code class="language-plaintext highlighter-rouge">low band부터 warm-up</code> :<br> 목적 : 처음부터 high band로 detail까지 학습하려고 하면<br> scene의 corner를 촬영하거나 inside-out 방식(카메라가 촬영 대상의 내부에 위치하여 바깥쪽을 촬영) 때문에<br> <code class="language-plaintext highlighter-rouge">놓친 angular 영역이 있을 경우 SH의 0-band coeff. (base or diffuse color)가 부적절</code>하게 만들어질 수 있어서<br> 처음에는 0-band coeff.를 optimize하고 매 1000 iter.마다 band 수 늘려서 4-band coeff.까지 optimization</li> </ul> </li> </ul> <h3 id="adaptive-density-control-of-gaussians">Adaptive Density Control of Gaussians</h3> <p>optimization of 4 param.의 경우 매 iter.마다 update하지만,<br> Adaptive Density Control of Gaussians의 경우 <code class="language-plaintext highlighter-rouge">100 iter.마다</code> update</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/14-480.webp 480w,/assets/img/2024-07-11-GS/14-800.webp 800w,/assets/img/2024-07-11-GS/14-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Remove</code> :<br> \(\alpha\) 값이 threshold보다 작거나<br> world-space에서 크기가 매우 크거나<br> view-space에서 footprint가 매우 큰 경우<br> 3D Gaussians 제거</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/15-480.webp 480w,/assets/img/2024-07-11-GS/15-800.webp 800w,/assets/img/2024-07-11-GS/15-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/15.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>Gaussians가 scene을 제대로 표현 못 하는 중<br> \(\rightarrow\) scene을 제대로 표현하기 위해선 Gaussian position을 크게 옮겨야 함<br> \(\rightarrow\) view-space positional gradient \(\Delta_{p} L\)가 큼<br> \(\rightarrow\) under/over-reconstruction 상황이므로 clone/split을 통해 정확한 위치에 Gaussian이 분포하도록 하자</p> </li> <li> <code class="language-plaintext highlighter-rouge">Split</code> :<br> <code class="language-plaintext highlighter-rouge">over-reconstruction</code>의 경우 3D Gaussians split <ul> <li>split : 1개의 Gaussian을 <code class="language-plaintext highlighter-rouge">2개로 분리</code>하고 각 scale을 줄인 후 <code class="language-plaintext highlighter-rouge">기존 3D Gaussian의 PDF</code>에 따라 sampling하여 배치<br> Gaussians의 수는 증가하지만, total volume은 유지</li> <li>조건 1. <code class="language-plaintext highlighter-rouge">view-space positional gradient</code> \(\Delta_{p} L\)의 avg. magnitude \(\geq\) threshold \(\tau_{pos}\)</li> <li>조건 2. <code class="language-plaintext highlighter-rouge">covariance</code>가 큼</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Clone</code> :<br> <code class="language-plaintext highlighter-rouge">under-reconstruction</code>의 경우 3D Gaussians clone <ul> <li>clone : <code class="language-plaintext highlighter-rouge">같은 크기로 copy</code> 후 <code class="language-plaintext highlighter-rouge">positional gradient 방향</code>에 배치<br> total volume 및 Gaussians의 수 모두 증가</li> <li>조건 1. <code class="language-plaintext highlighter-rouge">view-space positional gradient</code> \(\Delta_{p} L\)의 avg. magnitude \(\geq\) threshold \(\tau_{pos}\)</li> <li>조건 2. <code class="language-plaintext highlighter-rouge">covariance</code>가 작음</li> </ul> </li> <li>3000 iter.마다 \(\alpha\) <code class="language-plaintext highlighter-rouge">알파 값을 주기적으로 0으로 초기화</code> 하면 전체 Gaussian 조절에 큰 도움이 됨! <ul> <li>효과 1. volumetric 기법의 특성상 <code class="language-plaintext highlighter-rouge">camera와 가까운 영역</code>에서 많은 <code class="language-plaintext highlighter-rouge">floater</code>들이 생겨서 Gaussian density가 증가하는데, 이를 제거해주는 역할<br> floater 해결 관련 논문 : <d-cite key="floater1">[6]</d-cite> <d-cite key="floater2">[7]</d-cite> <d-cite key="floater3">[8]</d-cite> </li> <li>효과 2. <code class="language-plaintext highlighter-rouge">큰 Gaussian들이 중첩</code>되어 있는 case를 제거해주는 역할</li> </ul> </li> </ul> <h2 id="results">Results</h2> <h3 id="implementation">Implementation</h3> <ul> <li> <p>custom CUDA kernel :<br> tile-based rasterization을 위해<br> custom CUDA kernel를 추가하여 사용 like <d-cite key="Point1">[3]</d-cite>, <d-cite key="Plenoxels">[1]</d-cite>, <d-cite key="superfast">[9]</d-cite></p> </li> <li> <p>Radix Sort :<br> fast Radix Sort를 위해 NVIDIA CUB sorting routines <d-cite key="radixsort">[11]</d-cite> 사용</p> </li> <li> <p>interactive image viewer :<br> open-source SIBR <a href="https://gitlab.inria.fr/sibr/sibr_core" rel="external nofollow noopener" target="_blank">SIBR</a> 이용해서<br> interactive image-rendering viewer 만듬 (frame rate 측정에 사용)</p> </li> </ul> <h3 id="evaluation">Evaluation</h3> <ul> <li>Dataset :<br> bounded indoor scenes와 unbounded outdoor scenes 전부 커버 <ul> <li>synthetic Blender dataset (Nerf) :<br> have exhaustive set of bounded views with exact camera param.<br> \(\rightarrow\) SOTA result even with 100K uniformly random initialization</li> <li>Mip-Nerf360 dataset</li> <li>Tanks&amp;Temples dataset</li> <li>Hedman et al. dataset</li> </ul> </li> <li>Metrics : <ul> <li>PSNR</li> <li>L-PIPS</li> <li>SSIM (D-SSIM)</li> </ul> </li> <li>Comparison : <ul> <li> <code class="language-plaintext highlighter-rouge">Quality</code> : NeRF 계열 중 SOTA인 <code class="language-plaintext highlighter-rouge">Mip-Nerf360</code> <d-cite key="MipNeRF360">[10]</d-cite>과 비교 <ul> <li>끝까지 훈련시켰을 때 비슷한 quality 보이고,</li> <li>training speed는 35-45 min. versus 48 hours</li> </ul> </li> <li>Traning/Rendering <code class="language-plaintext highlighter-rouge">Speed</code> : NeRF 계열 중 SOTA인 <code class="language-plaintext highlighter-rouge">InstantNGP</code> <d-cite key="InstantNGP">[2]</d-cite>, <code class="language-plaintext highlighter-rouge">Plenoxels</code> <d-cite key="Plenoxels">[1]</d-cite> 과 비교 <ul> <li>speed SOTA인 <d-cite key="InstantNGP">[2]</d-cite> , <d-cite key="Plenoxels">[1]</d-cite> 과 비슷한 quality 가질 때까지 training 5-10 min.밖에 안 걸리고,</li> <li>훈련 더 하면 <d-cite key="InstantNGP">[2]</d-cite>, <d-cite key="Plenoxels">[1]</d-cite>보다 더 좋은 quality 가짐</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/19-480.webp 480w,/assets/img/2024-07-11-GS/19-800.webp 800w,/assets/img/2024-07-11-GS/19-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/17-480.webp 480w,/assets/img/2024-07-11-GS/17-800.webp 800w,/assets/img/2024-07-11-GS/17-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/17.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 7K iter.으로도 꽤 좋은 결과 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/18-480.webp 480w,/assets/img/2024-07-11-GS/18-800.webp 800w,/assets/img/2024-07-11-GS/18-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Comparison : <ul> <li>Compactness :<br> anisotropic 3D Gaussians는<br> scene representation 뿐만 아니라<br> complex shape with a lower number of param.을 모델링하는 데도 쓰일 수 있음 <ul> <li>space carving으로 얻은 <d-cite key="Point3">[12]</d-cite> 의 initial point cloud에서 시작했을 때 <d-cite key="Point3">[12]</d-cite> 의 PSNR 값은 2-4 min.만에 넘겨버림</li> <li>또한, <d-cite key="Point3">[12]</d-cite> 의 point cloud의 4분의 1만큼만 써도 작은 model size로도 <d-cite key="Point3">[12]</d-cite> 의 PSNR 넘겨버림</li> </ul> </li> </ul> </li> </ul> <blockquote> <p>Space Carving :</p> <ul> <li>설명 : 여러 camera에 대해 voxel-space에서 object 있는 부분만 남기고 깎아내는 기법</li> <li>이유 : 3D reconstruction을 할 때 color 정보만으로 segmentation 가능할 정도로 background는 simple할수록 좋기 때문</li> <li>한계 : 빛, 그림자 같은 정보는 사용하지 않기 때문에 fg/bg 판단만 가능하다. 따라서 lidar처럼 camera에 depth-detection 메커니즘이 없을 경우 물체 내부의 구멍 같은 건 reconstruct 불가능</li> </ul> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/20-480.webp 480w,/assets/img/2024-07-11-GS/20-800.webp 800w,/assets/img/2024-07-11-GS/20-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="ablation-study">Ablation Study</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/21-480.webp 480w,/assets/img/2024-07-11-GS/21-800.webp 800w,/assets/img/2024-07-11-GS/21-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> PSNR score for Ablation Study </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Intialization (SfM)</code> : <ul> <li>uniformly sample a cube (random initialization w/o SfM points) :<br> 주로 <code class="language-plaintext highlighter-rouge">background</code> 퀄리티 저하<br> training view가 충분하지 않은 영역에서는 optimization으로 제거할 수 없는 <code class="language-plaintext highlighter-rouge">floater</code> 많이 발생<br> \(\rightarrow\) synthetic NeRF dataset의 경우 bg가 없고 have exhaustive set of bounded views with exact input camera param. 이므로 random initializatino으로도 성능 굳</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/22-480.webp 480w,/assets/img/2024-07-11-GS/22-800.webp 800w,/assets/img/2024-07-11-GS/22-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/22.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Densification (clone, split)</code> : <ul> <li>Split : <code class="language-plaintext highlighter-rouge">background</code> reconstruction에 중요한 역할</li> <li>Clone : <code class="language-plaintext highlighter-rouge">thin</code> structure reconstruction에 중요한 역할</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/23-480.webp 480w,/assets/img/2024-07-11-GS/23-800.webp 800w,/assets/img/2024-07-11-GS/23-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/23.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Unlimited depth complexity of splats with gradients</code> : <ul> <li>Limited-BW :<br> 각 tile의 Gaussian list에서 앞에서부터 N개까지만 gradient 전파할 경우<br> Pulsar <d-cite key="Pulsar">[5]</d-cite>에서의 값의 2배인 N=10으로 했는데도 unstable optimization 초래</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/24-480.webp 480w,/assets/img/2024-07-11-GS/24-800.webp 800w,/assets/img/2024-07-11-GS/24-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/24.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> left: N=10 / right: N=inf </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Anisotropic Covariance</code> : <ul> <li>isotropic convariance :<br> single scala value (radius of 3D Gaussian)를 optimize할 경우<br> 같은 Gaussian 개수를 쓰더라도 <code class="language-plaintext highlighter-rouge">align with surfaces</code> 잘 하지 못해서 <code class="language-plaintext highlighter-rouge">fine</code> structure 잘 나타내지 못함</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/25-480.webp 480w,/assets/img/2024-07-11-GS/25-800.webp 800w,/assets/img/2024-07-11-GS/25-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/25.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Spherical Harmonics</code> : <ul> <li>color 나타낼 때 <code class="language-plaintext highlighter-rouge">view-dependent</code> effect 담당</li> </ul> </li> </ul> <h2 id="discussion">Discussion</h2> <h3 id="limitations--future-work">Limitations &amp; Future Work</h3> <ul> <li> <code class="language-plaintext highlighter-rouge">training view가 부족한 영역</code>에서는 여전히 <code class="language-plaintext highlighter-rouge">floater</code>, <code class="language-plaintext highlighter-rouge">elongated(길쭉한) artifacts</code>, <code class="language-plaintext highlighter-rouge">splotchy(얼룩진) Gaussians</code> 등 artifacts 발생 (Mip-NeRF360 등 prev. methods도 마찬가지)<br> \(\rightarrow\) regularization으로 alleviate 가능</li> <li> <code class="language-plaintext highlighter-rouge">view-dependent appearance</code>가 나타나는 영역에서는 large Gaussian 만들 때 <code class="language-plaintext highlighter-rouge">guard band</code> 등의 이유로 <code class="language-plaintext highlighter-rouge">popping</code> artifacts 발생<br> \(\rightarrow\) better culling과 regularization으로 alleviate 가능</li> <li>Gaussians <code class="language-plaintext highlighter-rouge">depth-order</code> 갑자기 바뀔 수 있음<br> \(\rightarrow\) <code class="language-plaintext highlighter-rouge">anti-aliasing</code>으로 해결 가능</li> <li>urban dataset처럼 very <code class="language-plaintext highlighter-rouge">large scene</code>에 대해서는 <code class="language-plaintext highlighter-rouge">position learning-rate</code>를 줄이는 게 도움됨</li> <li>prev. point-based methods에 비해서는 compact하긴 하지만, NeRF-based methods에 비해서는 memory consumption이 훨씬 큼<br> e.g. large scene을 학습할 때 최대 GPU memory consumption은 20GB를 넘김<br> \(\rightarrow\) InstantNGP에서처럼 optimization 과정을 low-level implementation 하면 괜찮<br> e.g. scene을 rendering할 때도 model 저장하는 데 몇백MB, rasterizer 저장하는 데 30-500MB 필요<br> \(\rightarrow\) memory consumption을 줄이기 위한 추후 개선 필요 (point-clouds compression technique <d-cite key="pointcompress">[13]</d-cite>을 적용해볼 수 있을 듯)</li> <li>3D Gaussians를 mesh reconstruction에 사용할 수 있는지 연구가 진행된다면 본 논문이 정확히 volumetric 과 surface representation 사이 어디에 위치해있는지를 이해할 수 있음</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/26-480.webp 480w,/assets/img/2024-07-11-GS/26-800.webp 800w,/assets/img/2024-07-11-GS/26-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/26.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> left(Mip-NeRF360): floaters and grainy(오돌토돌한, 거친) appearance / right(3DGS): low-detail bg from coarse Gaussians </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-11-GS/27-480.webp 480w,/assets/img/2024-07-11-GS/27-800.webp 800w,/assets/img/2024-07-11-GS/27-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-07-11-GS/27.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> training에서 많이 보지 못한 view의 경우 left(Mip-NeRF360), right(3DGS) 모두 artifacts 발생 </div> <h3 id="conclusion">Conclusion</h3> <ul> <li> <code class="language-plaintext highlighter-rouge">3D Gaussian</code> :<br> volumetric rendering의 특성을 살림과 동시에 fast splat-based rasterization 가능<br> continuous representation이어야만 fast, high-quality radiance field training 가능하다는 기존 통념을 반전시킴</li> <li> <code class="language-plaintext highlighter-rouge">CUDA</code> Implementation :<br> training time의 80%는 Pytorch code (for 가독성)<br> rasterization만 optimized CUDA kernels (for real-time)<br> \(\rightarrow\) InstantNGP <d-cite key="InstantNGP">[2]</d-cite>처럼 optimization 나머지 부분도 전부 CUDA로 옮기면 훨씬 speedup 가능</li> <li> <code class="language-plaintext highlighter-rouge">real-time rasterization by GPU</code> :<br> rasterization이 main bottleneck인데<br> GPU 힘으로 real-time rasterization pipeline 구현한 게<br> 기존 volumetric ray-marching NeRF-based 기법보다 faster training, rendering 가능했던 비결</li> <li>Higher Quality than SOTA Mip-NeRF360(2022)</li> <li>Faster Training than SOTA InstantNGP(2022)</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-07-11-GS.bib"></d-bibliography> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="semyeong-yu",disqus_identifier="/blog/2024/GS",disqus_title="3D Gaussian Splatting";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>