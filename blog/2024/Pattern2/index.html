<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> EE534 Pattern Recognition Final | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="Lecture Summary (24F)"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/Pattern2/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "EE534 Pattern Recognition Final",
            "description": "Lecture Summary (24F)",
            "published": "October 28, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>EE534 Pattern Recognition Final</h1> <p>Lecture Summary (24F)</p> </d-title> <d-article> <blockquote> <p>Lecture :<br> 24F EE534 Pattern Recognition<br> by KAIST Munchurl Kim <a href="https://www.viclab.kaist.ac.kr/" rel="external nofollow noopener" target="_blank">VICLab</a></p> </blockquote> <h2 id="chapter-5-linear-discriminant-functions">Chapter 5. Linear Discriminant Functions</h2> <h3 id="linearly-non-separable-svm">Linearly Non-Separable SVM</h3> <ul> <li>new constraint :<br> \(y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) \geq 1 - \xi_{i}\)<br> \(\xi_{i}\) 를 도입하여 이제는 inside margin or misclassified 도 가능하지만 대신 \(C \sum_{i=1}^{N} \xi_{i}\) 를 loss에 넣어서 큰 \(\xi_{i}\) 값을 penalize <ul> <li>\(\xi = 0\) : outside margin or support vector</li> <li>\(0 \lt \xi \leq 1\) : inside margin (correctly classified, but margin violation)</li> <li>\(\xi \gt 1\) : misclassified</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/2m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/2m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/2m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/2m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>방법 1) 1-norm-soft-margin <ul> <li>constrained primal form :<br> minimize \(J(\boldsymbol w, \xi) = \frac{1}{2} \| \boldsymbol w \|^{2} + C \sum_{i=1}^{N} \xi_{i}\)<br> subject to \(y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) \geq 1 - \xi_{i}\) and \(\xi_{i} \geq 0\) <ul> <li>unconstrained primal form :<br> 이 때 위의 두 가지 constraints는 \(\xi_{i} = \text{max}(0, 1 - y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}))\) 로 하나로 합칠 수 있음<br> 따라서<br> minimize \(J(\boldsymbol w, \xi) = \frac{1}{2} \| \boldsymbol w \|^{2} + C \sum_{i=1}^{N} \text{max}(0, 1 - y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}))\)</li> <li>regularization param. \(C\) : <ul> <li>small \(C\) : 큰 \(\xi_{i}\) 값도 허용하므로 margin 커짐</li> <li>large \(C\) : 큰 \(\xi_{i}\) 값은 허용 안 하므로 margin 작아짐</li> <li>\(C = \infty\) : non-zero \(\xi_{i}\) 값 허용 안 하므로 hard margin (no sample inside margin)<br> (Linearly Separable SVM 에 해당함)</li> </ul> </li> </ul> </li> <li>Lagrangian :<br> minimize \(L(\boldsymbol w, w_{0}, \xi, \boldsymbol \lambda, \boldsymbol \mu) = \frac{1}{2} \| \boldsymbol w \|^{2} + C \sum_{i=1}^{N} \xi_{i} - \sum_{i}^{N} \mu_{i} \xi_{i} - \sum_{i}^{N} \lambda_{i} (y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) - (1 - \xi_{i}))\)<br> subject to \(\xi_{i}, \mu_{i}, \lambda_{i} \geq 0\) <ul> <li> \[\nabla_{\boldsymbol w} L = 0 \rightarrow \boldsymbol w = \sum_{i=1}^{N} \lambda_{i} y_{i} \boldsymbol x_{i}\] </li> <li> \[\nabla_{w_{0}} L = 0 \rightarrow \sum_{i=1}^{N} \lambda_{i} y_{i} = 0\] </li> <li> \[\nabla_{\xi_{i}} L = 0 \rightarrow C - \mu_{i} - \lambda_{i} = 0\] </li> </ul> </li> <li>KKT condition 중 slackness condition : <ul> <li> \[\lambda_{i} (y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) - (1 - \xi_{i})) = 0\] </li> <li> \[\mu_{i} \xi_{i} = 0\] </li> </ul> </li> <li>dual form :<br> 위의 세 가지 식을 대입하여 \(\boldsymbol w, w_{0}, \xi_{i}, \mu_{i}\) 를 소거하면<br> maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j}\)<br> subject to \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\) and \(0 \leq \lambda_{i} \leq C\)</li> <li>Summary : <ul> <li>Step 1) optimal \(\lambda_{i}^{\ast}\) 구하기<br> \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\) and \(0 \leq \lambda_{i} \leq C\) 이용해서<br> \(\nabla_{\lambda_{i}} L = 0\) 으로 아래의 dual form 풀어서<br> (maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j}\))<br> optimal \(\lambda_{i}\) 얻음</li> <li>Step 2) optimal \(\boldsymbol w^{\ast}, w_{0}^{\ast}\) 구하기 <ul> <li>\(\boldsymbol w^{\ast} = \sum_{i=1}^{N_{s}} \lambda_{i}^{\ast} y_{i} x_{i}\)<br> (\(N_{s}\) : support vector 개수)<br> (hyperplane 결정할 때는 \(\lambda_{i} \gt 0\) 중에 \(\xi = 0\) 인 support vectors만 고려!!)</li> <li>\(w_{0}^{\ast} = \frac{1}{y_{j}} - \sum_{i=1}^{N_{s}} \lambda_{i}^{\ast} y_{i} x_{i}^{T} x_{j} = \frac{1}{y_{j}} - \boldsymbol w^{\ast T} x_{j}\)<br> (support vector \(x_{j}\) 1개 사용)<br> 또는<br> \(w_{0}^{\ast} = \frac{1}{N_{s}} \sum_{j=1}^{N_{s}} (\frac{1}{y_{j}} - \sum_{i=1}^{N_{s}} \lambda_{i}^{\ast} y_{i} x_{i}^{T} x_{j}) = \frac{1}{N_{s}} \sum_{j=1}^{N_{s}} (\frac{1}{y_{j}} - \boldsymbol w^{\ast T} x_{j})\)<br> (support vector \(x_{j}\) \(N_{s}\)-개 모두 사용하여 average value)</li> </ul> </li> <li>Tip : hard margin (no sample inside margin) 의 경우<br> 육안으로 어떤 sample이 support vector일지 판단 가능하다면<br> complementary slackness condition (\(\lambda_{i} (y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) - (1 - \xi_{i})) = 0\)) 에서<br> support vector만 \(\lambda_{i} \gt 0\) 이므로<br> 연립해서 \(\boldsymbol w^{\ast}, w_{0}^{\ast}\) 바로 구할 수 있음</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/1m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/1m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/1m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/1m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>방법 2) 2-norm-soft-margin <ul> <li>차이점 1) primal form<br> minimize \(J(\boldsymbol w, \xi) = \frac{1}{2} \| \boldsymbol w \|^{2} + C \sum_{i=1}^{N} \xi_{i}\)<br> subject to \(y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) \geq 1 - \xi_{i}\) and \(\xi_{i} \geq 0\)<br> 대신<br> minimize \(J(\boldsymbol w, \xi) = \frac{1}{2} \| \boldsymbol w \|^{2} + \frac{1}{2} C \sum_{i=1}^{N} \xi_{i}^{2}\)<br> subject to \(y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) \geq 1 - \xi_{i}\) and \(\xi_{i} \geq 0\)</li> <li>차이점 2) Lagrangian<br> \(\nabla_{\xi_{i}} L(\boldsymbol w, w_{0}, \boldsymbol \xi, \boldsymbol \lambda, \boldsymbol \mu) = 0\) 했을 때<br> \(C - \mu_{i} - \lambda_{i} = 0\)<br> 대신<br> \(C \xi_{i} - \mu_{i} - \lambda_{i} = 0\)</li> <li>차이점 3) dual form<br> maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j}\)<br> subject to \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\) and \(0 \leq \lambda_{i} \leq C\)<br> 대신<br> maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j} - \frac{1}{2C} \sum_{i=1}^{N} (\lambda_{i} + \mu_{i})^{2}\)<br> subject to \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\) and \(0 \leq \lambda_{i} \leq C\)</li> </ul> </li> <li>Remark : <ul> <li>Linearly Non-Separable SVM에서<br> \(C \rightarrow \infty\) 하면 Linearly Separable SVM<br> e.g. non-linear에서는 \(0 \leq \lambda_{i} \leq C\) 인데, linear에서는 \(0 \leq \lambda_{i} \lt \infty\)</li> <li>SVM의 한계 :<br> high computational complexity<br> (SVM training은 주로 batch mode로 진행되어 memory를 많이 필요로 하므로<br> training dataset을 subset으로 나눠서 training 진행)</li> <li>지금까지는 SVM for two-category만 살펴봤는데,<br> M-class 의 경우 M개의 discriminant function \(g_{i}(x)\) 를 design하여<br> assign \(x\) to class \(w_{i}\) if \(i = \text{argmax}_{k} g_{k}(x)\)</li> </ul> </li> </ul> <h3 id="v-svm">v-SVM</h3> <ul> <li>v-SVM : <ul> <li>hyperplane<br> \(\boldsymbol w^{T} \boldsymbol x_{i} + w_{0} = \pm 1\)<br> 대신<br> \(\boldsymbol w^{T} \boldsymbol x_{i} + w_{0} = \pm \rho\)<br> where \(\rho \geq 0\) : var. to be optimized</li> <li>margin<br> margin은 \(\frac{2 \rho}{\| w \|}\) 이므로<br> margin을 maximize하려면<br> \(\| w \|\) minimize 뿐만 아니라 \(\rho\) maximize하면 되므로<br> 둘 다 primal form loss term에 넣음</li> <li>primal form<br> minimize \(J(\boldsymbol w, \xi, \rho) = \frac{1}{2} \| \boldsymbol w \|^{2} - v \rho + \frac{1}{N} \sum_{i=1}^{N} \xi_{i}\)<br> subject to \(y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) \geq \rho - \xi_{i}\) and \(\xi_{i} \geq 0\) and \(\rho \geq 0\)</li> <li>Lagrangian<br> \(L(\boldsymbol w, w_{0}, \boldsymbol \xi, \rho, \boldsymbol \lambda, \boldsymbol \mu, \delta) = \frac{1}{2} \| \boldsymbol w \|^{2} - v \rho + \frac{1}{N} \sum_{i=1}^{N} \xi_{i} - \sum_{i}^{N} \mu_{i} \xi_{i} - \sum_{i}^{N} \lambda_{i} (y_{i} (\boldsymbol w^{T} \boldsymbol x_{i} + w_{0}) - (\rho - \xi_{i})) - \delta \rho\) <ul> <li>\(\nabla_{\boldsymbol w} L = 0\) 했을 때<br> \(\boldsymbol w = \sum_{i=1}^{N} \lambda_{i} y_{i} \boldsymbol x_{i}\)</li> <li>\(\nabla_{w_{0}} L = 0\) 했을 때<br> \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\)</li> <li>\(\nabla_{\xi_{i}} L = 0\) 했을 때<br> \(\mu_{i} + \lambda_{i} = \frac{1}{N}\)</li> <li>\(\nabla_{\rho} L = 0\) 했을 때<br> \(\sum_{i=1}^{N} \lambda_{i} - \delta = v\)</li> </ul> </li> <li>KKT condition 중 complementary slackness<br> For \(\lambda_{i} \geq 0\) and \(\mu_{i} \geq 0\) and \(\delta \geq 0\), <ul> <li> \[\lambda_{i} (y_{i}(\boldsymbol w^{T} \boldsymbol x + w_{0}) - (\rho - \xi_{i})) = 0\] </li> <li> \[\mu_{i} \xi_{i} = 0\] </li> <li> \[\delta \rho = 0\] </li> </ul> </li> <li>dual form<br> maximize \(L(\lambda) = - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j}\)<br> subject to \(\sum_{i=1}^{N} \lambda_{i} y_{i} = 0\) and \(0 \leq \lambda_{i} \leq \frac{1}{N}\) and \(\sum_{i=1}^{N} \lambda_{i} = \delta + v \geq v\) <ul> <li>\(\lambda\) 만 explicitly 남아 있고,<br> margin var. \(\rho\) 와 slack var. \(\xi_{i}\) 는 constraint의 bounds에 implicitly 들어 있음</li> <li>v-SVM에서는 \(\sum_{i=1}^{N} \lambda_{i}\) term이 없으므로<br> optimal \(\lambda_{i}\) 는 quadratically homogeneous solution</li> <li>새로운 constraint \(\sum_{i=1}^{N} \lambda_{i} \geq v\) 있음</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/3m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/3m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/3m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/3m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Remark <ul> <li>v-SVM의 경우 \(0 \leq v \leq 1\) 이어야 optimizable</li> <li>C-SVM에 비해 v-SVM은<br> error rate와 support vector 수 bound 측면에서 장점 <code class="language-plaintext highlighter-rouge">???</code> </li> <li>\(\rho \gt 0\) 일 때 \(\delta = 0\) 이므로<br> \(\sum_{i=1}^{N} \lambda_{i} = v\)</li> <li>loss (error)에 기여하는 애들은<br> \(\xi_{i} \gt 0\), 즉 \(\mu_{i} = 0\), 즉 \(\lambda_{i} = \frac{1}{N}\) 이다<br> 따라서 error rate = \(\sum_{i=1}^{N_{error}} \lambda_{i} = \frac{N_{error}}{N} \leq \sum_{i=1}^{N} \lambda_{i} = v\)<br> 즉, error rate \(\frac{N_{error}}{N} \leq v\) 이고<br> total number errors \(N_{error} \leq N v\)</li> <li>Since \(0 \lt \lambda_{i} \lt 1\) for support vector \(i\),<br> \(v = \sum_{i=1}^{N} \lambda_{i} = \sum_{i=1}^{N_{s}} \lambda_{i} \leq \sum_{i=1}^{N_{s}} \frac{1}{N} = \frac{N_{s}}{N}\)<br> 즉, \(vN \leq N_{s}\)<br> (\(\lambda_{i} \gt 0\) 중에 \(\xi = 0\) 인 support vectors만 고려하면 \(\sum_{i=1}^{N} \lambda_{i} = \sum_{i=1}^{N_{s}}\) !!)</li> <li>\(\frac{N_{error}}{N} \leq v \leq \frac{N_{s}}{N}\) 이므로<br> \(v\) optimize하면 error rate와 support vector 개수도 bound 알 수 있음</li> <li>support vector 수 \(N_{s}\) 는 classifier performance에 있어서 매우 중요<br> (\(N_{s}\) 가 클수록 inner product 많이 계산해야 돼서 computational cost 높아짐)<br> (\(N_{s}\) 가 크면 training set 이외의 data에 대한 performance가 제한되어 poor generalization)</li> </ul> </li> </ul> <h3 id="kernel-method-for-svm">Kernel Method for SVM</h3> <ul> <li> <p>discriminant function :<br> \(x\) 의 inner product 꼴<br> \(g(\boldsymbol x) = \boldsymbol w^{T} \boldsymbol x + w_{0} = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} \boldsymbol x_{i}^{T} \boldsymbol x + w_{0}\)</p> </li> <li> <p>Cover’s theorem :<br> non-linearly separable D-dim. space는<br> linearly separable space of high enough dim. 으로 transform 될 수 있다<br> (separating hyperplane의 optimality는 관심사 아님)</p> </li> <li> <p>Kernel Method for SVM :<br> discriminant function \(g(\boldsymbol x) = \boldsymbol w^{T} \boldsymbol x + w_{0} = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} \boldsymbol x_{i}^{T} \boldsymbol x + w_{0}\) 에서<br> kernel \(K(\boldsymbol x_{i}, \boldsymbol x) = \boldsymbol x_{i}^{T} \boldsymbol x\)<br> (inner product b.w. support vector and input vector)<br> 대신<br> 다른 kernel \(K(\boldsymbol x_{i}, \boldsymbol x) = \Phi(\boldsymbol x_{i})^{T} \Phi(\boldsymbol x)\) 을 써서<br> non-linearly separable samples도 분류해보자!</p> <ul> <li>Step 1)<br> input vector \(\boldsymbol x\) 와 training samples \(\boldsymbol x_{i}\) 를 <code class="language-plaintext highlighter-rouge">high-dim.으로 project</code> by function \(\Phi(\cdot)\)</li> <li>Step 2)<br> transformed vector \(\Phi (\boldsymbol x)\) 와 \(\Phi (\boldsymbol x_{i})\) 에 대해 linear SVM 적용<br> \(g(\boldsymbol x) = \boldsymbol w^{T} \Phi (\boldsymbol x) + w_{0}\)</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/4m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/4m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/4m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/4m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Kernel Trick</code> :<br> \(\boldsymbol x_{i}^{T} \boldsymbol x_{j}\) 대신 \(K(\boldsymbol x_{i}, \boldsymbol x_{j}) = \Phi(\boldsymbol x_{i})^{T} \Phi(\boldsymbol x_{j})\) 쓰면 됨!! <ul> <li>optimization of dual form :<br> maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} \boldsymbol x_{i}^{T} \boldsymbol x_{j}\) <br> 대신<br> maximize \(L(\lambda) = \sum_{i=1}^{N} \lambda_{i} - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} K(\boldsymbol x_{i}, \boldsymbol x_{j})\)<br> where \($K(\boldsymbol x_{i}, \boldsymbol x_{j}) = \Phi(\boldsymbol x_{i})^{T} \Phi(\boldsymbol x_{j})\)</li> <li>hyperplane :<br> \(g(\boldsymbol x) = \boldsymbol w^{T} \boldsymbol x + w_{0} = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} \boldsymbol x_{i}^{T} \boldsymbol x + w_{0} = 0\)<br> 대신<br> \(g(\boldsymbol x) = \boldsymbol w^{T} \Phi(\boldsymbol x) + w_{0} = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} \Phi(\boldsymbol x_{i})^{T} \Phi(\boldsymbol x) + w_{0} = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} K(\boldsymbol x_{i}, \boldsymbol x) + w_{0} = 0\)<br> where \(\boldsymbol w = \sum_{i=1}^{N_{s}} \lambda_{i} y_{i} \Phi(\boldsymbol x_{i})\)</li> </ul> </li> <li>Remark : <ul> <li>polynomial learning machine, radial-basis function network, two-layer perceptron(single hidden layer) 와 같은<br> kernel-based learning machine을 만들 때<br> support vector learning algorithm을 사용 <ul> <li>polynomial :<br> \(K(x, z) = (x^{T} z + 1)^{q}\) for \(q \gt 0\)</li> <li>radial-basis function :<br> \(K(x, z) = \text{exp}(-\frac{\| x - z \|^{2}}{\sigma^{2}})\)</li> <li>hyperbolic tangent :<br> \(K(x, z) = \text{tanh}(\beta x^{T} z + \gamma)\) where typical value is \(\beta = 2\) and \(\gamma = 1\)</li> </ul> </li> </ul> </li> <li>문제 풀이 예시 :</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/6m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/6m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/6m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/6m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/5m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/5m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/5m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/5m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/7m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/7m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/7m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/7m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/8m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/8m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/8m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/8m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/9m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/9m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/9m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/9m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="chapter-6-multilayer-neural-networks">Chapter 6. Multilayer Neural Networks</h2> <ul> <li>activation function : <ul> <li>unipolar sigmoid :<br> \(\phi (x) = \frac{1}{1 + exp(-x)}\)<br> \(\phi^{'} (x) = \phi (x) (1 - \phi (x))\)</li> <li>bipolar sigmoid (tanh) :<br> \(\phi (x) = \text{tanh} (x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}\)<br> \(\phi^{'} (x) = 1 - \text{tanh}^{2} (x) = 1 - \phi^{2} (x)\) <ul> <li>tanh가 sigmoid보다 gradient 더 커서 같은 \(\eta\) 일 때 학습 더 많이 함</li> </ul> </li> <li>ReLU</li> </ul> </li> <li>weight initialization : <ul> <li>zero-mean uniform distribution \(U(0, \sigma^{2})\)<br> where \(\sigma^{2}\) is chosen so that std of induced local fields of neurons lie in the linear transition interval of sigmoid activation function</li> </ul> </li> <li>weight update :<br> \(w_{ji}(n+1) = w_{ji}(n) + \eta \delta_{j} (n) y_{i} (n) + \alpha (w_{ji} (n) - w_{ji} (n-1))\)<br> where \(\eta\) : learning rate<br> where \(\alpha\) : momentum constant<br> (momentum in back-prop has stabilizing effect when gradient has oscillate in sign)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/11m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/11m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/11m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/11m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="back-propagation-algorithm">Back-propagation Algorithm</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/10m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/10m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/10m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/10m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="issues-on-neural-networks">Issues on Neural Networks</h3> <ul> <li>Stopping criteria : <ul> <li>Euclidean norm of gradient reaches sufficiently small threshold</li> <li>absolute rate of change in average squared error per epoch is sufficiently small</li> <li>generalization performance (tested after each iter.) has peaked</li> </ul> </li> <li>Weight Update : <ul> <li>sample-by-sample mode :<br> weights are updated after presenting each training sample<br> \(w_{ji}(n+1) = w_{ji}(n) + \eta \delta_{j} (n) y_{i} (n) + \alpha (w_{ji} (n) - w_{ji} (n-1))\) <ul> <li>very sensitive to each sample so that the weight update term is very noisy</li> </ul> </li> <li>batch mode :<br> weights are updated after presenting entire set of training samples<br> \(w_{ji}(t+1) = w_{ji}(t) + \eta \frac{1}{N} \sum_{n=1}^{N} \delta_{j} (n) y_{i} (n) + \alpha (w_{ji} (t) - w_{ji} (t-1))\)</li> </ul> </li> <li>k-fold cross validation :</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/12m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/12m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/12m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/12m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/13m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/13m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/13m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/13m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Normalization : Whitening <ul> <li>mean removal</li> <li>de-correlation</li> <li>scaling for equal covariance<br> (then input var. in training set becomes uncorrelated)<br> (then gradient descent converges faster)</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/14m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/14m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/14m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/14m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Gradient Vanish 해결 방법 : <ul> <li>방법 1) Batch Normalization<br> Batch Normalization을 해서 input이 \(0\) 주위의 가파른 부분에 머무르도록 함<br> 근데 sigmoid의 경우 gradient가 [0, 0.25] 이고, tanh의 경우 gradient가 [0, 1] 이므로<br> 여전히 gradient vanishing 문제 발생</li> <li>방법 2) ReLU activation<br> ReLU의 gradient는 0 또는 1이므로<br> gradient value 1의 경우 gradient vanishing 문제 없음</li> <li>방법 3) Residual Network<br> skip connection 사용하여<br> non-linear activation 통과하지 않고 바로 gradient가 흘러들어갈 수 있도록 함</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/15m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/15m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/15m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/15m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/16m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/16m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/16m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/16m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Bias-Variance dilemma : <ul> <li>prediction error의 종류로는 bias, variance, irreducible error가 있음<br> MSE \(E_{x, y, D}[\epsilon^{2} (x)] = E_{x, y, D}[(h_{D}(x) - y)^{2}]\)<br> \(= E_{x, D}[(h_{D}(x) - \bar h(x))^{2}] + E_{x}[(\bar h(x) - \bar y(x))^{2}] + E_{x, y}[(\bar y(x) - y)^{2}]\) <ul> <li>variance of model : \(E_{x, D}[(h_{D}(x) - \bar h(x))^{2}]\)<br> where \(h_{D}(x)\) : model output<br> where \(\bar h(x)\) : model mean <ul> <li>different test dataset으로 테스트했을 때 변하는 정도</li> <li>particular training dataset에 overfitting된 정도</li> </ul> </li> <li>bias of model : \(\bar h(x) - \bar y(x)\)<br> where \(\bar y(x)\) : label mean <ul> <li>data를 아무리 많이 학습시켜도 model 특성 때문에 발생하는 inherent error<br> e.g. linear classifier is biased to a particular kind of solution</li> </ul> </li> <li>data noise : \(E_{x, y}[(\bar y(x) - y)^{2}]\) <ul> <li>ambiguity due to data distribution and feature representation</li> </ul> </li> </ul> </li> <li>trade-off : <ul> <li>too simple model : high bias<br> \(\rightarrow\) 해결법 : pick more complex model</li> <li>too complex model : high variance<br> \(\rightarrow\) naive 해결법 : use more data, but it requires high cost</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/17m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/17m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/17m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/17m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>SSE (Sum of Squared Errors) :<br> 위의 유도 결과에서<br> 두 번째 term은 model weight와 무관하므로<br> back-propagation은 첫 번째 term만 minimize<br> 즉, \(y_{k}(x; W) \approx P(w_{k} | x)\)<br> 이 때, 잘 approx.하려면 model이 충분한 layers, neurons를 가지고 있어야 함 <ul> <li>\(y_{k}(x; W)\) : model output</li> <li> <table> <tbody> <tr> <td>$$P(w_{k}</td> <td>x)$$ : true posteriori probability (Bayes linear discriminant function)</td> </tr> </tbody> </table> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/18m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/18m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/18m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/18m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="chapter-7-stochastic-methods-for-pattern-classification">Chapter 7. Stochastic Methods for Pattern Classification</h2> <ul> <li>Learning : <ul> <li>deterministic learning :<br> 무조건 loss 작아지는 방향으로 이동<br> e.g. gradient descent</li> <li>stochastic learning :<br> 작은 확률이겠지만 energy 커지는 방향으로 이동하는 것도 허용<br> \(\rightarrow\) local minima에 빠지는 문제 해결하여 global minimum에 도달 가능 e.g. Simulated Annealing, Boltzmann Machine</li> </ul> </li> <li>Boltzmann Machine : <ul> <li>neuron : <ul> <li>visible neuron : \(\alpha = \{ \alpha^{i}, \alpha^{o} \}\)</li> <li>hidden neuron : \(\beta\)</li> </ul> </li> <li>probability \(P(\alpha) = \sum_{\beta} P(\alpha \beta) = \sum_{\beta} \frac{e^{- E_{\alpha \beta} / T}}{Z} = \sum_{\beta} \frac{e^{- E_{\alpha \beta} / T}}{\sum_{\alpha \beta} e^{- E_{\alpha \beta} / T}}\)<br> where energy \(E_{\gamma} = - \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} w_{ij} s_{i} s_{j}\)<br> where \(w_{ij} = w_{ji}\) is symmetric with \(w_{ii} = 0\)<br> 즉, energy \(E_{\gamma}\) 가 낮을수록 configuration \(\alpha\) 일 확률 \(P(\alpha)\) 가 높음</li> <li>goal :<br> \(P(\alpha)\) 가 \(Q(\alpha)\) 와 최대한 가까워지도록<br> weight \(w_{ij}\) 를 학습 <ul> <li>marginal (estimated) distribution of generated samples \(P(\alpha)\) :<br> network가 free-running일 때 (all neurons가 자유롭게 업데이트될 수 있을 때)<br> visible neuron이 \(\alpha\) 일 확률</li> <li>observed (desired) distribution of training samples \(Q(\alpha)\) :<br> network의 visible neuron이 \(\alpha\) 로 clamped되었을 때<br> visible neuron이 \(\alpha\) 일 확률</li> <li>KL-divergence \(D_{KL} (Q(\alpha), P(\alpha)) = \sum_{\alpha} Q(\alpha) \text{log} \frac{Q(\alpha)}{P(\alpha)}\) 를 minimize하면<br> \(\Delta w_{ij} = - \eta \frac{\partial D_{KL}}{\partial w_{ij}} = \eta \sum_{\alpha} \frac{Q(\alpha)}{P(\alpha)} \frac{\partial P(\alpha)}{\partial w_{ij}} = \frac{\eta}{2T}(\sum_{\alpha \beta} Q(\alpha) P(\beta | \alpha) s_{i} s_{j} - \sum_{\alpha^{'} \beta^{'}} P(\alpha^{'} \beta^{'}) s_{i} s_{j}) = \frac{\eta}{2T}(E_{Q}[s_{i} s_{j}]_{\text{clamped by} \alpha} - E[s_{i} s_{j}]_{\text{free}})\)<br> (pf는 아래에)</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/19m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/19m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/19m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/19m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Boltzmann Machine with I-O Association : <ul> <li>neuron : <ul> <li>visible neuron : <ul> <li>input neuron : \(\alpha\)</li> <li>output neuron : \(\gamma\)</li> </ul> </li> <li>hidden neuron : \(\beta\)</li> </ul> </li> <li>goal :<br> \(P(\gamma | \alpha)\) 가 \(Q(\gamma | \alpha)\) 와 최대한 가까워지도록<br> weight \(w_{ij}\) 를 학습 <ul> <li>KL-divergence \(D_{KL} (Q(\gamma | \alpha), P(\gamma | \alpha)) = D_{KL} (Q(\alpha \gamma), P(\alpha \gamma)) - D_{KL} (Q(\alpha), P(\alpha))\) 를 minimize하면<br> \(\Delta w_{ij} = \frac{\eta}{2T}(E_{Q}[s_{i} s_{j}]_{\text{clamped by} \alpha \gamma} - E[s_{i} s_{j}]_{\text{clamped by} \alpha})\)<br> (pf는 아래에)</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/20m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/20m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/20m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/20m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/21m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/21m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/21m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/21m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/22m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/22m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/22m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/22m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Restricted Boltzmann Machine (RBM) :<br> Boltzmann Machine with bi-partite graph of visible and hidden units <ul> <li>probability \(P(v) = \sum_{h} P(v, h) = \sum_{h} \frac{e^{- E(v, h)}}{Z}\)<br> where (intractable) partition function \(Z = \sum_{v, h} e^{- E(v, h)}\)<br> where energy \(E(v, h) = - h^{T} W v - b^{T} v - c^{T} h\) for \(T=1\)</li> <li>goal :<br> training dataset의 distribution을 학습!! <ul> <li>훈련 끝나고나면 해당 distribution을 따르는 new sample을 generate할 수 있음!! image inpainting에도 적용 가능</li> <li>label과의 joint distribution을 학습하여 classification 수행 가능!! feed-forward layer를 initialize할 때 RBM weight 사용 가능</li> <li>feature extractor 역할 수행 가능!!</li> </ul> </li> </ul> </li> <li>Training RBM 수식 유도 : <ul> <li>weight \(\theta = [W, b, c]\) 에 대해<br> \(\hat \theta = \text{argmax}_{\theta} \text{ln} P(v | \theta) = \text{argmax}_{\theta} \text{ln} \sum_{h} \frac{e^{- E(v, h | \theta)}}{Z} = \text{argmax}_{\theta} \text{ln} \sum_{h} e^{- E(v, h | \theta)} - \text{ln} Z\)<br> \(\rightarrow\)<br> \(\frac{\partial - \text{ln} P(v | \theta)}{\partial \theta} = \cdots = \sum_{h} P(h | v, \theta) \frac{\partial E(v, h | \theta)}{\partial \theta} - \sum_{v, h} P(v, h | \theta) \frac{\partial E(v, h | \theta)}{\partial \theta} = E_{h \sim P(h | v, \theta)}[\frac{\partial E(v, h | \theta)}{\partial \theta}] - E_{(v, h) \sim P(v, h | \theta)}[\frac{\partial E(v, h | \theta)}{\partial \theta}]\) <ul> <li>오른쪽 expectation 식 :<br> model distribution \(P(v, h | \theta)\) 의 모든 경우의 수에 대해 expectation \(E[\cdot]\) 계산하려면 \(2^{m+n}\) 로 costly하므로<br> MCMC (Markov chain Monte Carlo) 기법으로 해당 distribution에서 <code class="language-plaintext highlighter-rouge">Gibbs sampling</code> 수행하여<br> 오른쪽 expectation 식을 sample mean으로 approx.</li> </ul> </li> <li>RBM의 경우 visible units끼리, hidden units끼리는 connection 없으므로<br> given visible units에 대해 hidden units끼리는 <code class="language-plaintext highlighter-rouge">conditionally independent</code>하므로<br> 같은 layer에 있는 units는 쉽게 jointly(동시에) Gibbs sampling 가능<br> \(\rightarrow\)<br> <code class="language-plaintext highlighter-rouge">Gibbs sampling</code>은 두 단계로 요약 가능 (block Gibbs sampling) <ul> <li>Step 1)<br> sample \(h\) based on \(P(h | v)\)</li> <li>Step 2)<br> sample \(v\) based on \(P(v | h)\)</li> </ul> </li> <li>Conditional Distribution :<br> proof는 아래 아래 사진에 <ul> <li> \[P(h_{i} = 1 | v) = \sigma (\sum_{j=1}^{m} w_{ij} v_{j} + c_{i}) = \sigma (\boldsymbol w_{i} \cdot \boldsymbol v + c_{i})\] </li> <li> \[P(v_{j} = 1 | h) = \sigma (\sum_{i=1}^{n} w_{ij} h_{i} + b_{j}) = \sigma (\boldsymbol w_{j} \cdot \boldsymbol h + b_{j})\] </li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/27m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/27m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/27m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/27m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/23m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/23m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/23m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/23m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Training RBM 수식 유도 (continued) : <ul> <li>goal :<br> \(P(v | \theta)\) 가 \(Q(v)\) 와 최대한 가까워지도록<br> weight \(W, b, c\) 를 학습 <ul> <li> </li> <li>Gradient of Log-Likelihood :<br> (proof는 아래 사진에)<br> Let’s define<br> \(\boldsymbol h (\boldsymbol v_{0}) = P(\boldsymbol h = \boldsymbol 1 | \boldsymbol v_{0}, \theta) = \sigma(\boldsymbol W \boldsymbol v_{0} + \boldsymbol b)\) <br> \(\boldsymbol v_{0} \in S\) : clamped training sample where \(S\) is training dataset<br> \(\boldsymbol v_{k}\) : generated sample by RBM<br> KL-divergence \(D_{KL} (Q(v), P(v | \theta)) = \sum_{v} Q(v) \text{log} \frac{Q(v)}{P(v | \theta)}\) 를 minimize하려면 <ul> <li> \[\Delta W \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol h (\boldsymbol v_{0}) \boldsymbol v_{0}^{T} - \boldsymbol h (\boldsymbol v_{k}) \boldsymbol v_{k}^{T}\] </li> <li> \[\Delta b \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol v_{0}^{T} - \boldsymbol v_{k}^{T}\] </li> <li> \[\Delta c \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol h (\boldsymbol v_{0}) - \boldsymbol h (\boldsymbol v_{k})\] </li> </ul> </li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/24m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/24m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/24m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/24m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>k-step Contrastive Divergence :<br> model expectation은 exponential cost 가지므로<br> sampling from RBM distribution<br> 대신<br> k-step sampling from Gibbs chain initialized with training data<br> Then, \(\frac{\partial - \text{ln} P(v | \theta)}{\partial \theta} \approx \sum_{h} P(h | v_{0}) \frac{\partial E(v_{0}, h)}{\partial \theta} - \sum_{h} P(h | v_{k}) \frac{\partial E(v_{k}, h)}{\partial \theta}\)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/26m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/26m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/26m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/26m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Training RBM Summary : <ul> <li>Step 1) <code class="language-plaintext highlighter-rouge">Positive Phase</code><br> training sample \(\boldsymbol v_{0}\) 에서 시작하여<br> sample \(h_{i}\) from \(Q(h_{i} = 1 | v_{j}) = \sigma (\boldsymbol w_{i} \cdot \boldsymbol v + c_{i})\)<br> \(\rightarrow\)<br> \(h_{i} = \begin{cases} 1 &amp; \text{if} &amp; \text{rand}(0, 1) \lt Q(h_{i}=1 | v_{j}) \\ 0 &amp; \text{O.W.} &amp; \text{} \end{cases}\)</li> <li>Step 2) <code class="language-plaintext highlighter-rouge">Negative Phase</code> (Recon. Phase)<br> sample \(v_{j}\) from \(P(v_{j} = 1 | h_{i}) = \sigma (\boldsymbol w_{j} \cdot \boldsymbol h + b_{j})\)<br> \(\rightarrow\)<br> \(v_{j} = \begin{cases} 1 &amp; \text{if} &amp; \text{rand}(0, 1) \lt P(v_{j}=1 | h_{i}) \\ 0 &amp; \text{O.W.} &amp; \text{} \end{cases}\)</li> <li>Step 3) 위의 과정을 k-step 반복<br> \(\boldsymbol v_{0}\) 으로부터 \(\boldsymbol h(\boldsymbol v_{0})\) 얻고<br> \(\cdots\) (Gibbs sampling k-step 반복) \(\cdots\)<br> \(\boldsymbol v_{k}\) 으로부터 \(\boldsymbol h(\boldsymbol v_{k})\) 얻음</li> <li>Step 4) <code class="language-plaintext highlighter-rouge">Update Weights</code> <ul> <li> \[\Delta W \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol h (\boldsymbol v_{0}) \boldsymbol v_{0}^{T} - \boldsymbol h (\boldsymbol v_{k}) \boldsymbol v_{k}^{T}\] </li> <li> \[\Delta b \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol v_{0}^{T} - \boldsymbol v_{k}^{T}\] </li> <li> \[\Delta c \propto \frac{1}{N} \sum_{\boldsymbol v_{0} \in S} \boldsymbol h (\boldsymbol v_{0}) - \boldsymbol h (\boldsymbol v_{k})\] </li> </ul> </li> </ul> </li> <li>RBM Code :</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/25m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/25m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/25m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/25m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Example :</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/28m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/28m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/28m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/28m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/29m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/29m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/29m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/29m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="chapter-8-non-metric-methods-for-pattern-classification">Chapter 8. Non-metric Methods for Pattern Classification</h2> <p>training data 전체에 부합하는 parametric boundary 찾는 대신<br> feature space를 여러 tree level에서 sub-regions로 나눠서 classify independently</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/30m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/30m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/30m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/30m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Decision Tree :<br> not unique for partition <ul> <li>probability that \(\boldsymbol x \in u(t)\) has class \(w_{j}\) :<br> \(N(t=5) = 7\), \(N_{1} (t=5) = 2\), \(N_{2} (t=5) = 5\) 에 대해<br> \(P(w_{1} | t=5) = \frac{2}{7}\), \(P(w_{2} | t=5) = \frac{5}{7}\)</li> <li>node impurity and splitting :<br> \(I(t) = \phi (P(w_{1} | t), \cdots, P(w_{c} | t))\) where \(\sum_{i=1}^{c} P(w_{i} | t) = 1\) <ul> <li>maximum, minimum : <ul> <li> <table> <tbody> <tr> <td>$$P(w_{1}</td> <td>t) = \cdots = P(w_{c}</td> <td>t) = \frac{1}{c}$$ 일 때 maximum 값 (가장 impure)</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>$$P(w_{j}</td> <td>t) = 1\(and\)P(w_{i}</td> <td>t) = 0\(for all\)i \neq j$$ 일 때 minimum 값 (가장 pure)</td> </tr> </tbody> </table> </li> </ul> </li> <li>종류 : <ul> <li> <table> <tbody> <tr> <td>Gini criterion : $$I(t) = 1 - \sum_{i} P(w_{i}</td> <td>t)^{2}$$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Entropy : $$I(t) = - \sum_{i} P(w_{i}</td> <td>t) \text{log}<em>{2} P(w</em>{i}</td> <td>t)$$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Classification error : $$I(t) = 1 - \text{max}<em>{i} P(w</em>{i}</td> <td>t) = \frac{N_{minor}(t)}{N(t)}$$</td> </tr> </tbody> </table> </li> </ul> </li> <li>parent node에서 child node로 옮겼을 때 <code class="language-plaintext highlighter-rouge">impurity가 많이 감소할수록 잘 split</code>한 것임<br> 즉, \(\Delta I(t) = I(t) - (I(t_{L}) \frac{N(t_{L})}{N(t)} + I(t_{R}) \frac{N(t_{R})}{N(t)})\) 가 클수록 better split<br> e.g. \(I(t) = 1 - \text{max}_{i} P(w_{i} | t)\) 를 사용할 경우 위의 그림에서 \(\Delta I(t=3) = \frac{3}{13} - (\frac{1}{4} \frac{4}{13} + \frac{0}{9} \frac{9}{13}) = \frac{2}{13}\)</li> <li>terminating splitting : <ul> <li>stopping rule :<br> stop splitting the node if \(\Delta I(t) \lt \tau\)</li> <li>pruning :<br> 일단 (nearly) pure class 될 때까지 tree 늘린 뒤<br> subtree를 terminal node로 대체</li> </ul> </li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/31m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/31m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/31m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/31m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/32m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/32m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/32m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/32m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Pruning Decision Tree : <ul> <li>Let’s define <ul> <li>\(l(t), r(t)\) : node \(t\) 의 left, right child (\(l(t) = r(t) = 0\) for terminal node \(t\))</li> <li>\(\tilde T\) : set of terminal(leaf) nodes of tree \(T\)</li> <li> \[P(t) = \frac{N(t)}{N(t=1)}\] </li> <li> <table> <tbody> <tr> <td>$$P(w_{j}</td> <td>t) = \frac{N_{j}(t)}{N(t)}$$</td> </tr> <tr> <td>where $$\sum_{j=1}^{c} P(w_{j}</td> <td>t) = 1$$</td> </tr> </tbody> </table> </li> <li>\(P_{L}(t) = \frac{P(l(t))}{P(t)} = \frac{N(l(t))}{N(t)}\)<br> \(P_{R}(t) = \frac{P(r(t))}{P(t)} = \frac{N(r(t))}{N(t)}\)<br> where \(P_{L}(t) + P_{R}(t) = 1\)</li> </ul> </li> <li>subtree and pruned subtree : <ul> <li> <code class="language-plaintext highlighter-rouge">subtree</code> : 하나의 node에서 출발해서 its child node들을 가져오는데 양쪽 다 가져와야 함 (위 그림 참고)</li> <li> <code class="language-plaintext highlighter-rouge">pruned subtree</code> \(T_{1} \leq T\) : tree \(T\) 와 root node가 같아야 함 (위 그림 참고)</li> </ul> </li> <li> <table> <tbody> <tr> <td>tree \(T\) has class labels $${ w_{j}(t)</td> <td>t \in \tilde T }\(and disjoint partition\){ u(t)</td> <td>t \in \tilde T }$</td> </tr> </tbody> </table> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/33m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/33m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/33m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/33m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Pruning Algorithm : <ul> <li>Let’s define <ul> <li>misclassification rate at <code class="language-plaintext highlighter-rouge">node</code> \(t\) :<br> \(R(t) = \frac{M(t)}{N(t=1)} = \frac{M(t)}{N(t)} \frac{N(t)}{N(t=1)} = r(t) p(t)\)<br> (node \(t\) 가 <code class="language-plaintext highlighter-rouge">terminal node라고 생각</code>)<br> where \(r(t) = \frac{M(t)}{N(t)}\) : classification error at node \(t\)<br> where \(p(t) = \frac{N(t)}{N(t=1)}\) : frequency at node \(t\)</li> <li>total misclassification rate for <code class="language-plaintext highlighter-rouge">tree</code> \(T\) :<br> \(R(T) = \sum_{t \in \tilde T} R(t) = \frac{1}{N(t=1)} \sum_{t \in \tilde T} M(t)\)<br> (for <code class="language-plaintext highlighter-rouge">all terminal nodes</code> of tree \(T\))</li> <li>cost-complexity at node \(t\) :<br> \(R_{\alpha}(t) = R(t) + \alpha\)</li> <li>cost-complexity for tree \(T\) :<br> \(R_{\alpha}(T) = \sum_{t \in \tilde T} R_{\alpha} (t) = R(T) + \alpha | \tilde T |\)</li> <li>cost-complexity for subtree \(T_{t}\) :<br> \(R_{\alpha}(T_{t}) = \sum_{t \in \tilde T_{t}} R_{\alpha} (t) = R(T_{t}) + \alpha | \tilde T_{t} |\)<br> where \(T_{t}\) : node \(t\) 를 <code class="language-plaintext highlighter-rouge">root node</code>로 하는 subtree</li> <li>\(\alpha = g(t)\) s.t. \(R_{\alpha}(t) = R_{\alpha}(T_{t})\) :<br> \(R_{\alpha}(t) = R_{\alpha}(T_{t})\) 이도록 하는 \(\alpha\)<br> 즉, \(R(t) + \alpha = R(T_{t}) + \alpha | \tilde T_{t} |\) 이도록 하는 \(\alpha\) 즉, \(\alpha = g(t) = \frac{R(t) - R(T_{t})}{| \tilde T_{t} | - 1}\)</li> </ul> </li> <li>Pruning : <ul> <li>\(g(t)\) 가 <code class="language-plaintext highlighter-rouge">최소</code>인 node \(t\) 를 prune!!<br> \(\alpha = g(t) = \frac{R(t) - R(T_{t})}{| \tilde T_{t} | - 1}\) 가 최소라는 말은, <ul> <li>case 1)<br> node \(t\) 가 terminal node이든 (\(R(t)\)), node \(t\) 아래로 children이 있든 (\(R(T_{t})\)) 차이가 크지 않아서 prune해도 ok<br> 즉, \(R(t) - R(T_{t})\) 가 작다</li> <li>case 2)<br> node \(t\) 아래로 children이 너무 많아서 (large \(| \tilde T_{t} |\)) prune하는 게 나음</li> </ul> </li> <li>prune할수록 \(| \tilde T_{t} |\) 가 작아지니까<br> tree는 작아지고<br> cost \(\alpha = g(t)\) 는 커짐</li> <li>test set 또는 cross-validation 이용해서<br> training set에 너무 overfitting된 nodes를 pruning함으로써<br> better generalization</li> </ul> </li> </ul> </li> <li>Pruning Example :</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/34m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/34m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/34m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/34m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/35m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/35m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/35m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/35m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="chapter-9-algorithm-independent-machine-learning">Chapter 9. Algorithm-Independent Machine Learning</h2> <ul> <li>Resampling : <ul> <li>Comparison : <ul> <li>Sampling :<br> select groups within population</li> <li>Resampling :<br> accuracy 높이고 uncertainty of estimate quantify하기 위해<br> reselect new samples, that can provide more info. about population, based on one observed sample<br> and estimate population(distribution) param. multiple times from data</li> </ul> </li> <li>종류 :<br> resampling 기법 중 유명한 건 <ul> <li>jackknife</li> <li>bootstrap</li> </ul> </li> </ul> </li> </ul> <p>How to estimate bias and variance of estimator(statistic)?</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/36m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/36m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/36m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/36m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Jackknife : <ul> <li>bias 줄이기 위해<br> remove samples from available dataset<br> and recalculate the estimator</li> <li>may fail in estimating non-smooth statistic<br> (smooth statistic : small change in data causes small change in statistic)</li> <li>\(i\)-th jackknife sample :<br> \(i\)-th observation 제거<br> \(x_{i} = (x_{1}, \cdots, x_{i-1}, x_{i+1}, \cdots, x_{n})\)</li> <li>estimate again by \(i\)-th jackknife sample :<br> estimate \(\hat \theta_{(i)} = g(x_{i})\) based on \(x_{i}\)</li> <li>\(i\)-th pseudo-sample :<br> \(\tilde \theta_{(i)} = n \hat \theta - (n-1) \hat \theta_{(i)}\)</li> <li>jackknife estimate of bias (\(\hat b_{jack}(\hat \theta)\)) :<br> \(\hat b_{jack}(\hat \theta) = (n-1)(\hat \theta_{(\cdot)} - \hat \theta)\)<br> where \(\hat \theta_{(\cdot)} = \frac{1}{n} \sum_{i=1}^{n} \hat \theta_{(i)}\)</li> <li>bias-corrected jackknife estimate :<br> \(\hat \theta_{jack} = \hat \theta - \hat b_{jack}(\hat \theta) = n \hat \theta - (n-1) \hat \theta_{(\cdot)} = \frac{1}{n} \sum_{i=1}^{n} \tilde \theta_{i}\)<br> Then bias-corrected \(\hat \theta_{jack}\) 은 \(\hat \theta\) 에 비해 bias 작음</li> <li>jackknife estimate of variance (\(\hat v_{jack}(\hat \theta)\)) :<br> \(\hat v_{jack} (\hat \theta) = \hat v (\hat \theta_{jack}) = \frac{s_{jack}^{2}}{n} = \frac{1}{n(n-1)} \sum_{i=1}^{n} (\tilde \theta_{(i)} - \frac{1}{n} \sum_{j=1}^{n} \tilde \theta_{(j)})^{2} = \frac{n-1}{n} \sum_{i=1}^{n} (\hat \theta_{(i)} - \hat \theta_{(\cdot)})^{2} = \frac{(n-1)^{2}}{n} s^{2}\)<br> where \(s_{jack}^{2}\) is sample variance of \(n\) pseudo-samples<br> where \(s\) is sample variance of \(n\) estimates<br> (\(Var(\tilde \theta_{(i)}) \approx Var(\sqrt{n} \hat \theta)\))</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/37m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/37m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/37m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/37m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/38m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/38m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/38m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/38m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Bootstrap : <ul> <li>sampling distribution (\(\neq\) sample distribution) :<br> distribution of estimated statistics from different samples from the same population<br> By central limit theorem, sampling distribution is normal and allows for probabilistic predictions about outcomes <ul> <li>precision : by standard deviation of sampling distribution</li> <li>accuracy : by bias</li> </ul> </li> <li>bootstrap distribution :<br> <code class="language-plaintext highlighter-rouge">population 대신 a sample set itself</code>로부터 <code class="language-plaintext highlighter-rouge">sampling n points with replacement</code> 수행하여 distribution 구함<br> (population으로부터 추가 samples generate하지 않아도 new samples (sampling distribution) 얻는 과정을 모방)</li> <li>estimate by \(b\)-th bootstrap sample : \(\hat \theta^{\ast (b)}\)</li> <li>bootstrap estimate of bias (\(b_{boot} (\hat \theta)\)) :<br> \(b_{boot} (\hat \theta) = \hat \theta^{\ast (\cdot)} - \hat \theta\)<br> where \(\hat \theta^{\ast (\cdot)} = \frac{1}{B} \sum_{b=1}^{B} \hat \theta^{\ast (b)}\)</li> <li>bootstrap estimate of variance (\(Var_{boot} [\hat \theta]\)) :<br> \(Var_{boot} [\hat \theta] = \frac{1}{B} \sum_{b=1}^{B} (\hat \theta^{\ast (b)} - \hat \theta^{\ast (\cdot)})^{2}\)<br> (As \(B \rightarrow \infty\), \(Var_{boot}[\hat \theta] \rightarrow Var[\hat \theta]\))</li> <li>Implementation : Ensemble learning <ul> <li>Step 1)<br> multiple subsets(size \(n\)) are selected with replacement from original dataset(size \(n\))</li> <li>Step 2)<br> A base model is created on each subset</li> <li>Step 3)<br> Each independent model is learned in parallel with each subset</li> <li>Step 4)<br> Final prediction by combining predictions of each model</li> </ul> </li> <li>장단점 : <ul> <li>장점 : <ul> <li>sampling distribution for statistics의 shape, spread, bias 정도를 estimate하기 좋은 방법</li> <li>small samples로도 잘 작동<br> (jackknife는 \(n\) 개의 \(\hat \theta_{(i)}\) 구하려고 반복해야 했음)</li> <li>\(B\) 커질수록 bias, var. 측면에서 더 좋지만 computational load 커짐</li> </ul> </li> <li>단점 : <ul> <li>non-smooth model일 때는 잘 작동 X</li> <li>아래의 경우에는 사용 안 함 <ul> <li>data가 너무 작아서 population value와 가깝지 않을 때</li> <li>data에 outlier가 너무 많을 때</li> <li>dependent data일 때 (e.g. time series data)<br> (bootstrap은 data independence를 가정)</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Ensemble learning에는 Bagging과 Boosting의 two types 있음 <ul> <li>공통점 : <ul> <li>Ensemble learning <ul> <li>to get 1 strong learner from N homogeneous weak learners by averaging or majority voting<br> (each weak learner는<br> one target class에 대해서는 accurately predict하지만,<br> all target classes에 대해서는 not generalized (not optimal) to accurately predict)</li> </ul> </li> </ul> </li> <li>차이점 :<br> individual weak learner의 training phase에 차이가 있음 <ul> <li> <code class="language-plaintext highlighter-rouge">Bagging</code> (= Bootstrap aggregating) :<br> learn from each other independently in parallel, and combine them by averaging or voting <ul> <li>aim to decrease variance (not bias)<br> (overfitting 문제 해소)</li> <li>combine predictions that belong to the same type</li> <li>models combine할 때 equal vote</li> <li>each model is independent</li> <li>different training subsets : random sample from entire training dataset<br> by resampling with replacement</li> <li>classifier가 unstable (e.g. decision tree) (high variance) 하더라도 improve in almost all cases</li> <li>built and trained in parallel</li> <li>e.g. random forest model</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Boosting</code> (Arcing = Adaptive resampling and combining) :<br> learn iteratively and sequentially and adaptively<br> first round에는 training examples를 equal weight로 반영한 뒤<br> round마다 misclassified training examples(by current weak hypothesis) 에 더 많은 weight를 부여하도록 update하여<br> next round에서 weak learner가 hard-to-classify examples에 더 집중하도록 함 <ul> <li>aim to decrease bias (not variance)</li> <li>combine predictions that belong to the different types</li> <li>models combine할 때 weighted vote by their performance (accuracy)</li> <li>new model is influenced by the performance of previous model</li> <li>every new training subset : weighted sample to focus on misclassified examples by previous models (more often chosen)<br> by adaptive resampling 그로써 weak learner can be converted to strong learner</li> <li>classifier가 stable하고 simple할 때 (high bias) 적용</li> <li>built and trained sequentially</li> <li>e.g. AdaBoost</li> </ul> </li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/39m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/39m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/39m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/39m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="chapter-10-unsupervised-learning">Chapter 10. Unsupervised Learning</h2> <ul> <li>unsupervised learning :<br> hard since no answer and no correct accuracy measure to check<br> but, needed since annotating is costly and we often don’t know how many classes there are <ul> <li>parametric unsupervised learning : <ul> <li>sample comes from population that follows fixed param. probability distribution</li> <li>GMM(Gaussian Mixture Model) and EM(Expectation-Maximization)</li> </ul> </li> <li>non-parametric unsupervised learning : <ul> <li>clustering</li> <li>distribution-free, so do not require assumption about population distribution</li> </ul> </li> </ul> </li> <li> <p>K-means clustering :<br> discriminative approach</p> </li> <li>GMM(Gaussian Mixture Model) :<br> generative approach <ul> <li>mixture density :<br> \(p(x_{k} | \theta) = \sum_{j=1}^{c} P(w_{j}) p(x_{k} | w_{j}, \theta_{j})\)<br> where \(\sum_{j=1}^{c} P(w_{j}) = 1\)<br> (gaussian일 경우 \(p(x_k | w_{i}, \theta_{i}) = N(x_k | w_{i}, \mu_{i}, \Sigma_{i}) = (2 \pi)^{-\frac{d}{2}} | \Sigma_{i} |^{-\frac{1}{2}} \text{exp}(-\frac{1}{2}(x_k - \mu_{i})^T \Sigma_{i}^{-1} (x_k - \mu_{i}))\))</li> <li>matrix derivative :<br> \(\frac{d}{dx}(Ax) = A\)<br> \(\frac{d}{dx}(y^TAx) = A^Ty\)<br> \(\frac{d}{dx}(x^TAx) = (A+A^T)x\)<br> \(\frac{d}{dA}(x^TAx) = xx^T\)<br> \(\frac{\partial |A|}{\partial A} = (\text{adj}(A))^T = |A|(A^{-1})^T\)<br> \(\frac{\partial \text{ln}|A|}{\partial A} = (A^{-1})^T = (A^T)^{-1}\) where \(|A| = \frac{1}{|A^{-1}|}\)</li> <li>MLE on \(\theta\) :<br> \(L = \text{ln} p(D | \theta) = \text{ln} \prod_{k=1}^{n} p(x_{k} | \theta) = \sum_{k=1}^{n} \text{ln} p(x_{k} | \theta)\)<br> \(\rightarrow\)<br> data point index \(k\), class index \(i\) 에 대해<br> \(\nabla_{\theta_{i}} L = \cdots = \sum_{k=1}^{n} \gamma_{ki} \nabla_{\theta_{i}} \text{ln} p(x_{k} | w_{i}, \theta_{i}) = 0\)<br> where \(\gamma_{ki} = \frac{p(x_{k} | w_{i}, \theta_{i}) P(w_{i})}{\sum_{j=1}^{c} p(x_{k} | w_{j}, \theta_{j}) P(w_{j})} = \frac{p(x_{k} | w_{i}, \theta_{i}) P(w_{i})}{p(x_{k} | \theta)} = P(w_{i} | x_{k}, \theta_{i})\) : posterior probability (responsibility of mixture component \(i\) for data \(x_{k}\))<br> (data \(x_{k}\) 가 cluster \(i\) 에 속할 확률) <ul> <li>Case 1) unknown \(\theta_{i} = \mu_{i}\) :<br> \(\sum_{k=1}^{n} \gamma_{ki} \nabla_{\mu_{i}} \text{ln} p(x_{k} | w_{i}, \theta_{i}) = 0\)<br> \(\rightarrow\)<br> \(\hat \mu_{i} = \frac{1}{\sum_{k=1}^{n} \gamma_{ki}} \sum_{k=1}^{n} \gamma_{ki} x_{k} = \frac{1}{n_{i}} \sum_{k=1}^{n} \gamma_{ki} x_{k}\) : weighted mean of data points where posterior is weight<br> where \(n_{i} = \sum_{k=1}^{n} \gamma_{ki}\) : effective(expected) number of points assigned to cluster \(i\)</li> <li>Case 2) unknown \(\mu_{i}\) and \(\Sigma_{i}\) :<br> \(\sum_{k=1}^{n} \gamma_{ki} \nabla_{\Sigma_{i}^{-1}} \text{ln} p(x_{k} | w_{i}, \theta_{i}) = 0\)<br> \(\rightarrow\)<br> \(\hat \Sigma_{i} = \frac{1}{\sum_{k=1}^{n} \gamma_{ki}} \sum_{k=1}^{n} \gamma_{ki} (x_{k} - \hat \mu_{i})(x_{k} - \hat \mu_{i})^{T} = \frac{1}{n_{i}} \sum_{k=1}^{n} \gamma_{ki} (x_{k} - \hat \mu_{i})(x_{k} - \hat \mu_{i})^{T}\)</li> <li>Case 3) unknown \(\mu_{i}\) and \(\Sigma_{i}\) and \(P(w_{i})\) :<br> \(\hat P(w_{i}) = \frac{n_{i}}{n}\)<br> (proof는 아래에)<br> (\(P(w_{i})\) 와 \(\gamma_{ki}\) 는 서로 dependent,<br> so, \(\hat \mu_{i}, \hat \Sigma_{i}, \hat P(w_{i})\) 는 no closed-form solution<br> so, need repetitive steps)</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/40m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/40m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/40m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/40m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>EM (Expectation-Maximization) :<br> repeat E-step and M-step until log-likelihood \(L\) converges <ul> <li>E-step :<br> for each data point \(x_{k}\), estimate posterior \(\gamma_{ki}\) and assign \(x_{k}\) to the class \(\text{max}_{i} \gamma_{ki}\)</li> <li>M-step :<br> update parameter \(\hat \theta\)<br> e.g. \(\hat \mu_{i}, \hat \Sigma_{i}, \hat P(w_{i})\)</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-10-28-Pattern2/41m.PNG-480.webp 480w,/assets/img/2024-10-28-Pattern2/41m.PNG-800.webp 800w,/assets/img/2024-10-28-Pattern2/41m.PNG-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-10-28-Pattern2/41m.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="cheet-sheet-for-final-exam">Cheet Sheet for Final Exam</h2> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="semyeong-yu",disqus_identifier="/blog/2024/Pattern2",disqus_title="EE534 Pattern Recognition Final";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>