<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DreamFusion | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="Text-to-3D using 2D Diffusion (ICLR 2023)"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/Dreamfusion/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "DreamFusion",
            "description": "Text-to-3D using 2D Diffusion (ICLR 2023)",
            "published": "August 29, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>DreamFusion</h1> <p>Text-to-3D using 2D Diffusion (ICLR 2023)</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#contribution">Contribution</a> </div> <div> <a href="#overview">Overview</a> </div> <ul> <li> <a href="#random-camera-light-sampling">Random camera, light sampling</a> </li> <li> <a href="#nerf-rendering-with-shading">NeRF Rendering with shading</a> </li> <li> <a href="#diffusion-loss-with-conditioning">Diffusion loss with conditioning</a> </li> <li> <a href="#optimization">Optimization</a> </li> </ul> <div> <a href="#rendering">Rendering</a> </div> <ul> <li> <a href="#structure">Structure</a> </li> <li> <a href="#geometry-regularizer">Geometry Regularizer</a> </li> </ul> <div> <a href="#sds-loss">SDS Loss</a> </div> <div> <a href="#pseudo-code">Pseudo Code</a> </div> <div> <a href="#experiment">Experiment</a> </div> <div> <a href="#limitation">Limitation</a> </div> <div> <a href="#question">Question</a> </div> </nav> </d-contents> <h2 id="dreamfusion-text-to-3d-using-2d-diffusion-iclr-2023">DreamFusion: Text-to-3D using 2D Diffusion (ICLR 2023)</h2> <h4 id="ben-poole-ajay-jain-jonathan-t-barron-ben-mildenhall">Ben Poole, Ajay Jain, Jonathan T. Barron, Ben Mildenhall</h4> <blockquote> <p>paper :<br> <a href="https://arxiv.org/abs/2209.14988" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2209.14988</a><br> project website :<br> <a href="https://dreamfusion3d.github.io/" rel="external nofollow noopener" target="_blank">https://dreamfusion3d.github.io/</a><br> pytorch code :<br> <a href="https://github.com/ashawkey/stable-dreamfusion" rel="external nofollow noopener" target="_blank">https://github.com/ashawkey/stable-dreamfusion</a></p> </blockquote> <h2 id="contribution">Contribution</h2> <ul> <li> <code class="language-plaintext highlighter-rouge">SDS(Score Distillation) Loss</code> 처음 제시</li> <li>NeRF가 Diffusion(Imagen) model이 내놓을 만한 그럴 듯한 image를 합성하도록 함</li> </ul> <h2 id="overview">Overview</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-29-Dreamfusion/1-480.webp 480w,/assets/img/2024-08-29-Dreamfusion/1-800.webp 800w,/assets/img/2024-08-29-Dreamfusion/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-29-Dreamfusion/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Overview <ul> <li>initialize NeRF with random weight</li> <li>for each iter. <ul> <li>camera 위치와 각도, light 위치와 색상을 randomly sampling<br> \(P(camera), P(light)\)</li> <li>NeRF로 image rendering</li> <li>NeRF param. \(\theta\) 와 text embedding \(\tau\) 이용해서 SDS loss 계산</li> <li>update NeRF weight</li> </ul> </li> </ul> </li> </ul> <h3 id="random-camera-light-sampling">Random camera, light sampling</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-29-Dreamfusion/2-480.webp 480w,/assets/img/2024-08-29-Dreamfusion/2-800.webp 800w,/assets/img/2024-08-29-Dreamfusion/2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-29-Dreamfusion/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">camera</code> : <ul> <li>3D model을 <code class="language-plaintext highlighter-rouge">bounded sphere</code> 내부로 제한하고,<br> spherical coordinate(구 표면)에서 camera 위치를 sampling하여<br> 구의 원점을 바라보도록 camera 각도 설정</li> <li>width(64)에 0.7 ~ 1.35의 상수값을 곱하여 focal length 설정</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">light</code> : <ul> <li>camera 위치를 중심으로 한 확률분포로부터 light의 위치를 sampling하고<br> (어떤 확률분포 <code class="language-plaintext highlighter-rouge">????</code>)<br> light 색상도 sampling</li> </ul> </li> </ul> <h3 id="nerf-rendering-with-shading">NeRF Rendering with shading</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-29-Dreamfusion/3-480.webp 480w,/assets/img/2024-08-29-Dreamfusion/3-800.webp 800w,/assets/img/2024-08-29-Dreamfusion/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-29-Dreamfusion/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> albedo : NeRF가 예측한 color </div> <ul> <li>rendering 방법 : <ol> <li>albedo \(\rho\) 만으로 rendering<br> (기존 NeRF와 동일)</li> <li>albedo \(\rho\) 뿐만 아니라 shading하여 rendering</li> <li>albedo \(\rho\) 를 white \((1, 1, 1)\) 로 바꾼 뒤 shading하여 rendering</li> </ol> </li> <li> <code class="language-plaintext highlighter-rouge">Shading</code>의 역할 : <ul> <li>shading 없이 \(\rho\) 만으로 rendering하면<br> 평평한 3D model이 나와도 점수 높게 나옴</li> <li>shading으로 (빛 반사에 따른) shape 정보까지 고려해서 rendering하면<br> <code class="language-plaintext highlighter-rouge">volume 있는</code> 3D model이 되도록 촉구</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">NeRF MLP</code> \(\theta\) : <ul> <li>MLP output : volume density \(\tau\) 와 albedo \(\rho\)</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Normal</code> \(n\) :<br> \(n = - \frac{\nabla_{\mu} \tau}{\| \nabla_{\mu} \tau \|}\)<br> where \(n\) 은 물체 표면의 법선벡터 <ul> <li>normal vector의 방향은<br> volume density \(\tau\) 가 가장 급격하게 변하는 방향, 즉 \(\nabla_{\mu} \tau\) 의<br> 반대 방향</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Shading</code> \(s\) :<br> \(s = (l_p \circ \text{max}(0, n \cdot \frac{l - \mu}{\| l - \mu \|})) + l_a\)<br> where \(l_p\) 는 light 좌표 \(l\) 에서 나오는 light(광원) 색상<br> where \(l_a\) 는 ambient light(환경 조명) 색상<br> where \(\mu\) 는 shading 값을 계산할 surface 위 point 좌표<br> where \(\circ\) 는 element-wise multiplication <ul> <li>\(n \cdot (l - \mu)\) 는 표면에서의 normal vector와 표면에서 광원까지의 vector 간의 내적이며,<br> 이는 Lambertian(diffuse) reflectance(난반사)에 의해 광원의 빛이 반사되는 정도를 나타냄<br> 왜냐하면, 빛이 표면에 수직으로 들어올수록 많이 반사됨</li> <li>만약 빛이 표면 반대쪽에 있어서 내적 값 \(n \cdot (l - \mu)\) 이 음수일 경우<br> 난반사에 의해 광원의 빛이 반사되는 정도는 0</li> <li>\(l_p \circ \text{난반사 정도} + l_a\) 에 의해<br> <code class="language-plaintext highlighter-rouge">광원</code>의 색상 \(l_p\) 는 물체 <code class="language-plaintext highlighter-rouge">표면의 난반사 정도에 따라</code> 반영되고<br> <code class="language-plaintext highlighter-rouge">환경 조명</code>의 색상 \(l_a\) 는 물체의 <code class="language-plaintext highlighter-rouge">모든 표면에 일정하게</code> 반영됨</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">Color</code> \(c\) :<br> \(c = \rho \circ s\) 또는 \(c = \rho\)</li> </ul> <h3 id="diffusion-loss-with-conditioning">Diffusion loss with conditioning</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-29-Dreamfusion/5-480.webp 480w,/assets/img/2024-08-29-Dreamfusion/5-800.webp 800w,/assets/img/2024-08-29-Dreamfusion/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-29-Dreamfusion/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <code class="language-plaintext highlighter-rouge">Latent Diffusion</code> model : <ul> <li>image \(x\) 가 아니라 encoder를 거친 image latent vector \(z, \ldots z_T\) 에 대해 noising, denoising 수행</li> <li>noisy \(z_T\) 와 text embedding vector \(\tau_{\theta}\) (conditioning)을 concat한 뒤<br> denoising하여 input image와 유사한 확률 분포를 갖도록 학습</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-29-Dreamfusion/4-480.webp 480w,/assets/img/2024-08-29-Dreamfusion/4-800.webp 800w,/assets/img/2024-08-29-Dreamfusion/4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-29-Dreamfusion/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>text embedding vector \(\tau_{\theta}\) :<br> T5-XXL text embedding을 거치기 전에<br> text prompt engineering 수행 <ul> <li>Elevation angle(고각)이 60도 이상일 때 “overhead view”</li> <li>azimuth angle(방위각)에 따라 “front view”, “side view”, “back view”</li> <li>Imagen을 잘 쓰기 위한 text prompt engineering이 투박하긴 하네?</li> </ul> </li> </ul> <h3 id="optimization">Optimization</h3> <ul> <li>실험적인 implementation : <ul> <li>noise level sampling \(t\) :<br> \(z_t, t \sim U[0, 1]\) 에서 noise level이 너무 크거나(\(t=1\)) 너무 작을 경우(\(t=0\)) instability 생기므로<br> noise level을 \(t \sim U[0.02, 0.98]\) 로 sampling</li> <li>guidance weight \(w\) :<br> Imagen이 NeRF에 얼만큼 영향을 미칠지(guide할지)<br> high-quality 3D model을 학습하기 위해서는<br> classifier-free guidance weight \(w\) 를 큰 값(100)으로 설정<br> (NeRF MLP output color가 sigmoid에 의해 [0, 1]로 bounded되어있으므로 constrained optimization 문제라서 guidance weight 커도 딱히 artifacts 없음)</li> <li>seed :<br> noise level이 높을 때 smoothed density는 distinct modes를 많이 가지지 않고<br> SDS Loss는 mode-seeking property를 가지고 있으므로<br> random seed 바꿔도 실험 결과는 큰 차이 없음</li> </ul> </li> <li>implementation : <ul> <li>train : TPUv4, 15000 iter., 1.5h with Distributed Shampoo optimizer</li> <li>rendering : 각 cpu는 개별 view를 rendering하는데 사용</li> </ul> </li> </ul> <h2 id="rendering">Rendering</h2> <h3 id="structure">Structure</h3> <p>TBD</p> <h3 id="geometry-regularizer">Geometry Regularizer</h3> <p>TBD</p> <h2 id="sds-loss">SDS Loss</h2> <p>TBD</p> <p>mode-seeking property</p> <h2 id="pseudo-code">Pseudo Code</h2> <p>TBD</p> <h2 id="experiment">Experiment</h2> <p>TBD</p> <h2 id="limitation">Limitation</h2> <p>TBD</p> <h2 id="question">Question</h2> <p>TBD</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="semyeong-yu",disqus_identifier="/blog/2024/Dreamfusion",disqus_title="DreamFusion";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>