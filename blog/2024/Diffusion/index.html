<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Diffusion-DDPM | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="Diffusion Study"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/Diffusion/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Diffusion-DDPM",
            "description": "Diffusion Study",
            "published": "June 25, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Diffusion-DDPM</h1> <p>Diffusion Study</p> </d-title> <d-article> <h2 id="diffusion">Diffusion</h2> <h3 id="diffusion-model">Diffusion Model</h3> <ul> <li>forward process : <code class="language-plaintext highlighter-rouge">fixed</code> Gaussian noise 더함</li> <li>reverse process : <code class="language-plaintext highlighter-rouge">learned</code> Gaussian noise 뺌 (mean, std를 학습)</li> </ul> <h3 id="likelihood">Likelihood</h3> <p>아래 둘 다 관측값 \(x\)가 나올 확률인데,</p> <ul> <li> <code class="language-plaintext highlighter-rouge">probability</code> \(P(x | \theta)\) : <code class="language-plaintext highlighter-rouge">확률 분포가 고정</code>된 상태에서, <code class="language-plaintext highlighter-rouge">관측되는 사건이 변화</code>할 때의 확률<br> 예: 선택 가능한 정수를 1~5로 제한(확률 분포 고정)했을 때, 관측 목표값이 1~5 중 한 개의 숫자(관측 사건 변화)일 경우</li> <li> <code class="language-plaintext highlighter-rouge">likelihood</code> \(L(\theta | x)\) : <code class="language-plaintext highlighter-rouge">관측된 사건이 고정</code>된 상태에서, <code class="language-plaintext highlighter-rouge">확률 분포 몰라서 가정</code>할 때의 확률<br> 예: 선택 가능한 정수를 1~5가 아니라 1~10 또는 4~50으로 바꾸면서(확률 분포 모름), 2가 관측될 확률을 계산(관측 사건 고정)할 경우<br> 예: 어떤(모르는) 확률 분포를 따르는 task를 n회 반복 수행하여 관측했을 때 random var. 종류를 가정할 수도 있고 특정 random var.의 parameter를 가정할 수도 있다</li> </ul> <h3 id="markov-process">Markov process</h3> <ul> <li> <code class="language-plaintext highlighter-rouge">Markov</code> process (= Markov chain = <code class="language-plaintext highlighter-rouge">memoryless</code> process) : Markov property를 가지는 discrete stochastic process<br> \(P[s_{t+1}|s_t] = P[s_{t+1}|s_1, \ldots, s_t]\)</li> </ul> <h3 id="kl-divergence">KL-divergence</h3> <ul> <li>\(H(p, q) = - \sum p_i log q_i\) : 두 확률분포 p, q의 cross entropy<br> (보통 \(p\)는 GT, \(q\)는 predicted)</li> <li>\(H(p) = - \sum p_i log p_i\) : p’s entropy (상수값)</li> <li>\(KL(p \| q) = H(p, q) - H(p) = \sum p_i log \frac{p_i}{q_i}\) : 두 확률분포 p, q의 차이<br> \(H(p)\)는 상수값이므로 <code class="language-plaintext highlighter-rouge">KL-divergence minimize = cross entropy minimize</code> </li> <li>모르는 분포 \(p(x)\)를 N개 sampling하여 trained \(q(x | \theta)\)로 근사하고자 할 때,<br> \(KL(p \| q) \simeq \frac{1}{N} \sum_{n=1}^{N} {-log q(x_n | \theta) + log p(x_n)}\) :<br> \(log p(x_n)\)은 \(\theta\)에 독립이므로 <code class="language-plaintext highlighter-rouge">KL-divergence minimize = negative log likelihood minimize = MLE</code> </li> </ul> <p>KL-diverence 특성 :</p> <ol> <li>\(KL(p \| q) \geq 0\) : 확률분포 p = q일 때 최소</li> <li>\(KL(p \| q) \neq KL(q \| p)\) (asymmetric) : 거리 개념이 아님<br> 거리 개념으로 쓰는 방법 : 2가지 KL-divergence를 평균내는 방식의 \(JSD(p \| q)\)</li> </ol> <h3 id="diffusion-algorithm">Diffusion Algorithm</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-25-Diffusion/1-480.webp 480w,/assets/img/2024-06-25-Diffusion/1-800.webp 800w,/assets/img/2024-06-25-Diffusion/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-06-25-Diffusion/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>forward process (\(q\)) :<br> \(q(X_t | X_{t-1}) = N(X_t ; \mu_{X_{t-1}}, \Sigma_{X_{t-1}}) = N(X_t ; \sqrt{1-\beta_t} \cdot X_{t-1}, \beta_t \cdot I)\)<br> where \(\beta_t\) : noise 주입 정도 (상수값)<br> t가 증가할수록 \(\beta_t\)가 증가하여 다른 pixel(\(I\))을 선택하므로 noise가 강해진다</p> </li> <li> <p>backward process (\(p_{\theta}\)) :<br> image prior \(q(X_t)\)를 모르기 때문에 \(q(X_{t-1} | X_t)\)를 계산할 수 없으므로<br> 목표 : \(q(X_{t-1} | X_t)\)를 근사하는 \(p_{\theta}(X_{t-1} | X_t)\) 학습<br> 즉, 확률분포 \(q\)에서 관측한 값 \(x\)로 \(p_{\theta | x}\)의 likelihood를 구했을 때 그 값이 최대가 되도록 하는 <code class="language-plaintext highlighter-rouge">MLE Problem</code><br> 즉, minimize \(E_q [- log p_{\theta} (x_0)]\)</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Diffusion Model</code> Naive Loss 수식 :<br> 확률분포 \(q\)로 sampling했을 때,<br> \(E_q [D_{KL}(q(x_T | x_0) \| p_{\theta} (x_T)) + \sum_{t \gt 1} D_{KL}(q(x_{t-1} | x_t, x_0) \| p_{\theta} (x_{t-1} | x_t)) - log p_{\theta} (x_0 | x_1)]\)</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">DDPM</code>(Denoising Diffusion Probabilistic Model)(2020) Loss 수식 :<br> \(E_{t, x_0, \epsilon} [\| \epsilon - \epsilon_{\theta}(\sqrt{\bar \alpha_{t}}x_0 + \sqrt{1-\bar \alpha_{t}} \epsilon, t) \|^{2}]\)<br> where \(\epsilon \sim N(0, I)\)<br> 즉, \(\epsilon_{\theta}\)가 Standard Gaussian 분포 \(\epsilon\)를 따르도록!</p> </li> </ul> <p>이 때, \(\epsilon_{\theta}\)의 input은 \(q(x_t | x_0)\)와 \(t\) !!<br> \(q(X_t | X_{t-1}) = N(X_t ; \mu_{X_{t-1}}, \Sigma_{X_{t-1}}) = N(X_t ; \sqrt{1-\beta_t} \cdot X_{t-1}, \beta_t \cdot I)\)<br> \(\rightarrow q(x_t | x_0) = N(x_t; \sqrt{\bar \alpha_{t}}x_0, \sqrt{1-\bar \alpha_{t}} I) = \sqrt{\bar \alpha_{t}}x_0 + \sqrt{1-\bar \alpha_{t}} \epsilon\)<br> where \(\alpha_t = 1 - \beta_t\) and \(\bar \alpha_t = \prod_{s=1}^t \alpha_s\) and \(\epsilon \sim N(0, I)\)<br> (위의 수식 유도과정은 아래에서 다룰 예정)</p> <h3 id="diffusion-model-및-ddpm-loss-수식-유도">Diffusion Model 및 DDPM Loss 수식 유도</h3> <blockquote> <p>Step 1. ELBO (<code class="language-plaintext highlighter-rouge">Evidence Lower Bound</code>) 꼴로 변환</p> </blockquote> <p>\(log p_{\theta}(x_0)\)<br> \(= E_{x_T \sim q(x_T|x_0)}[log p_{\theta}(x_0)]\)<br> \(= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{p_{\theta}(x_{0:T})}{p_{\theta}(x_{1:T}|x_0)}]\)<br> \(= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}] + E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{1:T}|x_0)}] \cdots (\ast)\)<br> (\(p_{\theta}(x_{1:T}|x_0)\)은 <code class="language-plaintext highlighter-rouge">intractable</code>하므로 KL divergence 항에 넣어서 제거!)</p> <p>마지막 식의 오른쪽 항은 아래와 같이 <code class="language-plaintext highlighter-rouge">KL divergence</code> 꼴이다.<br> \(E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{1:T}|x_0)}] = \sum q(x_{1:T}|x_0) log \frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{1:T}|x_0)} = D_{KL}(q(x_{1:T}|x_0) \| p_{\theta}(x_{1:T}|x_0))\)<br> \(q(x_{1:T}|x_0)\)는 계산할 수 있지만 \(p_{\theta}(x_{1:T}|x_0)\)는 계산할 수 없으므로 KL divergence의 특성 \(KL(p \| q) \geq 0\)을 이용하면<br> \((\ast)\) 으로부터<br> \(log p_{\theta}(x_0) \geq E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}]\)<br> 즉, \(E_{x_T \sim q(x_T|x_0)}[- log p_{\theta}(x_0)] \leq E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}]\)</p> <blockquote> <p>Step 2. <code class="language-plaintext highlighter-rouge">Markov property</code> 이용하여 <code class="language-plaintext highlighter-rouge">Diffusion Loss</code> 유도</p> </blockquote> \[E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{0:T})}]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{\prod_{t=1}^{T} q(x_t|x_{t-1})}{p_{\theta}(x_T) \prod_{t=1}^T p_{\theta}(x_{t-1}|x_t)}]\] <p>by memoryless <code class="language-plaintext highlighter-rouge">Markov chain property</code></p> \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log p_{\theta}(x_T) + \sum_{t=1}^{T} log \frac{q(x_t|x_{t-1})}{p_{\theta}(x_{t-1}|x_t)}]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log p_{\theta}(x_T) + \sum_{t=2}^{T} log \frac{q(x_t|x_{t-1})}{p_{\theta}(x_{t-1}|x_t)} + log \frac{q(x_1|x_0)}{p_{\theta}(x_0|x_1)}]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log p_{\theta}(x_T) + \sum_{t=2}^{T} log \frac{q(x_t|x_{t-1}, x_0)}{p_{\theta}(x_{t-1}|x_t)} + log \frac{q(x_1|x_0)}{p_{\theta}(x_0|x_1)}]\] <p>by memoryless <code class="language-plaintext highlighter-rouge">Markov property</code><br> <code class="language-plaintext highlighter-rouge">tractable</code>하도록 만들기 위해 \(q(x_t|x_{t-1})\) 의 조건부에 \(x_0\) 추가</p> \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log p_{\theta}(x_T) + \sum_{t=2}^{T} log (\frac{q(x_{t-1}|x_t, x_0)}{p_{\theta}(x_{t-1}|x_t)} \cdot \frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}) + log \frac{q(x_1|x_0)}{p_{\theta}(x_0|x_1)}]\] <p>by <code class="language-plaintext highlighter-rouge">Bayes</code> 정리<br> \(P(A|B \bigcap C) = \frac{P(B|A \bigcap C) \cdot P(A|C)}{P(B|C)}\)</p> <p>\(= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[- log p_{\theta}(x_T) + \sum_{t=2}^{T} log \frac{q(x_{t-1}|x_t, x_0)}{p_{\theta}(x_{t-1}|x_t)} + log \frac{q(x_T|x_0)}{q(x_1|x_0)} + log \frac{q(x_1|x_0)}{p_{\theta}(x_0|x_1)}]\)<br> by log 곱셈으로 소거</p> \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[log \frac{q(x_T|x_0)}{p_{\theta}(x_T)} + \sum_{t=2}^{T} log \frac{q(x_{t-1}|x_t, x_0)}{p_{\theta}(x_{t-1}|x_t)} - log p_{\theta}(x_0|x_1)]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[D_{KL}(q(x_T|x_0) \| p_{\theta}(x_T)) + \sum_{t=2}^{T} D_{KL}(q(x_{t-1}|x_t, x_0) \| p_{\theta}(x_{t-1}|x_t)) - log p_{\theta}(x_0|x_1)]\] <p>by <code class="language-plaintext highlighter-rouge">KL divergence</code> 식 \(D_{KL}(P \| Q) = \sum P(x) log (\frac{P(x)}{Q(x)})\)</p> <blockquote> <p>Step 3. <code class="language-plaintext highlighter-rouge">DDPM Loss</code> 유도</p> </blockquote> <ol> <li> <p>\(L_T = D_{KL}(q(x_T | x_0) \| p(x_T))\) : <code class="language-plaintext highlighter-rouge">regularization</code> loss<br> <code class="language-plaintext highlighter-rouge">마지막 상태</code> \(x_T\)에서 확률분포 q, p의 차이를 최소화<br> noise 주입 정도인 \(\beta_t\)는 미리 정해둔 schedule에 따른 상수값(fixed)이므로<br> \(q(x_T | x_0)\)는 training과 관계없이 \(x_T\)가 항상 Gaussian 분포를 따르도록 한다.<br> \(x_T\)가 <code class="language-plaintext highlighter-rouge">Gaussian 분포</code>를 따르므로 \(q(x_T | x_0)\)와 \(p(x_T)\)는 거의 유사하고,<br> 결과적으로 둘의 KL divergence인 \(L_T\)는 항상 0에 가까운 값을 가지므로 training에서 \(L_T\) term은 <code class="language-plaintext highlighter-rouge">제외</code></p> </li> <li> <p>\(L_{t-1} = D_{KL}(q(x_{t-1} | x_t, x_0) \| p(x_{t-1} | x_t))\) : <code class="language-plaintext highlighter-rouge">denoising process</code> loss<br> <code class="language-plaintext highlighter-rouge">현재 상태</code> \(x_t\)가 주어질 때 <code class="language-plaintext highlighter-rouge">이전 상태</code> \(x_{t-1}\)가 나올 확률 분포 q, p의 차이를 최소화</p> </li> <li> <p>\(L_0 = - log p_{\theta} (x_0 | x_1)\) : <code class="language-plaintext highlighter-rouge">reconstruction</code> loss<br> q를 sampling했을 때 \(p_{\theta} (x_0 | x_1)\)를 최대화하여 (MLE) 확률분포 q, p의 차이를 최소화<br> 전체적으로 봤을 때 \(L_0\)는 무수히 많은 time step \(T \sim 1000\) 중 단일 시점에서의 log likelihood 값이므로<br> <code class="language-plaintext highlighter-rouge">값이 너무 작아서</code> training에서 \(L_0\) term은 <code class="language-plaintext highlighter-rouge">제외</code></p> </li> </ol> <p>Let’s only minimize the second term<br> \(E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\sum_{t=2}^{T} L_{t-1}] = E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\sum_{t=2}^{T} D_{KL}(q(x_{t-1} | x_t, x_0) \| p(x_{t-1} | x_t))]\)</p> <blockquote> <p>Step 4. Gaussian param. \(\mu, \sigma\)로 KL-divergence 나타내기</p> </blockquote> <ul> <li> <p><code class="language-plaintext highlighter-rouge">Gaussian Integral</code> :<br> \(\int_{-\infty}^{\infty} e^{-x^2}dx = \sqrt{\pi}\) and \(\int_{-\infty}^{\infty} x^2 e^{-ax^2}dx = \frac{1}{2}\sqrt{\pi}a^{-\frac{3}{2}}\)</p> </li> <li> <p>Integral of \(p(x)logp(x)\) for Gaussian \(p(x)\) :<br> For \(p(x) = \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-\frac{(x-\mu_{1})^2}{2 \sigma_{1}^2}} \sim N(\mu_{1}, \sigma_{1})\),<br> \(\int p(x) log p(x) dx\)<br> \(= \int \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-\frac{(x-\mu_{1})^2}{2 \sigma_{1}^2}} log (\frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-\frac{(x-\mu_{1})^2}{2 \sigma_{1}^2}}) dx\)<br> \(= \int \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-t^2} (log \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} - t^2) \sqrt{2} \sigma_{1} dt\)<br> by 치환 \(t = \frac{x-\mu_{1}}{\sqrt{2}\sigma_{1}}\)<br> \(= \frac{1}{\sqrt{\pi}} \int e^{-t^2} (log \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} - t^2) dt\)<br> \(= - \frac{log(2\pi \sigma_{1}^{2})}{2 \sqrt{\pi}} \int e^{-t^2} dt - \frac{1}{\sqrt{\pi}} \int t^2 e^{-t^2} dt\)<br> \(= - \frac{log(2\pi \sigma_{1}^{2})}{2 \sqrt{\pi}} \cdot \sqrt{\pi} - \frac{1}{\sqrt{\pi}} \cdot \frac{\sqrt{\pi}}{2}\) by <code class="language-plaintext highlighter-rouge">Gaussian integral</code><br> \(= - \frac{log(2\pi \sigma_{1}^{2})}{2} - \frac{1}{2}\)<br> \(= - \frac{1}{2} (1 + log(2\pi \sigma_{1}^{2}))\)</p> </li> <li> <p>Integral of \(p(x)logq(x)\) for Gaussian \(p(x)\) and \(q(x)\) :<br> For \(p(x) = \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-\frac{(x-\mu_{1})^2}{2 \sigma_{1}^2}} \sim N(\mu_{1}, \sigma_{1})\)<br> and \(q(x) = \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} e^{-\frac{(x-\mu_{2})^2}{2 \sigma_{2}^2}} \sim N(\mu_{2}, \sigma_{2})\),<br> \(\int p(x) log q(x) dx\)<br> \(= \int p(x) log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} e^{-\frac{(x-\mu_{2})^2}{2 \sigma_{2}^2}} dx\)<br> \(= \int p(x) log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} dx - \int p(x) \frac{(x-\mu_{2})^2}{2 \sigma_{2}^2} dx\)<br> \(= log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} - \int p(x) \frac{(x-\mu_{2})^2}{2 \sigma_{2}^2} dx\)<br> \(= log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} - \frac{\int p(x) x^2 dx - \int 2 \mu_{2} x p(x) dx + \mu_{2}^2 \int p(x) dx}{2 \sigma_{2}^2}\)<br> \(= log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} - \frac{E_{1}(x^2) - 2 \mu_{2} E_{1}(x) + \mu_{2}^2}{2 \sigma_{2}^2}\)<br> \(= log \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} - \frac{\sigma_{1}^2 + \mu_{1}^2 - 2 \mu_{2} \mu_{1} + \mu_{2}^2}{2 \sigma_{2}^2}\)<br> by \(Var(X) = E[X^2] - (E[X])^2\)<br> \(= - \frac{1}{2} log (2 \pi \sigma_{2}^{2}) - \frac{\sigma_{1}^2 + (\mu_{1} - \mu_{2})^2}{2 \sigma_{2}^2}\)</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">KL divergence</code> for Gaussian \(p(x)\) and \(q(x)\) :<br> For \(p(x) = \frac{1}{\sqrt{2 \pi \sigma_{1}^{2}}} e^{-\frac{(x-\mu_{1})^2}{2 \sigma_{1}^2}} \sim N(\mu_{1}, \sigma_{1})\)<br> and \(q(x) = \frac{1}{\sqrt{2 \pi \sigma_{2}^{2}}} e^{-\frac{(x-\mu_{2})^2}{2 \sigma_{2}^2}} \sim N(\mu_{2}, \sigma_{2})\),<br> \(D_{KL}(p \| q)\)<br> \(= \int p(x) log \frac{p(x)}{q(x)} dx\)<br> \(= \int p(x) logp(x) dx - \int p(x) log q(x)dx\)<br> \(= - \frac{1}{2} (1 + log(2\pi \sigma_{1}^{2})) - (- \frac{1}{2} log (2 \pi \sigma_{2}^{2}) - \frac{\sigma_{1}^2 + (\mu_{1} - \mu_{2})^2}{2 \sigma_{2}^2})\)<br> \(= - \frac{1}{2} + \frac{1}{2} log (\frac{2 \pi \sigma_{2}^2}{2 \pi \sigma_{1}^2}) + \frac{\sigma_{1}^2 + (\mu_{1} - \mu_{2})^2}{2 \sigma_{2}^2}\)<br> \(= - \frac{1}{2} + log (\frac{\sigma_{2}}{\sigma_{1}}) + \frac{\sigma_{1}^2 + (\mu_{1} - \mu_{2})^2}{2 \sigma_{2}^2}\)</p> </li> </ul> <blockquote> <p>Step 5. Only Minimize the second term in Diffusion Loss</p> </blockquote> \[E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\sum_{t=2}^{T} L_{t-1}]\] \[= E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\sum_{t=2}^{T} D_{KL}(q(x_{t-1} | x_t, x_0) \| p(x_{t-1} | x_t))]\] <p>Let \(\sigma\) <code class="language-plaintext highlighter-rouge">std have no learning param. (상수값)</code><br> Let \(q(x_{t-1} | x_t, x_0)\) have Gaussian mean \(\tilde \mu_{t}\)<br> Let \(p_{\theta}(x_{t-1} | x_t)\) have Gaussian mean \(\mu_{\theta}\)</p> <p>By Step 4., since \(\sigma\) is fixed, we have to minimize</p> \[E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\frac{1}{2 \sigma_{t}^2} \| \tilde \mu_{t} (x_t, x_0) - \mu_{\theta} (x_t, t) \|^2] + C\] <p>Now we have to know \(\tilde \mu_{t}\) and \(\mu_{\theta}\)</p> <blockquote> <table> <tbody> <tr> <td>Step 6. Obtain $$q(x_t</td> <td>x_0)\(from\)q(x_t</td> <td>x_{t-1})$$</td> </tr> </tbody> </table> </blockquote> <ol> <li> <p>Let’s define \(q(x_t | x_{t-1}) = N(x_t ; \sqrt{1-\beta_{t}} \cdot x_{t-1}, \beta_{t} \cdot \boldsymbol I)\)<br> where noise 주입 비율인 \(\beta_{t}\)는 t에 따라 증가하는 상수값이고,<br> noise 주입 비율이 커질수록 분산이 커지는 건 reasonable</p> </li> <li> <p>Let’s define \(\alpha_{t} = 1 - \beta_{t}\) and \(\bar \alpha_{t} = \prod_{s=1}^t \alpha_{s}\)<br> where \(\bar \alpha_{t}\)는 \(s=1\)부터 \(s=t\)까지 \(\alpha_{s} = 1 - \beta_{s}\)의 누적곱</p> </li> </ol> <p>When \(\epsilon_{t-1}, \epsilon_{t-2}, \cdots, \epsilon_0 \sim N(0, I)\),<br> \(x_t = \mu + \sigma \cdot \epsilon = \sqrt{\alpha_{t}} x_{t-1} + \sqrt{1-\alpha_{t}} \cdot \epsilon_{t-1}\)<br> \(\cdots\)<br> \(x_t = \sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \cdot \epsilon\)<br> where \(\epsilon \sim N(0, I)\)<br> by merging two Gaussians \(N(0, \sigma_{1}^2 I), N(0, \sigma_{2}^2 I) \rightarrow N(0, (\sigma_{1}^2 + \sigma_{2}^2) I)\)</p> <p>Therefore,<br> \(q(x_t | x_0) = N(x_t; \sqrt{\bar \alpha_{t}} x_{0}, (1-\bar \alpha_{t}) \boldsymbol I)\)</p> <table> <tbody> <tr> <td>즉, 우리가 정의한 Gaussian $$q(x_t</td> <td>x_{t-1})\(으로부터 Gaussian\)q(x_t</td> <td>x_0)$$ 를 얻어냈다!</td> </tr> </tbody> </table> <blockquote> <p>Step 7. Obtain \(q(x_{t-1} \| x_t, x_0)\)</p> </blockquote> <p>Remind that</p> <ol> <li> \[q(x_t | x_{t-1}, x_0) = q(x_t | x_{t-1}) = N(x_t ; \sqrt{\alpha_{t}} \cdot x_{t-1}, \beta_{t} \cdot \boldsymbol I)\] </li> <li> \[q(x_t | x_0) = N(x_t; \sqrt{\bar \alpha_{t}} x_{0}, (1-\bar \alpha_{t}) \boldsymbol I)\] </li> </ol> <p>\(q(x_{t-1} | x_t, x_0)\)<br> \(= q(x_t | x_{t-1}, x_0) \frac{q(x_{t-1} | x_0)}{q(x_t | x_0)}\)<br> \(\propto \exp (- \frac{(x_t - \sqrt{\alpha_{t}} x_{t-1})^2}{2 \beta_{t}} - \frac{(x_{t-1} - \sqrt{\bar \alpha_{t-1}} x_{0})^2}{2 (1-\bar \alpha_{t-1})} + \frac{(x_{t} - \sqrt{\bar \alpha_{t}} x_{0})^2}{2 (1-\bar \alpha_{t})})\)<br> \(= \exp (- \frac{1}{2} ((\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar \alpha_{t-1}})x_{t-1}^2 - (\frac{2 \sqrt{\alpha_t}}{\beta_{t}} x_t + \frac{2\sqrt{\bar \alpha_{t-1}}}{1 - \bar \alpha_{t-1}} x_0) x_{t-1} + C(x_t, x_0)))\)</p> <p>\(q(x_{t-1} | x_t, x_0)\) 또한 Gaussian이라서<br> \(\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}\) 꼴이므로<br> \(q(x_{t-1} | x_t, x_0)\)의 지수부분을 \(x_{t-1}\)에 대한 이차식 꼴로 정리하면<br> 계수 비교를 통해 \(q(x_{t-1} | x_t, x_0)\)의 mean, variance를 알 수 있음!</p> <ul> <li>\(q(x_{t-1} | x_t, x_0)\) 의 variance :<br> \(\frac{1}{\sigma^{2}}\)<br> \(= \frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar \alpha_{t-1}}\)<br> \(= \frac{\alpha_{t} - \alpha_{t} \bar \alpha_{t-1} + \beta_{t}}{\beta_{t}(1 - \bar \alpha_{t-1})}\)<br> \(= \frac{\alpha_{t} - \bar \alpha_{t} + 1 - \alpha_{t}}{\beta_{t}(1 - \bar \alpha_{t-1})}\)<br> \(= \frac{1 - \bar \alpha_{t}}{\beta_{t}(1 - \bar \alpha_{t-1})}\)</li> </ul> <p>따라서 \(\sigma^{2} = \frac{1 - \bar \alpha_{t-1}}{1 - \bar \alpha_{t}} \beta_{t}\)</p> <ul> <li>\(q(x_{t-1} | x_t, x_0)\) 의 mean :<br> \(- \frac{2 \mu}{\sigma^{2}}\)<br> \(= - (\frac{2 \sqrt{\alpha_t}}{\beta_{t}} x_t + \frac{2\sqrt{\bar \alpha_{t-1}}}{1 - \bar \alpha_{t-1}} x_0)\)<br> \(\rightarrow \mu = (\frac{\sqrt{\alpha_t}}{\beta_{t}} x_t + \frac{\sqrt{\bar \alpha_{t-1}}}{1 - \bar \alpha_{t-1}} x_0) \cdot \sigma^{2}\)<br> \(= (\frac{\sqrt{\alpha_t}}{\beta_{t}} x_t + \frac{\sqrt{\bar \alpha_{t-1}}}{1 - \bar \alpha_{t-1}} x_0) \cdot (\frac{1 - \bar \alpha_{t-1}}{1 - \bar \alpha_{t}} \beta_{t})\)<br> \(= \frac{\sqrt{\alpha_t} x_t (1 - \bar \alpha_{t-1}) + \beta_{t} x_0 \sqrt{\bar \alpha_{t-1}}}{\beta_{t}(1 - \bar \alpha_{t-1})} \cdot (\frac{1 - \bar \alpha_{t-1}}{1 - \bar \alpha_{t}} \beta_{t})\)<br> \(= \frac{\sqrt{\alpha_t} x_t (1 - \bar \alpha_{t-1}) + \beta_{t} x_0 \sqrt{\bar \alpha_{t-1}}}{1 - \bar \alpha_{t}}\)</li> </ul> <p>따라서<br> \(\mu = \frac{\sqrt{\bar \alpha_{t-1}} \beta_{t}}{1 - \bar \alpha_{t}} x_0 + \frac{\sqrt{\alpha_t} (1 - \bar \alpha_{t-1})}{1 - \bar \alpha_{t}} x_t\)</p> <p>\(q(x_t | x_0) = N(x_t; \sqrt{\bar \alpha_{t}} x_{0}, (1-\bar \alpha_{t}) \boldsymbol I)\)이므로<br> \(x_0\) <code class="language-plaintext highlighter-rouge">소거</code>하기 위해<br> \(x_t = \sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \epsilon\) 대입하면</p> <p>\(\mu_{t} = \frac{\sqrt{\bar \alpha_{t-1}} \beta_{t}}{1 - \bar \alpha_{t}} x_0 + \frac{\sqrt{\alpha_t} (1 - \bar \alpha_{t-1})}{1 - \bar \alpha_{t}} x_t\)<br> \(= \frac{\sqrt{\bar \alpha_{t-1}} \beta_{t}}{1 - \bar \alpha_{t}} (\frac{1}{\sqrt{\bar \alpha_{t}}}(x_t - \sqrt{1 - \bar \alpha_{t}} \epsilon_{t})) + \frac{\sqrt{\alpha_t} (1 - \bar \alpha_{t-1})}{1 - \bar \alpha_{t}} x_t\)<br> \(= \frac{\sqrt{\bar \alpha_{t-1}} (1 - \alpha_{t})}{1 - \bar \alpha_{t}} (\frac{1}{\sqrt{\bar \alpha_{t}}}(x_t - \sqrt{1 - \bar \alpha_{t}} \epsilon_{t})) + \frac{\sqrt{\alpha_t} (1 - \bar \alpha_{t-1})}{1 - \bar \alpha_{t}} x_t\)<br> \(= \frac{\sqrt{k} (1 - \alpha_{t})}{1 - \alpha_{t} k} (\frac{1}{\sqrt{\alpha_{t} k}}(x_t - \sqrt{1 - \alpha_{t} k} \epsilon_{t})) + \frac{\sqrt{\alpha_t} (1 - k)}{1 - \alpha_{t} k} x_t\)<br> by \(k = \bar \alpha_{t-1}\) 및 \(\alpha_{t}k = \bar \alpha_{t}\)로 치환<br> \(= \frac{1}{\sqrt{\alpha_{t}}} x_t - \frac{1 - \alpha_{t}}{\sqrt{\alpha_{t}}\sqrt{1 - \alpha_{t}k}} \epsilon_{t}\)<br> \(= \frac{1}{\sqrt{\alpha_{t}}} x_t - \frac{1 - \alpha_{t}}{\sqrt{\alpha_{t}}\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t}\)<br> \(= \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t})\)</p> <ul> <li>\(q(x_{t-1} | x_t, x_0)\) 결과 :<br> \(q(x_{t-1} | x_t, x_0) = N(x_{t-1}; \tilde \mu_{t}(x_t), \tilde \beta_{t})\)<br> where \(\tilde \mu_{t}(x_t) = \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t})\)<br> and \(\tilde \beta_{t} = \frac{1 - \bar \alpha_{t-1}}{1 - \bar \alpha_{t}} \beta_{t}\)</li> </ul> <blockquote> <p>Step 8. Obtain \(p_{\theta}(x_{t-1} \| x_t)\)</p> </blockquote> <p>우리의 목적은<br> \(D_{KL}(q(x_{t-1} | x_t, x_0) \| p_{\theta}(x_{t-1} | x_t))\) 최소화<br> 즉, \(p\)의 분포를 \(q\)의 분포에 approx.하는 것이다</p> <p>\(q(x_{t-1} | x_t, x_0)\) 의 mean, variance 인<br> \(\tilde \mu_{t}(x_t) = \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t})\)<br> \(\tilde \beta_{t} = \frac{1 - \bar \alpha_{t-1}}{1 - \bar \alpha_{t}} \beta_{t}\) 에서<br> \(x_t, \alpha_{t}, \beta_{t}\)는 입력값 및 미리 정해놓는 상수값이라서<br> deep learning network인 \(\epsilon_{\theta}\) 가 시간 t에 따라 \(\epsilon_{t} \sim N(0, I)\) 을 학습하도록 하기 위해서<br> <code class="language-plaintext highlighter-rouge">training param.로 학습할 수 있는 부분</code>은 \(\epsilon_{t} \sim N(0, I)\) 뿐이다<br> 즉, <code class="language-plaintext highlighter-rouge">p와 q의 분포에서 차이가 날 수 있는 부분은 epsilon 뿐!</code></p> <p>따라서 \(p_{\theta}(x_{t-1} | x_t)\)의 평균인 \(\mu_{\theta}(x_t, t)\) 는<br> \(\tilde \mu_{t}(x_t) = \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t})\) 에서<br> \(\epsilon_{t}\) 만 \(\epsilon_{\theta}(x_t, t)\) 로 바꾼 값이다<br> \(\mu_{\theta}(x_t, t) = \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{\theta}(x_t, t))\)</p> <blockquote> <p>Step 9. Final <code class="language-plaintext highlighter-rouge">DDPM Loss</code></p> </blockquote> <p>Step 5.에 따르면 we have to minimize<br> \(E_{x_{1:T} \sim q(x_{1:T}|x_0)}[\frac{1}{2 \sigma_{t}^2} \| \tilde \mu_{t} (x_t, x_0) - \mu_{\theta} (x_t, t) \|^2] + C\)</p> <p>\(E_{x_0, \epsilon}[\frac{1}{2 \|\Sigma(x_t, t) \|^2} \| \tilde \mu_{t} (x_t, x_0) - \mu_{\theta} (x_t, t) \|^2]\)<br> \(= E_{x_0, \epsilon}[\frac{1}{2 \|\Sigma \|^2} \| \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{t}) - \frac{1}{\sqrt{\alpha_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar \alpha_{t}}} \epsilon_{\theta}(x_t, t)) \|^2]\)<br> \(= E_{x_0, \epsilon}[\frac{(1 - \alpha_{t})^2}{2 \|\Sigma \|^2 \alpha_{t} (1 - \bar \alpha_{t})} \| \epsilon_{t} - \epsilon_{\theta}(x_t, t) \|^2]\)<br> \(= E_{x_0, \epsilon}[\frac{(1 - \alpha_{t})^2}{2 \|\Sigma \|^2 \alpha_{t} (1 - \bar \alpha_{t})} \| \epsilon_{t} - \epsilon_{\theta}(\sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \epsilon, t) \|^2]\)<br> since \(x_t = \sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \epsilon\)</p> <p>앞의 weight term을 제거하면<br> <code class="language-plaintext highlighter-rouge">최종 Loss 값</code>은 드디어!!!<br> \(= E_{x_0, \epsilon}[\| \epsilon_{t} - \epsilon_{\theta}(\sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \epsilon, t) \|^2]\)<br> where \(x_t = q(x_t | x_0) = \sqrt{\bar \alpha_{t}} x_{0} + \sqrt{1-\bar \alpha_{t}} \epsilon\) and \(\epsilon \sim N(0, I)\)</p> <h3 id="ddpm-pseudo-code">DDPM Pseudo-Code</h3> <blockquote> <p>출처 블로그 :<br> <a href="https://xoft.tistory.com/32" rel="external nofollow noopener" target="_blank">Diffusion Model</a><br> <a href="https://xoft.tistory.com/33?category=1156151" rel="external nofollow noopener" target="_blank">DDPM 수식 유도</a><br> <a href="https://woongchan789.tistory.com/12" rel="external nofollow noopener" target="_blank">DDPM 수식 유도</a></p> </blockquote> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"semyeong-yu/semyeong-yu.github.io","data-repo-id":"R_kgDOLmVJXQ","data-category":"Comments","data-category-id":"DIC_kwDOLmVJXc4CeSwc","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>