<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Mip-NeRF 360 | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="Unbounded Anti-Aliased Neural Radiance Fields"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/MipNeRF360/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Mip-NeRF 360",
            "description": "Unbounded Anti-Aliased Neural Radiance Fields",
            "published": "August 11, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Mip-NeRF 360</h1> <p>Unbounded Anti-Aliased Neural Radiance Fields</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#scene-and-ray-parameterization">Scene and Ray Parameterization</a> </div> <ul> <li> <a href="#ray-interval-parameterization">Ray Interval Parameterization</a> </li> <li> <a href="#ray-interval-parameterization-in-disparity">Ray Interval Parameterization in Disparity</a> </li> <li> <a href="#scene-parameterization">Scene Parameterization</a> </li> </ul> <div> <a href="#coarse-to-fine-online-distillation">Coarse-to-Fine Online Distillation</a> </div> <div> <a href="#regularization-for-interval-based-models">Regularization for Interval-Based Models</a> </div> <div> <a href="#optimization">Optimization</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> <div> <a href="#question">Question</a> </div> <div> <a href="#code-review">Code Review</a> </div> <div> <a href="#appendix">Appendix</a> </div> </nav> </d-contents> <h2 id="mip-nerf-360-unbounded-anti-aliased-neural-radiance-fields">Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</h2> <h4 id="jonathan-t-barron-ben-mildenhall-dor-verbin-pratul-p-srinivasan-peter-hedman">Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P. Srinivasan, Peter Hedman</h4> <blockquote> <p>paper :<br> <a href="https://arxiv.org/abs/2111.12077" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2111.12077</a><br> project website :<br> <a href="https://jonbarron.info/mipnerf360/" rel="external nofollow noopener" target="_blank">https://jonbarron.info/mipnerf360/</a><br> pytorch code :<br> <a href="https://github.com/google-research/multinerf" rel="external nofollow noopener" target="_blank">https://github.com/google-research/multinerf</a></p> </blockquote> <blockquote> <p>핵심 요약 :</p> <ol> <li>sampling 기법 개선하고, bounded scene으로 warp</li> <li>non-linear scene, ray parameterization :<br> disparity에 비례하도록 sampling 개선하고<br> bounded space로 mapping하여<br> 임의의 방향과 깊이에 대한 unbounded scene 다룸</li> <li>efficient proposal-based online-distillation :<br> higher capacity MLP을 조금만 evaluate해서<br> 효율적으로 large scene 다룸</li> <li>interval-distortion-based regularizer :<br> artifacts 줄이기 위해<br> step-function을 delta-function에 가깝게 regularize</li> </ol> </blockquote> <h2 id="introduction">Introduction</h2> <ul> <li>임의의 <code class="language-plaintext highlighter-rouge">direction</code>(360 degrees)과 임의의 <code class="language-plaintext highlighter-rouge">depth</code>로 <code class="language-plaintext highlighter-rouge">unbounded</code> 되어있는 scene 문제 해결 <ul> <li>non-linear scene parameterization :<br> sampling 개선하고 bounded space로 mapping하여<br> 임의의 방향과 깊이에 대한 unbounded scene 다룰 수 있음</li> <li>online-distillation :<br> higher capacity MLP을 조금만 evaluate해서 효율적으로 large scene 다룰 수 있음</li> <li>distortion-based regularizer :<br> artifacts 줄이기 위한 regularization</li> </ul> </li> <li>NeRF model을 large unbounded scene에 적용하는 데 3가지 문제가 있다<br> (자세한 내용은 스킵했는데 나중에 읽어보자) <ul> <li>Parametrization : Mip-NeRF는 3D coordinate가 bounded domain 안에 있는 경우만 처리 가능</li> <li>Efficiency : large-and-detailed scene은 large MLP를 필요로 해서 expensive</li> <li>Ambiguity : scene content가 임의의 distance에 있고 이는 only 적은 수의 ray로 관찰되기 때문에 inherent ambiguity 발생</li> </ul> </li> </ul> <h2 id="scene-and-ray-parameterization">Scene and Ray Parameterization</h2> <h3 id="ray-interval-parameterization">Ray Interval Parameterization</h3> <ul> <li> <p>Ray Interval Parameterization :<br> samples의 경우 distance가 아니라 그의 역수인 <code class="language-plaintext highlighter-rouge">disparity에 비례</code>하여 분포하도록 하면<br> 가까이 있는 content는 많이 sampling하고 멀리 있는 content는 덜 sampling함으로써<br> <code class="language-plaintext highlighter-rouge">임의의 scale의 unbounded scene</code>을 잘 다룰 수 있음</p> </li> <li>NeRF : <ul> <li>NeRF에서는 distance에 비례하여 stratified uniform sampling 했음</li> <li>만약 NDC parameterization을 쓰면<br> disparity (distance의 역수)에 비례하여 uniform sampling 한 것과 같은 효과를 가짐 <code class="language-plaintext highlighter-rouge">?????</code> </li> <li>그런데 NDC는 single direction으로만 unbounded된 scene (front-facing camera)에 대해서만 적합하고<br> 모든 방향으로 unbounded된 scene에 대해서는 적합하지 않음</li> </ul> </li> <li>Mip-NeRF 360 : <ul> <li>처음부터 ray interval을 disparity (distance의 역수)에 비례하도록 <d-cite key="LLFF">[2]</d-cite> parameterize 한다</li> </ul> </li> </ul> <h3 id="ray-interval-parameterization-in-disparity">Ray Interval Parameterization in Disparity</h3> <ul> <li>distance along ray를 t-space 또는 s-space에서 나타내자 <ul> <li>t-space :<br> Euclidean ray distance \(t \in [t_n, t_f]\)<br> \(t = g^{-1}(s \cdot g(t_f) + (1-s) \cdot g(t_n))\)</li> <li>s-space :<br> normalized ray distance \(s \in [0, 1]\)<br> \(s = \frac{g(t)-g(t_n)}{g(t_f)-g(t_n)}\)</li> </ul> </li> <li>사용 예시 : <ul> <li>\(g(x) = \frac{1}{x}\) 로 설정할 경우<br> <code class="language-plaintext highlighter-rouge">s-space에서 uniform sampling</code>하면<br> <code class="language-plaintext highlighter-rouge">t-space에서 disparity에 비례</code>하여 distributed</li> <li>\(g(x) = log(x)\) 로 설정할 경우<br> s-space에서 uniform sampling하면<br> t-space에서는 logarithmic spacing <d-cite key="DONeRF">[3]</d-cite> 으로 distributed</li> </ul> </li> <li>기존 NeRF 모델에서는 t-distance를 따라 uniform sampling했지만<br> 본 논문에서는 <code class="language-plaintext highlighter-rouge">s-distance</code>를 따라 uniform sampling하여 나타낸다</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/4-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/4-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="scene-parameterization">Scene Parameterization</h3> <ul> <li> <p>Scene Parameterization :<br> unbounded scene을 radius-2 내부의 <code class="language-plaintext highlighter-rouge">bounded space</code>로 mapping하기 위해 <code class="language-plaintext highlighter-rouge">contract 함수</code>를 사용<br> ray parameterization을 할 때 disparity에 비례하게 sampling 했으므로<br> contract 함수도 consistently <code class="language-plaintext highlighter-rouge">disparity에 비례</code>하게 bounded space로 mapping<br> \(\rightarrow\) scene origin에서 cast된 ray의 경우 contract 함수를 적용한 후에는 아래 그림의 주황색 영역에서 일정한 길이의 interval을 가진다</p> </li> <li>Define smooth coordinate-transformation function as \(f(x) : R^3 \rightarrow R^3\) <ul> <li>\(f(x) \approx f(\mu) + J_{f}(\mu)(x-\mu)\) (linear approx.)<br> \(f(\mu, \Sigma) = (f(\mu), J_{f}(\mu) \Sigma J_{f}(\mu)^T)\)</li> <li>이는 state transition model \(f = \text{contract}(x) = \begin{cases} x &amp; \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) &amp; \text{if} \| x \| \gt 1 \end{cases}\) 에 대해<br> classic Extended Kalman filter <d-cite key="kalman">[1]</d-cite> 와 수학적으로 동일</li> <li>MipNeRF360에서는 contract 함수를<br> <code class="language-plaintext highlighter-rouge">point가 아니라</code> Euclidean 3D-space에 있는 <code class="language-plaintext highlighter-rouge">Gaussian</code>에 적용!<br> 또한<br> <code class="language-plaintext highlighter-rouge">모든 방향</code> (360 degress)에 대해 적용!</li> </ul> </li> <li>IPE (integrated positional encoding) : <ul> <li>Mip-NeRF :<br> \(\gamma (\mu, \Sigma) = \left[ \begin{bmatrix} sin(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \\ cos(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \end{bmatrix} \right]_{l=0}^{l=L-1}\)</li> <li>Mip-NeRF 360 :<br> \(\gamma (\text{contract}(\mu, \Sigma))\)<br> where \(\text{contract}(x) = \begin{cases} x &amp; \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) &amp; \text{if} \| x \| \gt 1 \end{cases}\)</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/1-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/1-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> contract 함수는 파란색 구(radius 1) 외부의 Gaussian(회색)을 주황색 영역(radius 1 ~ 2)의 Gaussian(빨간색)으로 mapping </div> <h2 id="coarse-to-fine-online-distillation">Coarse-to-Fine Online Distillation</h2> <ul> <li>기존 NeRF :<br> coarse-MLP와 fine-MLP</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/2-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/2-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 위의 그림은 Mip-NeRF, 아래의 그림은 Mip-NeRF 360 </div> <ul> <li>Mip-NeRF 360 :<br> proposal-MLP와 NeRF-MLP <ul> <li> <code class="language-plaintext highlighter-rouge">small</code> proposal-MLP는 <code class="language-plaintext highlighter-rouge">many</code> samples로 <code class="language-plaintext highlighter-rouge">여러 번</code> evaluate하고,<br> <code class="language-plaintext highlighter-rouge">large</code> NeRF-MLP는 <code class="language-plaintext highlighter-rouge">less</code> samples로 <code class="language-plaintext highlighter-rouge">딱 한 번</code> evaluate함으로써<br> Mip-NeRF보다 조금만 더 costly하지만 훨씬 더 <code class="language-plaintext highlighter-rouge">higher capacity</code>를 가진 것과 같은 효과<br> \(\rightarrow\) 효율적으로 <code class="language-plaintext highlighter-rouge">large unbounded scene</code>을 표현하기에 적절<br> distill 효과가 좋아서 proposal-MLP의 경우 크기 줄이더라도 accuracy 감소하지 않음</li> <li>small proposal-MLP : <ul> <li>color 말고 volume density만 예측하여 weight \(\hat w\) 구함</li> </ul> </li> <li>large NeRF-MLP : <ul> <li>color, volume density 예측하여 weight \(w\) 구하고 rendering</li> </ul> </li> </ul> </li> <li>Loss :<br> 아래 두 가지 loss로 각 MLP를 jointly train <ul> <li> <code class="language-plaintext highlighter-rouge">reconstruction loss</code> : <ul> <li>large NeRF-MLP에서 rendering해서 구함<br> 기존 NeRF 방식과 동일</li> <li> <code class="language-plaintext highlighter-rouge">GT-image를 supervision</code>으로 하여 <code class="language-plaintext highlighter-rouge">NeRF-MLP만 업데이트</code> </li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">proposal loss</code> : <ul> <li>두 MLP의 <code class="language-plaintext highlighter-rouge">weight histogram이 consistent</code>하도록 함<br> (Mip-NeRF 계열은 point가 아니라 interval 별로 weight를 구하므로 histogram을 만들 수 있음)</li> <li> <code class="language-plaintext highlighter-rouge">NeRF-MLP의 weight를 supervision</code>으로 하여 <code class="language-plaintext highlighter-rouge">proposal-MLP만 업데이트</code><br> (<code class="language-plaintext highlighter-rouge">online distillation</code> of NeRF-MLP’s knowledge into proposal-MLP)</li> <li>문제 :<br> 하나의 histogram bin의 distribution에 대해 아무 것도 가정할 수 없음<br> (하나의 bin의 distribution이 uniform일 수도 있고 특정 지점에 몰빵된 delta function일 수도 있음…)<br> coarse \(\hat t\) 와 fine \(t\) (bins)가 매우 다를 수 있음</li> <li>가정 :<br> 두 개의 histogram이 매우 달라보이더라도<br> 둘 다 <code class="language-plaintext highlighter-rouge">어떤 하나의 동일한 (underlying continuous) true mass distribution으로부터 유래되었다고 설명할 수 있다면</code> 둘의 차이인 loss는 0 이다</li> <li>위의 가정에 따라<br> NeRF-MLP (\(t\), \(w\))의 구간 \(T\) 와 겹치는 모든 proposal-MLP의 weight \(\hat w_{j}\) 를 더해서 아래와 같이 NeRF-MLP weight \(w\) 의 <code class="language-plaintext highlighter-rouge">upper bound</code>를 구하자<br> \(\text{bound}(\hat t, \hat w, T) = \sum_{j: T \cap \hat T_{j} \neq \emptyset} \hat w_{j}\)<br> (\(t\) 와 \(\hat t\) 가 정렬되어 있으므로 summed-area table로 효율적으로 계산 가능)</li> <li>만약 두 개의 histogram이 consistent하다면,<br> NeRF-MLP (\(t\), \(w\))의 모든 구간 (\(T_i, w_i\))에 대해<br> \(w_i \leq \text{bound}(\hat t, \hat w, T_i)\) 이어야 한다<br> \(\rightarrow\)<br> 아래와 같이 <code class="language-plaintext highlighter-rouge">proposal loss는 이를 위반하는 경우</code>에 해당한다<br> \(L_{prop}(t, w, \hat t, \hat w) = \sum_{i}\frac{1}{w_i} \text{max}(0, w_i - \text{bound}(\hat t, \hat w, T_i))^2\)</li> <li>proposal loss가 asymmetirc loss인 이유 :<br> proposal-MLP가 NeRF-MLP보다 coarse하기 때문에<br> proposal-MLP weight가 NeRF-MLP weight의 upper bound를 형성하는 게 (overestimate) 당연하고,<br> proposal-MLP weight가 NeRF-MLP weight를 underestimate (\(\text{bound}(\hat t, \hat w, T_i) &lt; w_i\)) 하는 경우에만 penalize</li> <li>proposal loss term에서 \(w_i\) 로 나누는 이유 :<br> bound가 0일 때 \(\frac{dL_{prop}}{d\text{bound}} = \sum_{i} \frac{1}{w_i} \cdot 2 \cdot \text{max}(0, w_i - \text{bound}) \cdot (-1) = -2\sum_{i}1\) 와 같이<br> gradient 값이 \(w_i\) 크기와 상관없이 상수값이 되어 균등하게 penalize하여 optimization에 도움됨</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/8-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/8-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 위의 histogram이 NeRF-MLP, 아래의 histogram이 proposal-MLP, 보통 proposal-MLP가 coarse하고 NeRF-MLP가 fine한데 여기선 반대로 그려져 있음 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/3-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/3-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> fine NeRF-MLP는 점점 scene content의 surface 쪽으로 weight가 집중되고, coarse proposal-MLP는 이를 따라잡으며 upper bound를 형성 </div> <h2 id="regularization-for-interval-based-models">Regularization for Interval-Based Models</h2> <ul> <li>Artifacts :<br> NeRF 계열은 pose 문제 때문에 두 가지 주된 artifacts가 나타난다 <ul> <li> <code class="language-plaintext highlighter-rouge">floater</code> :<br> 특정 view를 너무 잘 설명하려던 나머지<br> 실제로 물체가 존재하지 않는 small disconnected regions of dense volume에서 불필요하게 opacity를 예측하여<br> 다른 view에서 보면 반투명한 blurry cloud처럼 보이는 부분</li> <li> <code class="language-plaintext highlighter-rouge">background collapse</code> :<br> 멀리 있는 surface가<br> 반투명한 가까운 content로 잘못 모델링된 경우</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/5-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/5-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 반투명하게 떠다니는 게 floater, 좌하단에서 background surface가 가깝게 보이는 게 background collapse </div> <ul> <li>Artifacts 완화 : <ul> <li>기존 NeRF : <code class="language-plaintext highlighter-rouge">random noise</code><br> <a href="https://semyeong-yu.github.io/blog/2024/NeRFcode/">NeRF-Code</a> 의 raw2outputs()에서 볼 수 있듯이<br> raw-opacity에 random noise 더해서 \(\sigma_{i}\) 구함<br> noise 덕분에 <code class="language-plaintext highlighter-rouge">불필요한 특정 지점에 overfit 되는 게 아니라 일관성 있게</code> 학습<br> But, 부분적으로 artifacts 완화하고 reconstruction quality를 떨어뜨림</li> <li>Mip-NeRF 360 : <code class="language-plaintext highlighter-rouge">regularize</code><br> ray-sampling은 이미 했고 weight를 구할 때<br> <code class="language-plaintext highlighter-rouge">물체가 있을만한 정확한 지점에서 집중적으로 예측</code>하여<br> <code class="language-plaintext highlighter-rouge">부정확한 지점에서의 불필요한 예측을 억제</code> </li> </ul> </li> <li>Regularization for Interval-Based Models : <ul> <li> <code class="language-plaintext highlighter-rouge">distortion loss</code> :<br> step-function인 weight-histogram \(s, w\) 을 regularize하기 위해<br> \(L_{dist}(s, w) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} w_s(u)w_s(v)|u-v|d_ud_v\) <ul> <li> <code class="language-plaintext highlighter-rouge">NeRF-MLP 업데이트</code>할 때 artifacts 완화(<code class="language-plaintext highlighter-rouge">regularization</code>)하는 역할</li> </ul> </li> <li>위의 loss를 최소화하기 위해선<br> \(w\) 를 매우 작은 \(|u-v|\) 에 몰빵하면 된다<br> 즉, 위의 loss term만 있을 경우 histogram(step-function)이 <code class="language-plaintext highlighter-rouge">delta-function</code>에 가까워지면 된다</li> <li>t-distance 대신 <code class="language-plaintext highlighter-rouge">s-distance</code> 사용 :<br> t-distance 사용하면 먼 거리에 있는 interval 길이가 길기 때문에 무조건 먼 거리의 interval 쪽으로 distortion 됨<br> s-distance 기준으로 weight-histogram 만들어서 distortion loss 구하자!</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/6-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/6-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> TBD </div> <ul> <li> <code class="language-plaintext highlighter-rouge">distortion loss</code> : <ul> <li>weight \(w\) 는 step-function (각 interval 안에선 constant) 이므로<br> 아래와 같이 계산하기 쉬운 꼴로 유도할 수 있음<br> \(L_{dist}(s, w) = \sum_{i, j} w_i w_j |\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}| + \frac{1}{3} \sum_{i} w_i^2 (s_{i+1} - s_i)\)</li> <li>유도 과정 :<br> 출처 : https://charlieppark.kr/ <ul> <li>\(L_{dist}(s, w) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} w_s(u)w_s(v)|u-v|d_ud_v\)<br> where \(w_s(u) = w_i\) for \(u \in [s_i, s_{i+1})\)</li> <li>case 1. \(u, v\) are in the same interval : \(u, v \in [s_i, s_{i+1})\)<br> \(\int_{s_i}^{s_{i+1}}\int_{s_i}^{s_{i+1}}w_i^2|u-v|d_ud_v\)<br> \(= w_i^2 \frac{(s_{i+1}-s_i)^3}{3}\)</li> <li>case 2. \(u, v\) are in different intervals : \(u \in [s_i, s_{i+1}), v \in [s_j, s_{j+1})\) where \(i \neq j\)<br> \(\int_{s_i}^{s_{i+1}}\int_{s_j}^{s_{j+1}}w_iw_j|u-v|d_ud_v\)<br> \(\simeq \int_{s_i}^{s_{i+1}}\int_{s_j}^{s_{j+1}}w_iw_j|\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}|d_ud_v\)<br> \(= w_iw_j|\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}|\cdot (s_{i+1}-s_i)(s_{j+1}-s_j)\)</li> <li> \[L_{dist}(s, w) = \sum_{i} w_i^2 \frac{(s_{i+1}-s_i)^3}{3} + \sum_{i, j} w_iw_j|\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}|\cdot (s_{i+1}-s_i)(s_{j+1}-s_j)\] </li> <li>\((s_{i+1} - s_i)^2\) 항과 \((s_{i+1}-s_i)(s_{j+1}-s_j)\) 항을 제거하여 학습의 안정성을 높임<br> \(L_{dist}(s, w) = \frac{1}{3} \sum_{i} w_i^2 (s_{i+1} - s_i) + \sum_{i, j} w_i w_j |\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}|\)</li> <li>\(u, v\) 가 <code class="language-plaintext highlighter-rouge">same interval</code>에 있을 경우에는 \((s_{i+1}-s_i)\) 항으로 <code class="language-plaintext highlighter-rouge">각 구간의 (weighted) 너비</code>를 줄이고,<br> \(u, v\) 가 <code class="language-plaintext highlighter-rouge">different interval</code>에 있을 경우에는 \(|\frac{s_i + s_{i+1}}{2} - \frac{s_j + s_{j+1}}{2}|\) 항으로 <code class="language-plaintext highlighter-rouge">두 구간 사이의 (weighted) 중심 거리</code>를 줄임<br> 이 원리를 통해<br> 가능하다면(entire ray is unoccupied) 모든 weight가 0에 가까워지려 하고<br> 불가능하다면 weight를 few interval에 몰빵하려 해서<br> weight-histogram이 delta-function에 가까워질 수 있음</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/7-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/7-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="optimization">Optimization</h2> <ul> <li>Setting : <ul> <li>proposal-MLP with 4 layers and 256 hidden_dim<br> two proposal-MLP \((\hat s^0, \hat w^0)\) and \((\hat s^1, \hat w^1)\) each using 64 samples</li> <li>NeRF-MLP \((s, w)\) with 8 layers and 1024 hidden_dim<br> one NeRF-MLP using 32 samples</li> <li>total loss :<br> \(L_{tot} = L_{recon}(C(t), C^{\ast}) + \lambda L_{dist}(s, w) + \sum_{k=0}^{1}L_{prop}(s, w, \hat s^k, \hat w^k)\)<br> averaged over all rays in batch<br> where author sets \(\lambda = 0.01\)</li> <li>\(L_{recon}\) and \(L_{dist}\) for NeRF-MLP <ul> <li>\(L_{recon}(x, x^{\ast}) = \sqrt{(x - x^{\ast})^2 + \epsilon^{2}}\) : Charbonnier loss<br> slightly more stable than MSE</li> </ul> </li> <li>\(L_{prop}\) for proposal-MLP</li> <li>learning schedule :<br> 250k iter. with batch size \(2^{14}\)<br> Adam optimizer with \(\beta_{1} = 0.9, \beta_{2} = 0.999, \epsilon = 10^{-6}\)<br> lr is annealed log-linearly from \(2 \times 10^{-3}\) to \(2 \times 10^{-5}\)<br> warm-up phase of 512 iter.<br> gradient clipping to norm of \(10^{-3}\)</li> </ul> </li> </ul> <h2 id="conclusion">Conclusion</h2> <ul> <li>Mip-NeRF extension for real-world unbounded scenes with unconstrained camera depth and orientations</li> <li>(Kalman-like) scene and ray parameterization</li> <li>efficient proposal-based coarse-to-fine distillation framework</li> <li>interval-distortion-based regularizer</li> <li>Mip-NeRF에 비해 57% reduction in MSE</li> </ul> <h2 id="question">Question</h2> <ul> <li>Q&amp;A reference : 3DGS online study</li> <li>Q1 : 아래의 문구가 이해되지 않습니다<br> recall that the “bins” of those histograms \(t\) and \(\hat t\) need not be similar; indeed, if the proposal MLP successfully culls the set of distances where scene content exists, \(\hat t\) and \(t\) will be highly dissimilar</li> <li>A1 : 아래 사진의 (c)에서처럼 충분히 optimize되어 만약 coarse proposal-MLP가 이미 scene content가 있는 곳을 성공적으로 예측하고 있다면 이를 이용한 fine NeRF-MLP의 fine-samples는 그 곳에 더 촘촘히 존재할 것이므로 bin 간격이 달라져서 두 histogram이 크게 달라보인다<br> 달라보이더라도 두 개의 histogram이 어떤 하나의 (true continuous underlying) mass distribution에서 유래되었다고 설명할 수 있으면 둘의 차이가 0이라고 가정하여 upper bound를 이용해서 proposal loss 만듬</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-11-MipNeRF360/3-480.webp 480w,/assets/img/2024-08-11-MipNeRF360/3-800.webp 800w,/assets/img/2024-08-11-MipNeRF360/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-11-MipNeRF360/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Q2 : 갑자기 든 생각인데 Mip-NeRF 360의 sampling 기법과 contract 함수가 background collapse의 원인이 될 수도 있지 않을까요?<br> disparity에 비례하게 sampling하므로 먼 거리에 대해서는 덜 sampling한 채로 bounded space로 warp하는데,<br> 먼 거리의 content에 대해 정보가 부족한 채로 warp하는 과정에서 왜곡이 일어날 수 있을 것 같다</li> <li>A2 : 그럴 수 있을 것 같습니다</li> </ul> <h2 id="code-review">Code Review</h2> <p>TBD</p> <h2 id="appendix">Appendix</h2> <h3 id="off-axis-positional-encoding">Off-Axis Positional Encoding</h3> <ul> <li>Mip-NeRF의 IPE 식에 따르면 \(diag(\Sigma)\) 만 알면 되는데,<br> Mip-NeRF 360에서는 IPE를 하기 전에 Gaussian을 우선 radius-2의 구 안으로 contract 해야 해서 full covariance matrix \(\Sigma\) 가 필요하다</li> <li> </li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-08-11-MipNeRF360.bib"></d-bibliography> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="semyeong-yu",disqus_identifier="/blog/2024/MipNeRF360",disqus_title="Mip-NeRF 360";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>