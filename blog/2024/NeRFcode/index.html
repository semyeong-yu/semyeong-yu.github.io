<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> NeRF-Code | Semyeong Yu </title> <meta name="author" content="Semyeong Yu"> <meta name="description" content="NeRF Code Review"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://semyeong-yu.github.io/blog/2024/NeRFcode/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "NeRF-Code",
            "description": "NeRF Code Review",
            "published": "August 05, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Semyeong</span> Yu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>NeRF-Code</h1> <p>NeRF Code Review</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#load-data">Load Data</a> </div> <div> <a href="#create-nerf-model">Create NeRF Model</a> </div> <div> <a href="#get-ray-with-batch">Get Ray with batch</a> </div> <div> <a href="#get-ray-without-batch">Get Ray without batch</a> </div> <div> <a href="#render">Render</a> </div> <div> <a href="#evaluation">Evaluation</a> </div> <div> <a href="#question">Question</a> </div> </nav> </d-contents> <h2 id="nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</h2> <h4 id="ben-mildenhall-pratul-psrinivasan-matthew-tancik">Ben Mildenhall, Pratul P.Srinivasan, Matthew Tancik</h4> <blockquote> <p>paper :<br> <a href="https://arxiv.org/abs/2003.08934" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2003.08934</a><br> project website :<br> <a href="https://www.matthewtancik.com/nerf" rel="external nofollow noopener" target="_blank">https://www.matthewtancik.com/nerf</a><br> pytorch code :<br> <a href="https://github.com/yenchenlin/nerf-pytorch" rel="external nofollow noopener" target="_blank">https://github.com/yenchenlin/nerf-pytorch</a><br> <a href="https://github.com/csm-kr/nerf_pytorch?tab=readme-ov-file" rel="external nofollow noopener" target="_blank">https://github.com/csm-kr/nerf_pytorch?tab=readme-ov-file</a><br> tiny tensorflow code :<br> <a href="https://colab.research.google.com/github/bmild/nerf/blob/master/tiny_nerf.ipynb" rel="external nofollow noopener" target="_blank">https://colab.research.google.com/github/bmild/nerf/blob/master/tiny_nerf.ipynb</a><br> Overview image reference :<br> <a href="https://yconquesty.github.io/blog/ml/nerf/nerf_ndc.html#dataflow" rel="external nofollow noopener" target="_blank">https://yconquesty.github.io/blog/ml/nerf/nerf_ndc.html#dataflow</a></p> </blockquote> <h3 id="train-code-flow-overview">Train Code Flow Overview</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/1-480.webp 480w,/assets/img/2024-08-05-NeRFcode/1-800.webp 800w,/assets/img/2024-08-05-NeRFcode/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="load-data">Load Data</h3> <ul> <li>load data : <ul> <li>load_llff.py</li> <li>load_blender.py</li> <li>load_LINEMOD.py</li> <li>load_deepvoxels.py</li> </ul> </li> </ul> <h4 id="load_llff_data">load_llff_data()</h4> <ul> <li>LLFF dataset : real dataset<br> return images, poses, bds, render_poses, i_test <ul> <li>images : np (N, H, W, C)</li> <li>poses : np (N, 3, 5)<br> camera poses<br> poses[:, 0:3, 0:3] : 3-by-3 rotation matrix<br> poses[:, 0:3, 3:4] : 3-by-1 translation matrix<br> poses[:, 0:3, 4:5] : H, W, focal-length for intrinsic matrix</li> <li>bds : np (N, 2)<br> scene bounds<br> dim=1 : 2 = 1(near bound) + 1(far bound)</li> <li>render_poses : np (M, 3, 5)<br> dim=0 : the number of generated poses for novel view synthesis<br> generate new pose along sphere or spiral path</li> <li>i_test : int<br> index of holdout-view (avg pose랑 가장 비슷한 pose를 갖는 view)<br> training에서 제외하여 test할 때 사용</li> <li>near, far = 0., 1. if ndc is true else near, far = 0.9 * bds.min(), 1. * bds.max()</li> </ul> </li> </ul> <h4 id="load_blender_data">load_blender_data()</h4> <ul> <li>Blender dataset : synthetic dataset<br> return images, poses, render_poses, hwf, i_split <ul> <li>images : np (N, H, W, C)<br> blender dataset은 RGB-A channel을 가지고 있어 C = 4</li> <li>i_train, i_val, i_test = i_split</li> <li>near, far = 2., 6.<br> (blender synthetic dataset은 통제된 환경에서 수집된 data이므로 ndc 사용하지 않고 frustum의 near, far plane 고정)</li> <li>투명한 배경을 흰 배경으로 만들려면<br> RGB * opacity + (1 - opacity) 를 통해<br> RGB 값을 opacity만큼 반영하고 opacity가 작을수록(투명할수록) 색상이 흰색(1.)에 가까워지도록 함<br> images = images[…,:3]*images[…,-1:] + (1.-images[…,-1:])</li> <li>그냥 투명한 배경 그대로 쓰려면<br> RGB-A channel에서 RGB channel만 가져와서 씀<br> images = images[…,:3]</li> </ul> </li> </ul> <h4 id="load_linemod_data">load_LINEMOD_data()</h4> <ul> <li>LINEMOD dataset : real dataset<br> return images, poses, render_poses, hwf, K, i_split, near, far</li> </ul> <h4 id="load_dv_data">load_dv_data()</h4> <ul> <li>Deepvoxels dataset : synthetic dataset<br> return images, poses, render_poses, hwf, i_split <ul> <li>near, far = hemi_R - 1., hemi_R + 1.<br> where hemi_R = np.mean(np.linalg.norm(poses[:,:3,-1], axis=-1))<br> camera center들로 이루어진 반구의 평균 반지름</li> </ul> </li> </ul> <h3 id="create-nerf-model">Create NeRF Model</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/4-480.webp 480w,/assets/img/2024-08-05-NeRFcode/4-800.webp 800w,/assets/img/2024-08-05-NeRFcode/4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>args.N_importance : fine-MLP에서 추가적으로 사용할 fine-sample 개수 <ul> <li>args.N_importance &gt; 0 : fine-MLP 사용함</li> <li>args.N_importance &lt;= 0 : fine-MLP 사용 안함</li> </ul> </li> <li>network_query_fn : 추후에 run_network() 사용하기 위한 함수 <ul> <li>input : position info., view-direction info., model</li> <li>output : model output</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/10-480.webp 480w,/assets/img/2024-08-05-NeRFcode/10-800.webp 800w,/assets/img/2024-08-05-NeRFcode/10-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>render_kwargs_train : dict for rendering <ul> <li>network_query_fn : 추후에 run_network() 사용하기 위한 함수</li> <li>perturb : 일반화 위해 stratified ray-sampling할 때 randomness 추가할지 여부<br> (test할 때는 False)</li> <li>network_fine, network_fn : fine-MLP, coarse-MLP</li> <li>N_importance, N_samples : number of fine-sampling, coarse-sampling</li> <li>white_bkgd : rendering에서 alpha-channel 사용할 때 투명한 부분이 흰색으로 채워지도록 할지 여부</li> <li>raw_noise_std : 일반화 위해 raw2ouputs()에서 model output 중 opacity에 추가할 noise의 std값<br> (test할 때는 0.)</li> <li>lindisp : <ul> <li>NDC를 사용하는 front-unbounded llff dataset의 경우 lindisp = False로 설정하여<br> linearly sampling in depth, 즉 depth를 균등하게 sampling하여<br> 먼 거리의 scene도 적절히 표현</li> <li>NDC를 사용하지 않는 나머지 dataset의 경우 lindisp = True로 설정하여<br> linearly sampling in inverse-depth, 즉 가까운 depth를 더 많이 sampling하여<br> 가까운 scene의 디테일을 잘 포착</li> </ul> </li> </ul> </li> </ul> <h4 id="positional-encoding">Positional Encoding</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/2-480.webp 480w,/assets/img/2024-08-05-NeRFcode/2-800.webp 800w,/assets/img/2024-08-05-NeRFcode/2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>get_embedder() input :<br> PE freq. 개수 \(L\) 과 PE 쓸지말지 여부</li> <li>get_embedder() output :<br> PE-function과 PE 결과의 dim.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/3-480.webp 480w,/assets/img/2024-08-05-NeRFcode/3-800.webp 800w,/assets/img/2024-08-05-NeRFcode/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>self.embed_fns :<br> 각 frequency(\(0 \sim 2^{L-1}\))와 각 period function(\(sin, cos\))에 대한<br> list of lambda functions<br> \([sin(2^0x), cos(2^0x), \ldots sin(2^{L-1}x), cos(2^{L-1}x)]\)</li> <li>Embedder.embed(x) :<br> self.embed_fns의 각 PE-function을 input x에 적용하여 dim=-1에 대해 concat</li> </ul> <h4 id="nerf-model">NeRF model</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/5-480.webp 480w,/assets/img/2024-08-05-NeRFcode/5-800.webp 800w,/assets/img/2024-08-05-NeRFcode/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input_ch : position info. dim. : 3</li> <li>input_ch_views : view-direction info. dim. : 3</li> <li>use_viewdirs : MLP input으로 view-direction info.를 사용할지 말지 여부<br> (view-direction info.를 사용하면 RGB color 계산에 도움됨)</li> <li>output_ch : output(RGB, opacity) dim. : 4 use_viewdirs가 False일 때만 사용하는 값</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/6-480.webp 480w,/assets/img/2024-08-05-NeRFcode/6-800.webp 800w,/assets/img/2024-08-05-NeRFcode/6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input x를 position info.와 view-direction info.로 쪼갬</li> <li>self.use_viewdirs가 True일 때(view-direction info. 사용할 때) :<br> position info.만 넣어서 opacity를 뽑은 뒤<br> view-direction info.를 추가로 넣어서 RGB 뽑고<br> dim=-1에 대해 concat</li> <li>self.use_viewdirs가 False일 때(view-direction info. 사용 안 할 때) :<br> position info.만 넣어서 output_ch만큼 한 번에 뽑음</li> </ul> <h4 id="run_network">run_network</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/9-480.webp 480w,/assets/img/2024-08-05-NeRFcode/9-800.webp 800w,/assets/img/2024-08-05-NeRFcode/9-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/7-480.webp 480w,/assets/img/2024-08-05-NeRFcode/7-800.webp 800w,/assets/img/2024-08-05-NeRFcode/7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>flatten position and flatten view-direction \(\rightarrow\) each positional encoding and concat \(\rightarrow\) batchify model and apply model \(\rightarrow\) reshape again output</li> </ul> <h4 id="batchify">batchify</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/8-480.webp 480w,/assets/img/2024-08-05-NeRFcode/8-800.webp 800w,/assets/img/2024-08-05-NeRFcode/8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input이 주어지면 chunk만큼씩 쪼개서 적용하는 model 반환</li> </ul> <h3 id="get-ray-with-batch">Get Ray with batch</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/11-480.webp 480w,/assets/img/2024-08-05-NeRFcode/11-800.webp 800w,/assets/img/2024-08-05-NeRFcode/11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>rays : shape (N, 2, H, W, 3) <ul> <li>dim=1 : rays_o, rays_d</li> <li>dim=2, 3 : for H*W개의 pixels</li> <li>dim=4 : 3d</li> </ul> </li> <li>rays_rgb : shape (N, 3, H, W, 3) after concat with images <ul> <li>dim=1 : rays_o, rays_d, images</li> </ul> </li> <li>rays_rgb : shape (N, H, W, 3, 3) \(\rightarrow\) (N_train, H, W, 3, 3) \(\rightarrow\) (N_train * H * W, 3, 3) \(\rightarrow\) shuffle along dim=0 <ul> <li>dim=0 : the number of rays(pixels)</li> <li>dim=1 : rays_o, rays_d, images</li> <li>dim=2 : 3d for rays and rgb for images</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/14-480.webp 480w,/assets/img/2024-08-05-NeRFcode/14-800.webp 800w,/assets/img/2024-08-05-NeRFcode/14-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>batch : N_train * H * W 개의 ray를 batch size = N_rand-개씩 묶어서 전부 사용<br> shape (N_train * H * W, 3, 3) \(\rightarrow\) shape (N_rand, 3, 3) \(\rightarrow\) (3, N_rand, 3)</li> <li>batch_rays : shape (2, N_rand, 3) <ul> <li>dim=0 : rays_o, rays_d</li> <li>dim=1 : the number of rays</li> </ul> </li> <li>target_s : shape (N_rand, 3) <ul> <li>dim=0 : the number of pixels</li> <li>dim=1 : target pixel RGB</li> </ul> </li> <li>shuffle rays_rgb by torch.randperm() for every epoch</li> </ul> <h4 id="get_rays_np">get_rays_np</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/12-480.webp 480w,/assets/img/2024-08-05-NeRFcode/12-800.webp 800w,/assets/img/2024-08-05-NeRFcode/12-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>parameter :<br> K : intrinsic matrix of shape (3, 3)<br> c2w : extrinsic matrix of shape (3, 4)</li> <li>line 1 :<br> np.meshgrid([0, …, W-1], [0, …, H-1], indexing=’xy’) <ul> <li>indexing=’xy’ : 첫 번째 array를 row-방향으로 반복하고, 두 번째 array를 column-방향으로 반복</li> <li>i, j : both shape (H, W) : 2D-pixel-coordinate (x, y)</li> </ul> </li> <li>line 2 : <ul> <li>apply intrinsic matrix<br> <a href="https://semyeong-yu.github.io/blog/2024/NeRF/">NeRF-Blog</a> 의 Ray from input image (pre-processing) 참고</li> <li>dirs : shape (H, W, 3) : 2D-normalized-coordinate</li> </ul> </li> <li>line 4 : <ul> <li>apply extrinsic matrix to calculate ray-direction</li> <li>dirs[…, np.newaxis, :] : shape (H, W, 1, 3) \(\rightarrow\) (H, W, 3, 3) by broad-casting</li> <li>c2w[:3, :3] : shape (3, 3) \(\rightarrow\) (H, W, 3, 3) by broad-casting</li> <li>ray_d : shape (H, W, 3)<br> “elementwise-multiplication 후 sum”은 “matrix-multiplication”과 동일한 계산</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/13-480.webp 480w,/assets/img/2024-08-05-NeRFcode/13-800.webp 800w,/assets/img/2024-08-05-NeRFcode/13-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>line 6 : <ul> <li>apply extrinsic matrix to calculate ray-origin</li> <li>rays_o : shape (3,) \(\rightarrow\) (H, W, 3) by broad-casting</li> </ul> </li> </ul> <h3 id="get-ray-without-batch">Get Ray without batch</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/15-480.webp 480w,/assets/img/2024-08-05-NeRFcode/15-800.webp 800w,/assets/img/2024-08-05-NeRFcode/15-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/15.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>차이점 :<br> Get Ray with batch에서는 N_train * H * W 개의 ray를 batch size = N_rand-개씩 묶어서 전부 사용했다면<br> Get Ray without batch에서는 N_train 중 training view 하나를 randomly 고른 뒤 H * W 개의 ray 중 N_rand-개를 randomly 골라서 사용</p> </li> <li>target : shape (N, H, W, C) \(\rightarrow\) (H, W, C)<br> \(\rightarrow\) target_s : shape (N_rand, C)</li> <li>coords : H * W 개의 ray를 H-axis와 W-axis에서 인덱싱하기 위해 meshgrid of shape (H, W, 2) 생성 <ul> <li>초반부 iter. : 중심부 crop해서 meshgrid of shape (2 * dH, 2 * dW, 2) 생성</li> <li>후반부 iter. : meshgrid of shape (H, W, 2) 생성</li> <li>dim=2 : coords[:, :, 0]은 H-coord이고, coords[:, :, 1]은 W-coord</li> </ul> </li> <li>select_coords : shape (N_rand, 2)<br> H * W 개의 ray 중 N_rand-개를 randomly 고름</li> <li>batch_rays : shape (2, N_rand, 3)</li> <li>target_s : shape (N_rand, 3)</li> </ul> <h3 id="render">Render</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/16-480.webp 480w,/assets/img/2024-08-05-NeRFcode/16-800.webp 800w,/assets/img/2024-08-05-NeRFcode/16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/17-480.webp 480w,/assets/img/2024-08-05-NeRFcode/17-800.webp 800w,/assets/img/2024-08-05-NeRFcode/17-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/17.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input : <ul> <li>chunk : 동시에 처리할 수 있는 최대 ray 수 (due to maximum memory usage)</li> <li>c2w_staticcam : view-direction의 영향을 확인하고자 할 때 사용<br> 기존 c2w는 view-direction MLP input 만드는 데만 사용하고<br> c2w_staticcam으로 rendering 위한 rays_o, rays_d 다시 계산</li> </ul> </li> <li>output : <ul> <li>rgb_map : shape (B, 3)<br> predicted RGB values for B개의 rays</li> <li>disp_map : shape (B,)<br> disparity map (inverse of depth)</li> <li>acc_map : shape (B,)<br> sum of sample weights along each ray</li> <li>extras : 나머지 dict from render_rays()<br> fine-MLP를 사용하는 경우에만 존재 <ul> <li>rgb0, disp0, acc0 : from coarse-MLP</li> <li>z_std : shape (B,)<br> std of distances (\(t\) 값) of fine samples for each ray</li> </ul> </li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/19-480.webp 480w,/assets/img/2024-08-05-NeRFcode/19-800.webp 800w,/assets/img/2024-08-05-NeRFcode/19-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>rays : <ul> <li>if use_viewdirs = True : shape (N_rand, 8)<br> dim=1 : 3(rays_o) + 3(rays_d) + 1(near) + 1(far)</li> <li>if use_viewdirs = False : shape (N_rand, 11)<br> dim=1 : 3(rays_o) + 3(rays_d) + 1(near) + 1(far) + 3(viewdirs)</li> </ul> </li> <li>all_ret : dict <ul> <li>rgb_map : shape (N_rand, 3)</li> <li>disp_map : shape (N_rand,)</li> <li>acc_map : shape (N_rand,)</li> <li>raw : MLP raw output (raw2outputs() 안 한 것)</li> <li>rgb0, disp0, acc0 : from coarse-MLP</li> <li>z_std : shape (N_rand,)</li> </ul> </li> <li>render() output :<br> rgb_map, disp_map, acc_map, (나머지 모아놓은)-dict</li> </ul> <h4 id="ndc_rays">ndc_rays</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/18-480.webp 480w,/assets/img/2024-08-05-NeRFcode/18-800.webp 800w,/assets/img/2024-08-05-NeRFcode/18-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>shift ray origin to near plane :<br> NDC를 적용하기 전에 3D ray origin \(o\) 을 near plane 위 \(o_n\) 으로 옮긴다<br> (world-coordinate에서 ray가 near plane에서 출발하도록)<br> by \(o_n = o + t_nd\)<br> where z-axis에서는 \(-n = o_z + t_nd_z\) 이므로 \(t_n = \frac{-(n+o_z)}{d_z}\)<br> where n은 argument(near)</p> </li> <li> <p>project ray to NDC-space :<br> ray \(r = o_n + td\) 를 NDC로 projection했을 때<br> projected ray \(r^{\ast} = o^{\ast} + t^{\ast} d^{\ast}\) 에서<br> \(o^{\ast} = \begin{bmatrix} -\frac{f_{cam}}{\frac{W}{2}}\frac{o_{n_x}}{o_{n_z}} \\ -\frac{f_{cam}}{\frac{H}{2}}\frac{o_{n_y}}{o_{n_z}} \\ 1 + \frac{2n}{o_{n_z}} \end{bmatrix}\) where n은 argument(near)<br> and<br> \(t^{\ast} = \frac{td_z}{o_{n_z} + td_z} = 1 - \frac{o_{n_z}}{o_{n_z} + td_z}\)<br> and<br> \(d^{\ast} = \begin{bmatrix} -\frac{f_{cam}}{\frac{W}{2}}(\frac{d_x}{d_z} - \frac{o_{n_x}}{o_{n_z}}) \\ -\frac{f_{cam}}{\frac{H}{2}}(\frac{d_y}{d_z} - \frac{o_{n_y}}{o_{n_z}}) \\ -2n\frac{1}{o_{n_z}} \end{bmatrix}\) where n은 argument(near)</p> </li> </ul> <h4 id="batchify_rays">batchify_rays</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/20-480.webp 480w,/assets/img/2024-08-05-NeRFcode/20-800.webp 800w,/assets/img/2024-08-05-NeRFcode/20-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>Out-of-Memory를 방지하기 위해 N_rand-개의 rays를 더 작은 chunk (B개)로 쪼개서 rendering</p> </li> <li>ret : render_rays()의 output<br> dict <ul> <li>rgb_map : shape (B, 3)<br> predicted RGB values by alpha-compositing</li> <li>disp_map : shape (B,)<br> disparity map (inverse of depth)</li> <li>acc_map : shape (B,)<br> sum of sample weights along each ray</li> <li>raw : MLP raw output (raw2outputs() 안 한 것)</li> <li>rgb0, disp0, acc0 : from coarse-MLP</li> <li>z_std : shape (B,)<br> std of distances (\(t\) 값) of fine-samples for each ray</li> </ul> </li> <li>all_ret : B-개씩 쪼개서 rendering한 걸 다시 N_rand-개로 합침<br> dict <ul> <li>rgb_map : shape (N_rand, 3)</li> <li>disp_map : shape (N_rand,)</li> <li>acc_map : shape (N_rand,)</li> <li>raw : MLP raw output (raw2outputs() 안 한 것)</li> <li>rgb0, disp0, acc0 : from coarse-MLP</li> <li>z_std : shape (N_rand,)</li> </ul> </li> </ul> <h4 id="render_rays">render_rays</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/21-480.webp 480w,/assets/img/2024-08-05-NeRFcode/21-800.webp 800w,/assets/img/2024-08-05-NeRFcode/21-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>ray_batch of shape (B, 8) or (B, 11)로부터<br> rays_o, rays_d, near, far, viewdirs 분리</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/22-480.webp 480w,/assets/img/2024-08-05-NeRFcode/22-800.webp 800w,/assets/img/2024-08-05-NeRFcode/22-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/22.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Stratified Sampling of distance \(t\) for coarse-MLP :<br> z_vals : shape (B, N_samples) = (N_rays, N_samples)<br> stratified sampled distance \(t\) <ul> <li>Let 균등한 간격을 나타내는 \(t_{vals} \in [0, 1]\) has shape (N_samples,)</li> <li>if lindisp = False:<br> sample linearly in depth<br> \(z_{vals} = near \cdot (1-t_{vals}) + far \cdot (t_{vals})\)</li> <li>if lindisp = True:<br> sample linearly in inverse-depth<br> \(z_{vals} = \frac{1}{\frac{1}{near} \cdot (1-t_{vals}) + \frac{1}{far} \cdot (t_{vals})}\)</li> <li>if perturb = True:<br> add randomness</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/25-480.webp 480w,/assets/img/2024-08-05-NeRFcode/25-800.webp 800w,/assets/img/2024-08-05-NeRFcode/25-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/25.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> perturb=False이면 맨 윗줄을 coarse-samples로 쓰고, perturb=True이면 맨 아랫줄을 coarse-samples로 쓴다 </div> <ul> <li>pts, viewdirs : coarse-MLP input <ul> <li>pts : position info. \(r = o + td\) of shape (B, N_samples, 3)</li> <li>viewdirs : view-direction info. of shape (B, 3)</li> </ul> </li> <li>raw : coarse-MLP output<br> shape (B, N_samples, 4) where 4 : for RGB, opacity</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/23-480.webp 480w,/assets/img/2024-08-05-NeRFcode/23-800.webp 800w,/assets/img/2024-08-05-NeRFcode/23-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/23.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Inverse-transform Sampling of distance \(t\) for fine-MLP : <ul> <li>coarse-samples :<br> z_vals : shape (B, N_samples) = (N_rays, N_samples)</li> <li>fine-samples :<br> coarse-MLP의 MLP output raw에 대해 raw2outputs()로 구한 weights 값을 Fine-Sampling에 사용<br> z_samples : shape (B, N_importance)</li> <li>total sorted samples for fine-MLP :<br> z_vals : shape (B, N_samples + N_importance)</li> </ul> </li> <li>pts, viewdirs : fine-MLP input <ul> <li>pts : position info. \(r = o + td\) of shape (B, N_samples + N_importance, 3)</li> <li>viewdirs : view-direction info. of shape (B, 3)</li> </ul> </li> <li>raw : fine-MLP output<br> shape (B, N_samples + N_importance, 4) where 4 : RGB, opacity</li> </ul> <h4 id="sample_pdf">sample_pdf</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/29-480.webp 480w,/assets/img/2024-08-05-NeRFcode/29-800.webp 800w,/assets/img/2024-08-05-NeRFcode/29-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/29.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input : <ul> <li>z_vals_mid : shape (B, N_samples - 1)<br> stratified samples 사이의 중점</li> <li>weights[…, 1:-1] : shape (B, N_samples - 2)<br> 시작점, 끝점 빼고 weight of each stratified sample</li> <li>det : stratified samples에 randomness 부여했다면 False</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/27-480.webp 480w,/assets/img/2024-08-05-NeRFcode/27-800.webp 800w,/assets/img/2024-08-05-NeRFcode/27-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/27.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/28-480.webp 480w,/assets/img/2024-08-05-NeRFcode/28-800.webp 800w,/assets/img/2024-08-05-NeRFcode/28-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/28.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>pdf : shape (B, N_samples - 2)<br> \(\frac{w_i}{\sum_{j=1}^{num_{N_samples - 2}} w_j}\)</li> <li>cdf : shape (B, N_samples - 1)<br> \(F_i = \sum_{j=1}^{i-1} f_j\)<br> by torch.cumsum()<br> 각 row는 0 ~ 1 에서 점점 증가하는 수로 이루어져 있음</li> <li>u : shape (B, N_importance) <ul> <li>det가 True (no randomness)일 경우 :<br> \(\begin{bmatrix} 0 &amp; \frac{1}{N_{importance}-1} &amp; \cdots &amp; 1 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \end{bmatrix}\)</li> <li>det가 False (randomness)일 경우 :<br> 0 ~ 1 사이의 random float로 이루어져 있음</li> </ul> </li> <li>inds : shape (B, N_importance)<br> u를 cdf의 어디에 끼워넣을 수 있는지에 대한 index<br> by torch.searchsorted()</li> <li>below : shape (B, N_importance)<br> max(0, inds - 1)</li> <li>above : shape (B, N_importance)<br> min(N_samples - 2, inds)</li> <li>inds_g : shape (B, N_importance, 2) and range [0, N_samples - 1)<br> u가 위치할 수 있는 cdf의 두 경계의 index를 의미</li> <li>cdf_g : shape (B, N_importance, 2)<br> torch.gather(cdf.expand(), 2, inds_g)<br> inds_g에 따라 cdf의 값(확률값)을 추출해옴<br> where cdf.expand() : shape (B, N_importance, N_samples - 1)<br> where inds_g : shape (B, N_importance, 2) and range [0, N_samples - 1)</li> <li>bins_g : shape (B, N_importance, 2)<br> torch.gather(bins.expand(), 2, inds_g)<br> inds_g에 따라 bins의 값(coarse-samples 사이의 중점 \(t\) 값)을 추출해옴<br> where bins.expand() : shape (B, N_importance, N_samples - 1)<br> where inds_g : shape (B, N_importance, 2) and range [0, N_samples - 1)</li> <li>denom : shape (B, N_importance)<br> u가 위치할 수 있는 구간의 cdf 값 차이</li> <li>t : shape (B, N_importance)<br> u가 구간 내에서 차지하는 상대적인 위치</li> <li>samples : shape (B, N_importance)<br> fine samples의 \(t\) 값<br> bins_g[…, 0]과 bins_g[…, 1] 사이의 값</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/31-480.webp 480w,/assets/img/2024-08-05-NeRFcode/31-800.webp 800w,/assets/img/2024-08-05-NeRFcode/31-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/31.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> empty circles는 coarse(stratified) samples 사이의 중점(mid-point)의 t값 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/24-480.webp 480w,/assets/img/2024-08-05-NeRFcode/24-800.webp 800w,/assets/img/2024-08-05-NeRFcode/24-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/24.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>render_rays() output : dict <ul> <li>rgb_map : shape (B, 3)<br> predicted RGB values by alpha-compositing</li> <li>disp_map : shape (B,)<br> disparity map (inverse of depth)</li> <li>acc_map : shape (B,)<br> sum of sample weights along each ray</li> <li>raw : MLP raw output (raw2outputs() 안 한 것)</li> <li>rgb0, disp0, acc0 : from coarse-MLP</li> <li>z_std : shape (B,)<br> std of distances (\(t\) 값) of fine-samples for each ray</li> </ul> </li> </ul> <h4 id="raw2outputs">raw2outputs</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/26-480.webp 480w,/assets/img/2024-08-05-NeRFcode/26-800.webp 800w,/assets/img/2024-08-05-NeRFcode/26-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/26.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>input : <ul> <li>raw : shape (B, num_samples, 4)</li> </ul> </li> <li> <p>dists : shape (B, num_samples)<br> \(\delta_{i}\) : sample 간의 간격 in world-coordinate<br> sample 간의 간격 in t-coordinate 에 \(\| d \|\) 곱해서 구함<br> (dists[:, -1]은 마지막 sample부터 inf까지의 간격을 의미하는 매우 큰 수 1e10)</p> </li> <li> <p>rgb : shape (B, num_sample, 3)<br> \(c_i\) : raw-RGB에 sigmoid 씌운 값<br> sigmoid(raw[…, :3])<br> so that \(c_i \in (0, 1)\)</p> </li> <li> <p>alpha : shape (B, num_samples)<br> \(\alpha_{i} = 1 - \exp(- \sigma_{i} \delta_{i})\)<br> where \(\sigma_{i}\) : raw-opacity에 noise 더하고 relu 씌운 값<br> so that \(\sigma_{i} \in [0, \infty)\)</p> </li> <li> <p>weights : shape (B, num_samples)<br> \(w_i = \alpha_{i} \times T_i\)<br> where \(T_i = \prod_{j=1}^{i-1} (1-\alpha_{j}+1e-10)\) is obtained by torch.cumprod()</p> </li> <li>output : <ul> <li>rgb_map : shape (B, 3)<br> predicted RGB values<br> by volume rendering \(\hat{C}(r) = \sum_{i=1}^{num_{samples}} T_i \alpha_{i} c_i = \sum_{i=1}^{num_{samples}} w_i c_i\) <ul> <li>if white_bkgd (투명한 배경 대신 흰색) :<br> \(\hat{C}(r) = \sum_{i=1}^{num_{samples}} w_i c_i + (1 - \sum_{i=1}^{num_{samples}} w_i)\)<br> so that 투명해서 \(\sum_{i=1}^{num_{samples}} w_i\) 가 작을 때 RGB-color가 흰색(1.)에 가깝도록</li> </ul> </li> <li>disp_map : shape (B,)<br> disparity map (inverse of depth)<br> by \(\frac{1}{max(1e-10, \frac{\sum_{i=1}^{num_{samples}} w_i t_i}{\sum_{i=1}^{num_{samples}} w_i})}\)</li> <li>acc_map : shape (B,)<br> sum of sample weights along each ray<br> by \(\sum_{i=1}^{num_{samples}} w_i\)</li> <li>weights : shape (B, num_samples)<br> weight of each sample<br> \(w_i = \alpha_{i} \times T_i\)</li> <li>depth_map : shape (B,)<br> depth map (estimated distance to object)<br> by \(\sum_{i=1}^{num_{samples}} w_i t_i\)<br> (weight가 높은 깊이 값 \(t_i\) 을 더 많이 반영하는 식으로 weighted sum)</li> </ul> </li> </ul> <h3 id="evaluation">Evaluation</h3> <h4 id="img2mse-for-loss-and-mse2psnr-for-psnr">img2mse for loss and mse2psnr for psnr</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/32-480.webp 480w,/assets/img/2024-08-05-NeRFcode/32-800.webp 800w,/assets/img/2024-08-05-NeRFcode/32-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/32.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/30-480.webp 480w,/assets/img/2024-08-05-NeRFcode/30-800.webp 800w,/assets/img/2024-08-05-NeRFcode/30-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/30.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>loss = coarse-MLP-loss + fine-MLP-loss<br> where each is MSE loss b.w. predicted RGB and GT RGB of shape (N_rand, 3)</li> <li>PSNR : \(PSNR = -10 * log_{10}(loss)\)</li> <li>to8b : 0. ~ 1.에서 0 ~ 255 (8-bit)로 변환</li> </ul> <h4 id="test">test</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/34-480.webp 480w,/assets/img/2024-08-05-NeRFcode/34-800.webp 800w,/assets/img/2024-08-05-NeRFcode/34-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/34.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>args.i_video iter.마다<br> novel view(render_poses)에 대해 rendering해서<br> 여러 장의 rgb_map과 disp_map을 동영상으로 저장</li> <li>args.i_testset iter.마다<br> test view에 대해 rendering해서<br> 한 장의 rgb_map을 사진으로 저장</li> </ul> <h4 id="render_path">render_path</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-05-NeRFcode/33-480.webp 480w,/assets/img/2024-08-05-NeRFcode/33-800.webp 800w,/assets/img/2024-08-05-NeRFcode/33-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-08-05-NeRFcode/33.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>inference rendering (한 장씩)</li> <li>빠른 rendering을 위해 H, W, focal을 downsample</li> </ul> <h3 id="question">Question</h3> <ul> <li>Q1 : 왜 ndc_rays() 호출할 때 near bound n 값에 near = 1.으로 하드코딩해서 넣어주지?</li> <li>A1 : <code class="language-plaintext highlighter-rouge">????</code> </li> <li>Q2 : 왜 blender dataset에서 render_poses 만들 때 phi=-30. 으로 하드코딩해서 넣어주지?</li> <li>A2 : <code class="language-plaintext highlighter-rouge">????</code> </li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="semyeong-yu",disqus_identifier="/blog/2024/NeRFcode",disqus_title="NeRF-Code";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Semyeong Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YMLX9VHFX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5YMLX9VHFX");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>