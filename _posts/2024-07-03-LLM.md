---
layout: distill
title: LLM
date: 2024-07-03 14:00:00
description: Upstage Solar LLM
tags: generative LLM
categories: generative
thumbnail: assets/img/2024-07-03-LLM/1.png
giscus_comments: true
related_posts: true
# toc:
#   beginning: true
#   sidebar: right
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Solar LLM by Upstage

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-03-LLM/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div> 

### Solar Mini LLM

small-size  
best LLM for fine-tuning  
can be used as personalized LLM  

### Layout Analyzer

Extract layouts, tables, and figures from any document to .html file  

```Python
import os
from langchain_upstage import UpstageLayoutAnalysisLoader

os.environ["UPSTAGE_API_KEY"] = "UPSTAGE_API_KEY"

file_path = "invoice.png" # "pdfs/solar_sample.pdf"
loader = UpstageLayoutAnalysisLoader(file_path, split="page", use_ocr=True)

pages = loader.load()  # or loader.lazy_load()
for page in pages:
    print(page)
```

### Embedding

Solar-Embedding-1-Large (v1.0)  
Convert unstructured text data into embedding vectors  

```Python
from langchain_upstage import UpstageEmbeddings

embeddings = UpstageEmbeddings(
  api_key="UPSTAGE_API_KEY", 
  model="solar-embedding-1-large"
)
doc_result = embeddings.embed_documents(
    ["Sam is a teacher.", "This is another document"]
)
print(doc_result)

query_result = embeddings.embed_query("What does Sam do?")
print(query_result)
```

### In-context

### Fine-tuning

CFT (Continued Fine-Tuning) : feedback database에 기반하여 계속 fine-tuning  

```Python
adapter = pb.adapters.create(
  config=FinetuningConfig(
    base_model = "solar-1-mini-chat-240612",
    epochs = 1, # default: 3
    rank = 1, # default: 16
  ),
  dataset = pb_dataset, # also accepts the dataset name as str
  repo = repo,
  description = "initial model with defaults"
)
```

### Future of AI Ecosystem Hierarchy

Domain-specific and self-fine-tuned LLMs  
Solar LLM O/S  
O/S  
AI chips  