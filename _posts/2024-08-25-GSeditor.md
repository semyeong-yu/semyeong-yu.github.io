---
layout: distill
title: GaussianEditor
date: 2024-08-25 11:00:00
description: Swift and Controllable 3D Editing with Gaussian Splatting (CVPR 2024)
tags: GS 3d editing
categories: 3d-view-synthesis
thumbnail: assets/img/2024-08-25-GSeditor/2.png
giscus_comments: false
disqus_comments: true
related_posts: true
bibliography: 2024-08-25-GSeditor.bib
# toc:
#   beginning: true
#   sidebar: right
# featured: true
toc:
  - name: Related Work
  - name: Method
    subsections:
      - name: Gaussian Semantic Tracing
      - name: Hierarchical Gaussian Splatting
      - name: 3D inpainting
  - name: Experiments
  - name: Conclusion
  - name: Question
  
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting

#### Yiwen Chen, Zilong Chen, Chi Zhang, Feng Wang, Xiaofeng Yang, Yikai Wang, Zhongang Cai, Lei Yang, Huaping Liu, Guosheng Lin

> paper :  
[https://arxiv.org/abs/2311.14521](https://arxiv.org/abs/2311.14521)  
project website :  
[https://gaussianeditor.github.io/](https://gaussianeditor.github.io/)  
code :  
[https://github.com/buaacyw/GaussianEditor](https://github.com/buaacyw/GaussianEditor)  

## Introduction

생략

## Related Work

- NeRF-based 3D Editing :  
  - Instruct-nerf2nerf: Editing 3D scenes with instructions  
  - Ed-nerf: Efficient text-guided editing of 3D scene using latent space nerf
  - Clip-nerf: Text-and-Image driven manipulation of neural radiance fields
  - Nerf-art: Text-driven neural radiance fields stylization
  - Dreameditor: Text-driven 3D scene editing with neural fields

- NeRF-based 3D Editing by MLP의 문제점 :  
  - `specific` scene parts를 직접 수정하는 데 제한
  - inpainting 및 scene composition 과정이 `복잡`
  - strictly `masked area` 내에서만 editing 가능

- 3DGS-based 3D Editing의 문제점 :  
  - Editing할 Gaussian을 `identify`(분류)해야 함
  - Diffusion model로 얻은 `random generative guidance`를 3DGS에 적용할 때  
  randomness in loss로 인해  
  view마다 random한 image를 합성(Editing)하므로  
  GS is directly affected by randomness,  
  so 업데이트 불안정  
  - `수많은` Gaussian points를 업데이트해야 함  
  NeRF-based에서처럼 MLP NN buffering이 불가능하므로 불안정하여  
  finely detailed result로 수렴하는 걸 방해

## Method 

### Gaussian Semantic Tracing

- 전제 : 3DGS가 이미 잘 구성되어 있다고 가정하고, 특정 scene part를 제거 또는 추가하거나 inpainting하는 등 3D Editing 수행

- Gaussian Semantic Tracing :  
훈련하는 동안 3D Editing할 target을 trace하기 위해 semantic label(mask) 생성

#### Parameters

- $$x, s, q, \alpha , c$$ (position, covariance(scale, quaternion), opacity, color) 뿐만 아니라  
$$m_{ij}$$ (`semantic Gaussian mask` for i-th Gaussian and j-th semantic label) 추가

- densification할 때 clone/split된 points는 parent point의 semantic label를 그대로 물려받음

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-25-GSeditor/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    처음에 inaccurate segmentation mask에서 출발했더라도 Gaussian semantic tracing하는 동안 3DGS 업데이트하면서 semantic Gaussian mask도 알맞게 업데이트됨
</div>

#### Initial Labeling Process

- camera pose 하나 골라서 SAM(Segment Anything)으로 2D segmentation 수행한 뒤  
`inverse rendering`으로 2D mask를 3D Gaussian으로 unproject  
$$w_i^j = \Sigma o_i (p) \ast T_i^j (p) \ast M^j (p)$$  
where $$w_i^j$$ : weight of i-th Gaussian for j-th semantic label  
where $$o, T, M, p$$ : opacity, transmittance, mask, pixel

- average weight가 threshold를 넘는 경우에만 해당 i-th Gaussian이 j-th semantic class를 갖는다고 선별

### Hierarchical Gaussian Splatting

- Hierarchical Gaussian Splatting :  
stabilized and fine results 만들기 위해 anchor loss 사용

- `anchor loss` :  
  - densification할 때마다 `기존`의 Gaussian param.을 anchor에 record  
  - 3D Editing에 따라 변형되는 Gaussian param.가 각 anchor로부터 크게 벗어나지 않도록 함  
  $$L_{anchor}^P = \Sigma_{i=0}^n \lambda_{i} (P_i - \hat P_i)^2$$  
  where $$P : x, s, q, \alpha , c, m_{ij}$$  
  where $$\lambda_{i}$$ 값이 점점 증가 (새로 만들어지는 Gaussian param.의 영향이 크도록)
  - `stable` geometry formation under stochastic loss 보장

### 3D Inpainting

- `Edit loss` :  
  - 3DGS model로 rendering한 image와 diffusion model 간의 차이  
  $$L_{Edit} = D(\theta ; p, e)$$  
  where $$D, \theta , p, e$$ : Diffusion model, 3D model, camera pose, prompt
  - 2D diffusion model로 3D Editing하는 방법 :  
  1) DreamFusion <d-cite key="Dreamfusion">[1]</d-cite> 의 SDS loss처럼 3D model의 noised rendering과 other conditions를 2D diffusion model에 넣어준 뒤, `diffusion model이 내놓은 score`가 3D model의 업데이트 방향을 guide  
  2) 3D model의 rendering과 prompts 이용해서 2D Editing 수행하는 데 초점을 두고, 3D model에게 guidance 주기 위해 Edited 2D images를 training target으로 사용

- total loss :  
$$L = L_{Edit} + \Sigma_{P \in [x, s, q, \alpha , c]} \lambda_{P} L_{anchor}^P$$

- `Object Removal` :  
  - semantic label(mask) 가지는 3D Gaussian만 삭제하면 target object와 scene 사이의 interface에서 artifacts 생김
  - `precise mask`를 생성할 필요가 있음
    - 삭제한 3DGS와 가장 가까운 Gaussian을 KNN으로 identify  
    - 이를 다양한 view-points로 project하여 mask를 `확장` (dilate)
    - hole을 메꿔서 interface area를 정확하게 표현하도록 refined mask를 생성
  - `Diffusion model`을 이용해서 해당 area를 `2D inpainting` (object 삭제)
  - inpainted image를 기반으로 `3DGS 업데이트`

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-25-GSeditor/4.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- `Object Incorporation by text` :  
  - 앞 과정은 똑같음
  - `Stable Diffusion XL` model <d-cite key="SDXL">[2]</d-cite> 을 이용해서 해당 area에 `넣을 image`를 생성하고  
  fg object is segmented
  - `Wonder3D` model <d-cite key="Wonder3D">[3]</d-cite> 을 이용해서 fg-segmented image를 3D textured `mesh`로 변환  
  - Hierarchical Gaussian Splatting을 이용해서 mesh를 `3DGS`로 변환  
  - `DPT` <d-cite key="DPT">[4]</d-cite> 로 depth estimation해서 기존의 3DGS와 생성된 3DGS의 depth를 align해주고 concatenate

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-25-GSeditor/5.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-25-GSeditor/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Experiments

TBD

## Conclusion

TBD

## Question