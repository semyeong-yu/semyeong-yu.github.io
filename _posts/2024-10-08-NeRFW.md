---
layout: distill
title: NeRF in the Wild
date: 2024-10-08 12:00:00
description: Neural Radiance Fields for Unconstrained Photo Collections (CVPR 2021)
tags: nerf static transient uncertainty
categories: 3d-view-synthesis
thumbnail: assets/img/2024-10-08-NeRFW/0.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Introduction
  - name: Architecture - Static Network
  - name: Architecture - Transient Network
  - name: Volume Rendering
  - name: Optimization
  - name: Results
  - name: Conclusion
  - name: Limitation
  - name: Code
  - name: Question

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## NeRF in the Wild - Neural Radiance Fields for Unconstrained Photo Collections (CVPR 2021)

#### Ricardo Martin-Brualla, Noha Radwan, Mehdi S. M. Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth

> paper :  
[https://arxiv.org/abs/2008.02268](https://arxiv.org/abs/2008.02268)  
project website :  
[https://nerf-w.github.io/](https://nerf-w.github.io/)  
code :  
[https://github.com/kwea123/nerf_pl/tree/nerfw?tab=readme-ov-file](https://github.com/kwea123/nerf_pl/tree/nerfw?tab=readme-ov-file)  
[https://github.com/rover-xingyu/Ha-NeRF](https://github.com/rover-xingyu/Ha-NeRF)  
youtube video :  
[https://www.youtube.com/watch?v=mRAKVQj5LRA&t=254s](https://www.youtube.com/watch?v=mRAKVQj5LRA&t=254s)  
reference :  
NeRF and 3DGS Study

### Introduction

- Issue :  
  - Q : image 상의 동적인 물체를 어떻게 없앨 수 있을까?
  - A : `Static Network`와 `Transient Network`를 분리한 뒤  
  $$c, \sigma$$ 에 대한 `Uncertainty`를 측정하자!

- Contribution :  
  - Latent Appearance Embedding in Static Network :  
  각 image의 광도 반영
  - Latent Transient Embedding in Transient Network :  
  동적인 물체 구별
  - Loss w. Uncertainty and Transient density 

- 결과 :  
  - Latent Embedding Vector 변화로 Appearance에 변화 줄 수 있음
  - 일시적으로 찍힌 동적인 물체를 제거할 수 있음

### Architecture - Static Network

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Static Network :  
우리가 Novel View Synthesis 하고 싶어하는 대상을 다룸

- View Direction과 함께 Appearance Embedding Vector 넣어준다는 것 말고는 기존 NeRF 구조와 same
  - $$\gamma_{x}(r(t)) \rightarrow \sigma_{i}(t)$$ (3d shape)
  - $$\gamma_{x}(r(t)), \gamma_{d}(d), l_{i}^{(a)} \rightarrow c_{i}(t)$$ (view-dependent 3d color)

- Appearance Embedding Vector :  
  - image의 embedding vector (각 image의 광도 반영)
  - random initialization (learnable)
  - control처럼 쓰일 수 있음  
  Embedding Vector 수정하여 Appearance(스타일)에 변화 줄 수 있음
  - training dataset에 대해 $$l_{i}^{(a)}$$ 를 학습하므로  
  test할 때는 target image에 적합할 만한 Embedding Vector 골라서 사용

### Architecture - Transient Network

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Transient Network :  
  - 우리가 Novel View Synthesis 하고 싶어하는 대상이 아닌,  
  동적인 물체를 다룸 (제거하기 위해)
  - Bayesian learning framework를 적용하여 `???` Uncertainty를 모델링

- Transient Embedding $$l_{i}^{(T)}$$ 을 넣어서 동적인 물체의 transient density를 얻은 뒤 제거 가능  
  - $$\gamma_{x}(r(t)), l_{i}^{(T)} \rightarrow c_{i}^{(T)}(t), \sigma_{i}^{(T)}(t), \tilde \beta_{i}(t)$$
  - $$\beta_{i}(t) = \beta_{min} + \text{log}(1+\text{exp}(\tilde \beta_{i}(t)))$$

### Volume Rendering

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Training : (a) Static, (b) Transient 모두 사용하여 아래의 rendering 식으로 (c) Composite 만들고, 이를 (d) GT와 비교하여 학습  
$$\hat C_{i} (r) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k) + \alpha(\sigma_{i}^{(T)}(t_k) \delta_{k}) c_{i}^{(T)}(t_k))$$  
where $$T_{i}(t_k) = \text{exp}(-\sum_{k^{'}=1}^{k-1}(\sigma_{i}(t_{k^{'}}) + \delta_{i}^{(T)}(t_{k^{'}}))\delta_{k^{'}})$$

- Test : (a) Static만 사용

### Optimization

- Coarse Model :  
(기존 NeRF와 유사하게) static network만 사용해서 Appearance Embedding Vector를 학습  
$$L = \sum_{ij} L_{c}(r_{ij})$$  
  - $$L_{c}(r_{ij}) = \frac{1}{2} \| C(r_{ij}) - \hat C^{c}(r_{ij}) \|^2$$  
  where $$\hat C^{c}(r_{ij}) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k))$$  
  (static network만 사용)

- Fine Model :  
static, transient network 모두 사용해서 학습  
$$L = \sum_{ij} L_{f}(r_{ij}) + L_{c}(r_{ij})$$  
  - $$L_{c}(r_{ij}) = \frac{1}{2} \| C(r_{ij}) - \hat C^{c}(r_{ij}) \|^2$$  
  where $$\hat C^{c}(r_{ij}) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k))$$  
  (static network만 사용)
  - $$L_{f}(r_{ij}) = \frac{\| C(r_{ij}) - \hat C^{f}(r_{ij}) \|^2}{2\beta(r)^2} + \frac{\text{log} \beta(r)^2}{2} + \frac{\lambda}{K} \sum_{k=1}^K \sigma^{(T)}(t_k)$$  
  where $$\hat C^{f}(r_{ij}) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k) + \alpha(\sigma_{i}^{(T)}(t_k) \delta_{k}) c_{i}^{(T)}(t_k))$$  
  (static, trasient network 모두 사용)
    - 1번째 term : `recon. loss term`  
    Uncertainty $$\beta(r)$$ 가 크면 recon. loss 영향력 작아짐  
    (동적인 물체가 있어서 불확실한 부분은 loss 및 gradient 작게)
    - 2번째 term : `regularization term`  
    Uncertainty $$\beta(r)$$ 가 너무 커지지 않도록 regularize
    - 3번째 term : `regularization term`  
    transient density $$\sigma^{(T)}$$ 가 너무 커지지 않도록 regularize

### Results

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/4.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/5.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Conclusion

- 동적이고 조명이 바뀌는 상황에서 촬영된 image dataset으로도 neural rendering 가능
  - Appearance Embedding : 각 image의 광도를 반영
  - Transient Embedding : target static object를 가리는 동적인 물체 구별하여 제거

### Limitation

- training 개수, camera calibration error에 민감

### Code

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/6.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/7.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Question

- Q1 :  
$$\hat C_{i} (r) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k) + \alpha(\sigma_{i}^{(T)}(t_k) \delta_{k}) c_{i}^{(T)}(t_k))$$  
위의 volume rendering 식을 보면 static network의 color, density와 transient network의 color, density가 함께 하나의 pixel color로 rendering되어 동시에 backpropagation되는데  
어떻게 두 network 중에서 하필 transient network의 color, density가 동적인 물체를 구별하는 역할을 수행할 수 있느냐

- A1 :  
Coarse Model(static network 사용)과 Fine Model(static, transient network 모두 사용)을 two-stage로 분리해서 학습하기 때문에 transient network가 동적인 물체를 식별하는 역할을 잘 수행할 수 있을 것이다  
(NeRF and 3DGS 스터디원 피셜)