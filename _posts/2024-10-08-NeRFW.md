---
layout: distill
title: NeRF in the Wild
date: 2024-10-08 12:00:00
description: Neural Radiance Fields for Unconstrained Photo Collections (CVPR 2021)
tags: nerf static transient uncertainty
categories: 3d-view-synthesis
thumbnail: assets/img/2024-10-08-NeRFW/0.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Introduction
  - name: Architecture - Static Network
  - name: Architecture - Transient Network
  - name: Volume Rendering
  - name: Optimization
  - name: Results
  - name: Conclusion
  - name: Code
  - name: Question

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## NeRF in the Wild - Neural Radiance Fields for Unconstrained Photo Collections (CVPR 2021)

#### Ricardo Martin-Brualla, Noha Radwan, Mehdi S. M. Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth

> paper :  
[https://arxiv.org/abs/2008.02268](https://arxiv.org/abs/2008.02268)  
project website :  
[https://nerf-w.github.io/](https://nerf-w.github.io/)  
code :  
[https://github.com/kwea123/nerf_pl/tree/nerfw?tab=readme-ov-file](https://github.com/kwea123/nerf_pl/tree/nerfw?tab=readme-ov-file)  
[https://github.com/rover-xingyu/Ha-NeRF](https://github.com/rover-xingyu/Ha-NeRF)  
reference :  
NeRF and 3DGS Study

### Introduction

- Issue :  
  - Q : image 상의 동적인 물체를 어떻게 없앨 수 있을까?
  - A : `Static Network`와 `Transient Network`를 분리한 뒤  
  $$c, \sigma$$ 에 대한 `Uncertainty`를 측정하자!

- Contribution :  
  - Latent Appearance Modeling
  - Transient Objects
  - Optimization Loss

- 결과 :  
  - Latent Embedding Vector 변화로 Appearance에 변화 줄 수 있음
  - 일시적으로 찍힌 동적인 물체를 제거할 수 있음

### Architecture - Static Network

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Static Network :  
우리가 Novel View Synthesis 하고 싶어하는 대상을 다룸

- View Direction과 함께 Appearance Embedding Vector 넣어준다는 것 말고는 기존 NeRF 구조와 same
  - $$\gamma_{x}(r(t)) \rightarrow \sigma_{i}(t)$$ (3d shape)
  - $$\gamma_{x}(r(t)), \gamma_{d}(d), l_{i}^{(a)} \rightarrow c_{i}(t)$$ (view-dependent 3d color)

- Appearance Embedding Vector :  
  - image의 embedding vector
  - random initialization (learnable)
  - control처럼 쓰일 수 있음  
  Embedding Vector 수정하여 Appearance(스타일)에 변화 줄 수 있음
  - training dataset에 대해 $$l_{i}^{(a)}$$ 를 학습하므로  
  test할 때는 target image에 적합할 만한 Embedding Vector 골라서 사용

### Architecture - Transient Network

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Transient Network :  
우리가 Novel View Synthesis 하고 싶어하는 대상이 아닌  
동적인 물체를 다룸 (제거하기 위해)

- Transient Embedding $$l_{i}^{(T)}$$ 을 넣어서 동적인 물체의 transient density를 얻은 뒤 제거 가능  
  - $$\gamma_{x}(r(t)), l_{i}^{(T)} \rightarrow c_{i}^{(T)}(t), \sigma_{i}^{(T)}(t), \tilde \beta_{i}(t)$$
  - $$\beta_{i}(t) = \beta_{min} + \text{log}(1+\text{exp}(\tilde \beta_{i}(t)))$$

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-10-08-NeRFW/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Volume Rendering

$$\hat C_{i} (r) = \sum_{k=1}^K T_{i}(t_k)(\alpha(\sigma_{i}(t_k) \delta_{k}) c_{i}(t_k) + \alpha(\sigma_{i}^{(T)}(t_k) \delta_{k}) c_{i}^{(T)}(t_k))$$  
where $$T_{i}(t_k) = \text{exp}(-\sum_{k^{'}=1}^{k-1}(\sigma_{i}(t_{k^{'}}) + \delta_{i}^{(T)}(t_{k^{'}}))\delta_{k^{'}})$$

### Optimization

- loss :  
$$L = \sum_{ij} L_{f}(r_{ij}) + L_{c}(r_{ij})$$  
  - Coarse :  
  $$L_{c}(r_{ij}) = TBD$$
  - Fine :  
  $$L_{f}(r_{ij}) = TBD$$

### Results

### Conclusion

### Code

### Question

