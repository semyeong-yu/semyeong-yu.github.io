---
layout: distill
title: Spacetime Gaussian
date: 2025-02-08 10:00:00
description: Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis (CVPR 2024)
tags: dynamic 3DGS
categories: 3d-view-synthesis
thumbnail: assets/img/2025-02-08-STGS/1.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Contribution
  - name: Method
    subsections:
      - name: Spacetime Gaussians
      - name: Splatted Feature Rendering
      - name: Loss
      - name: Guided Sampling of Gaussians
  - name: Experiment
    subsections:
      - name: Result
      - name: Ablation Study
  - name: Limitation
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis (CVPR 2024)

#### Zhan Li, Zhang Chen, Zhong Li, Yi Xu

> paper :  
[https://arxiv.org/abs/2312.16812](https://arxiv.org/abs/2312.16812)  
project website :  
[https://oppo-us-research.github.io/SpacetimeGaussians-website/](https://oppo-us-research.github.io/SpacetimeGaussians-website/)  
code :  
[https://github.com/oppo-us-research/SpacetimeGaussians](https://github.com/oppo-us-research/SpacetimeGaussians)  
blog reference :  
[https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/spacetime-gaussian/](https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/spacetime-gaussian/)

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/1.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Contribution

- Spacetime Gaussian (STG) :  
3DGS를 dynamic 4D scene으로 확장하기 위해  
`time-dependent opacity, motion trajectory(mean), rotation` 사용

- Splatted Feature Rendering :  
spherical harmonics (`SH`) coeff. `대신`  
base color, view direction info., time info.를 encoding하는 `feature` $$f_{i}(t) \in R^{9}$$ 사용

- Guided Sampling of Gaussians :  
initialization 할 때 Gaussian이 희박한 먼 영역은 흐릿해지는 경향이 있는데,  
이를 해결하기 위해 `학습 오차와 coarse depth를 guidance`로 삼아  
4D scene에서 `새로운 Gaussian을 sampling`

## Method

### Spacetime Gaussians

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/2.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- `temporal-and-spatial opacity` :  
$$\alpha_{i}(\boldsymbol x, t) = \sigma_{i}(t) \text{exp}(-\frac{1}{2} (\boldsymbol x - \mu_{i}(t))^{T} \Sigma_{i}(t)^{-1} (\boldsymbol x - \mu_{i}(t)))$$  
(temporal opacity $$\sigma_{i}(t)$$ 가 위치 $$\boldsymbol x$$ 에 따라 희석됨)  
where $$\sigma_{i}(t)$$ : temporal opacity  
where $$\mu_{i}(t), \Sigma_{i}(t)$$ : time-dependent mean, covariance

- `Temporal Radial Basis Function` (`temporal opacity`) :  
$$\sigma_{i}(t) = \sigma_{i}^{s} \text{exp}(-s_{i}^{\tau} | t - \mu_{i}^{\tau} |^{2})$$  
where `temporal center` $$\mu_{i}^{\tau}$$ : $$i$$-th STG $$G_{i}$$ 가 가장 잘 보이는 timestamp  
where `temporal scaling factor` $$s_{i}^{\tau}$$ : valid 지속 기간 결정  
where temporal-independent `spatial opacity` $$\sigma_{i}^{s}$$
  - 1D Gaussian으로 모델링!  
  즉, timestamp $$t$$ 가 temporal center $$\mu_{i}^{\tau}$$ 에서 멀어질수록 opacity $$\sigma_{i}^{s}$$ 가 옅어짐!
  - 시간에 따라 변하는 `opacity` $$\sigma_{i}(t)$$ 을 통해  
  `새로 나타나거나 사라지는` object를 효과적으로 모델링할 수 있음!

- `Polynomial Motion Trajectory` :  
$$\mu_{i}(t) = \sum_{k=0}^{n_{p}} b_{i,k}(t - \mu_{i}^{\tau})^{k}$$
  - polynomial로 모델링!  
  - polynomical coeff. $$b_{i,k} \in R$$ 은 learnable param.
  - 시간에 따라 변하는 `mean` $$\mu_{i}(t)$$ 을 통해  
  object `motion`을 모델링할 수 있음!

- `Polynomial Rotation` :  
$$q_{i}(t) = \sum_{k=0}^{n_{q}} c_{i,k}(t - \mu_{i}^{\tau})^{k}$$
  - polynomial로 모델링!
  - polynomical coeff. $$c_{i,k} \in R$$ 은 learnable param.
  - 시간에 따라 변하는 `quaternion` $$q_{i}(t)$$ 을 통해  
  object `변형`을 모델링할 수 있음!

- time-independent Scale :  
  - Scaling matrix $$S_{i}$$ 는 시간에 독립적

### Splatted Feature Rendering

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/3.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- `Feature Splatting` :  
  - `color`의 경우 view direction 뿐만 아니라 시간에 따라 변하므로  
  `spherical harmonics (SH) coeff.` 대신  
  `feature` $$f_{i}(t) = [f_{i}^{base}, f_{i}^{dir}, (t - \mu_{i}^{\tau}) f_{i}^{time}]^{T} \in R^{9}$$ 로 대체!
    - RGB base color : $$f_{i}^{base} \in R^{3}$$
    - view direction : $$f_{i}^{dir} \in R^{3}$$
    - time : $$f_{i}^{time} \in R^{3}$$
  - RGB color (SH coeff.) 대신 feature $$f_{i}(t)$$ 를 image-space로 splatting한 뒤  
  2-layer MLP $$\Phi$$ 를 거쳐 최종 RGB color를 얻음  
  $$I = F^{base} + \Phi(F^{dir}, F^{time}, \boldsymbol r)$$  
    - feature $$f_{i}(t)$$ 를 image-space로 splatting한 feature를 $$F^{base}, F^{dir}, F^{time}$$ 으로 분할
    - target view direction : $$\boldsymbol r$$
  - 장점 :  
    - less param. than SH coeff. encoding
    - still fast rendering using shallow MLP $$\Phi$$
  - light 버전 :  
  rendering speed를 최대화하기 위해 선택적으로 MLP $$\Phi$$ 를 삭제하고 $$F^{base}$$ 만 유지

### Loss

- learnable param. :  
  - temporal `opacity` :  
    - time-independent spatial opacity $$\sigma_{i}^{s}$$
    - temporal scaling factor $$s_{i}^{\tau}$$
    - temporal center $$\mu_{i}^{\tau}$$
  - time-dependent `motion` (trajectory) :  
    - polynomial coeff. $$\{ b_{i,k} \}_{k=0}^{n_{p}}$$
  - time-dependent `rotation` (quaternion) :  
    - polynomial coeff. $$\{ c_{i,k} \}_{k=0}^{n_{q}}$$
  - time-dependent `color` :  
    - feature $$f_{i}^{base}, f_{i}^{dir}, f_{i}^{time}$$

- loss :  
photometric loss (L1, D-SSIM)

### Guided Sampling of Gaussians

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/4.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- issue :  
initialization 할 때 `Gaussian이 희박한 먼 영역은 흐릿`해지는 경향이 있음

- solution :  
  - 이를 해결하기 위해 `학습 오차`와 `coarse depth`를 guidance로 삼아  
  4D scene에서 새로운 Gaussian을 sampling
  - sampling 효율성을 보장하기 위해  
  `loss가 안정된 후`에 sampling 진행
  - Procedure :  
    - Step 1)  
    학습 오차에 noise가 있을 수 있으므로  
    patch-wise로 학습 오차를 계산하여 상당한 오차가 있는 patch 찾기
    - Step 2)  
    학습 오차가 큰 patch의 중앙 pixel의 ray를 따라 Gaussian들을 sampling  
    (coarse depth map을 이용해 Gaussian들이 희박한 깊이 범위를 찾은 뒤 해당 범위에서 uniform sampling)  
    (3회 이하로 수행)
      - feature sampling 중에 생성되는 coarse depth map을 이용하므로  
      additional overhead 거의 없음
      - 새로 sampling된 Gaussian들의 mean에 작은 noise를 추가  
      (불필요한 Gaussian들은 학습 중에 자연스레 opacity가 낮아져 remove됨)
  - 의의 :  
  `3DGS density control을 보완`  
  (3DGS density control은 기존 Gaussian들 근처에서 점진적으로 Gaussian들을 증가시키는데,  
  본 논문의 Guided Sampling은 Gaussian들이 희박한 새로운 영역에서 Gaussians들을 sampling)

## Experiment

- Implementation :  
$$n_{p}=3, n_{q}=1$$  
Adam optimizer  
initialize Spacetime Gaussians using SfM pcd of all timestamps  
density control의 pruning을 3DGS보다 더 공격적으로 수행하여 Gaussian 수를 줄이고 모델 크기 작게 유지  
40~60 min. for 50 frames on NVIDIA A6000 GPU

### Result

- Neural 3D Video Dataset :  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/5.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/6.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Google Immersive Dataset :  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/7.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/8.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Technicolor Dataset :  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/9.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Ablation Study

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/10.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-08-STGS/11.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Limitation

- Limitation :  
  - need SfM for Spacetime Gaussians' Initialization
  - per-Scene model (`???` maybe)