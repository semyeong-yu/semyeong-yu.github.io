---
layout: distill
title: Mip-NeRF 360
date: 2024-08-11 01:03:00
description: Unbounded Anti-Aliased Neural Radiance Fields
tags: nerf rendering 3d multiscale antialiasing
categories: 3d-view-synthesis
thumbnail: assets/img/2024-08-11-MipNeRF360/1.png
bibliography: 2024-08-11-MipNeRF360.bib
giscus_comments: false
disqus_comments: true
related_posts: true
# toc:
#   beginning: true
#   sidebar: right
featured: true
toc:
  - name: Introduction
  - name: Scene and Ray Parameterization
  - name: Coarse-to-Fine Online Distillation
  - name: Regularization for Interval-Based Models
  - name: Optimization
  - name: Results
  - name: Conclusion
  - name: Question
  - name: Code Review
  - name: Appendix
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields

#### Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P. Srinivasan, Peter Hedman 

> paper :  
[https://arxiv.org/abs/2111.12077](https://arxiv.org/abs/2111.12077)  
project website :  
[https://jonbarron.info/mipnerf360/](https://jonbarron.info/mipnerf360/)  
pytorch code :  
[https://github.com/google-research/multinerf](https://github.com/google-research/multinerf)

> 핵심 요약 :  
1. ddd

## Introduction

- 임의의 `direction`(360 degrees)과 임의의 `depth`로 `unbounded` 되어있는 scene 문제 해결  
  - non-linear scene parameterization :  
  임의의 방향과 깊이에 대한 unbounded scene 다룰 수 있음
  - online-distillation :  
  higher capacity MLP을 조금만 evaluate해서 효율적으로 large scene 다룰 수 있음
  - distortion-based regularizer :  
  artifacts 줄이기 위한 regularization

- NeRF model을 large unbounded scene에 적용하는 데 3가지 문제가 있다  
(자세한 내용은 스킵했는데 나중에 읽어보자)  
  - Parametrization : Mip-NeRF는 3D coordinate가 bounded domain 안에 있는 경우만 처리 가능
  - Efficiency : large-and-detailed scene은 large MLP를 필요로 해서 expensive
  - Ambiguity : scene content가 임의의 distance에 있고 이는 only 적은 수의 ray로 관찰되기 때문에 inherent ambiguity 발생

## Scene and Ray Parameterization

### Ray Interval Parameterization

- Ray Interval Parameterization :  
samples의 경우 distance가 아니라 그의 역수인 `disparity에 비례`하여 분포하도록 하면  
가까이 있는 content는 많이 sampling하고 멀리 있는 content는 덜 sampling함으로써  
`임의의 scale의 unbounded scene`을 잘 다룰 수 있음

- NeRF :  
  - NeRF에서는 distance에 비례하여 stratified uniform sampling 했음  
  - 만약 NDC parameterization을 쓰면  
  disparity (distance의 역수)에 비례하여 uniform sampling 한 것과 같은 효과를 가지고 `?????`  
  - 그런데 NDC는 single direction으로만 unbounded된 scene (front-facing camera)에 대해서만 적합하고  
  모든 방향으로 unbounded된 scene에 대해서는 적합하지 않음  

- Mip-NeRF 360 :  
  - 처음부터 ray interval을 disparity (distance의 역수)에 비례하도록 <d-cite key="LLFF">[2]</d-cite> parameterize 한다  
  - contract 함수도 마찬가지로 disparity에 비례하여 scene content를 mapping하므로  
  scene origin에서 cast된 ray가 disparity에 비례한 spacing을 가졌을 경우  
  contract 함수를 counter-balance하여  
  contract 함수를 적용한 후에는 위 그림의 주황색 영역에서  
  일정한 길이의 interval을 가진다

### Ray Interval Parameterization in Disparity

- distance along ray를 t-space 또는 s-space에서 나타내자  
  - t-space :  
  Euclidean ray distance $$t \in [t_n, t_f]$$  
  $$t = g^{-1}(s \cdot g(t_f) + (1-s) \cdot g(t_n))$$  
  - s-space :  
  normalized ray distance $$s \in [0, 1]$$  
  $$s = \frac{g(t)-g(t_n)}{g(t_f)-g(t_n)}$$  

- 사용 예시 :  
  - $$g(x) = \frac{1}{x}$$ 로 설정할 경우  
  `s-space에서 uniform sampling`하면  
  `t-space에서 disparity에 비례`하여 distributed  
  - $$g(x) = log(x)$$ 로 설정할 경우  
  s-space에서 uniform sampling하면  
  t-space에서는 logarithmic spacing <d-cite key="DONeRF">[3]</d-cite> 으로 distributed  

- 기존 NeRF 모델에서는 t-distance를 따라 sampling했지만  
본 논문에서는 `s-distance`를 따라 sampling하여 나타낸다

### Scene Parameterization

- Scene Parameterization :  
unbounded scene을 radius-2 내부의 `bounded space`로 나타내기 위해 `contract 함수`를 사용  
ray parameterization을 할 때 disparity에 비례하게 분포하도록 했으므로  
contract 함수도 `여전히 disparity에 비례`하게 분포하도록 bounded space로 mapping

- Define smooth coordinate-transformation function as $$f(x) : R^3 \rightarrow R^3$$  
  - $$f(x) \approx f(\mu) + J_{f}(\mu)(x-\mu)$$ (linear approx.)  
  $$f(\mu, \Sigma) = (f(\mu), J_{f}(\mu) \Sigma J_{f}(\mu)^T)$$  
  - 이는 state transition model $$f = \text{contract}(x) = \begin{cases} x & \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) & \text{if} \| x \| \gt 1 \end{cases}$$ 에 대해  
  classic Extended Kalman filter <d-cite key="kalman">[1]</d-cite> 와 수학적으로 동일
  - MipNeRF360에서는 contract 함수를  
  `point가 아니라` Euclidean 3D-space에 있는 `Gaussian`에 적용!  
  또한  
  `모든 방향` (360 degress)에 대해 적용!  

- IPE (integrated positional encoding) :  
  - Mip-NeRF :  
  $$\gamma (\mu, \Sigma) = \left[ \begin{bmatrix} sin(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \\ cos(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \end{bmatrix} \right]_{l=0}^{l=L-1}$$  
  - Mip-NeRF 360 :  
  $$\gamma (\text{contract}(\mu, \Sigma))$$  
  where $$\text{contract}(x) = \begin{cases} x & \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) & \text{if} \| x \| \gt 1 \end{cases}$$  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    contract 함수는 파란색 구(radius 1) 외부의 Gaussian(회색)을 주황색 영역(radius 1 ~ 2)의 Gaussian(빨간색)으로 mapping
</div>


## Coarse-to-Fine Online Distillation

- 기존 NeRF :  
coarse-MLP와 fine-MLP

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    위의 그림은 Mip-NeRF, 아래의 그림은 Mip-NeRF 360
</div>

- Mip-NeRF 360 :  
proposal-MLP와 NeRF-MLP  
  - `small` proposal-MLP는 `many` samples로 `여러 번` evaluate하고,  
  `large` NeRF-MLP는 `less` samples로 `딱 한 번` evaluate함으로써  
  Mip-NeRF보다 조금만 더 costly하지만 훨씬 더 `higher capacity`를 가진 것과 같은 효과  
  $$\rightarrow$$ 효율적으로 `large unbounded scene`을 표현하기에 적절  
  distill 효과가 좋아서 proposal-MLP의 경우 크기 줄이더라도 accuracy 감소하지 않음
  - small proposal-MLP :  
    - color 말고 volume density만 예측하여 weight $$\hat w$$ 구함
  - large NeRF-MLP :  
    - color, volume density 예측하여 weight $$w$$ 구하고 rendering
  
- Loss :  
  - `reconstruction loss` :  
    - large NeRF-MLP에서 rendering해서 구함  
    기존 NeRF 방식과 동일  
    - `NeRF-MLP 업데이트`
  - `proposal loss` :  
    - Mip-NeRF 계열은 point가 아니라 interval 별로 weight를 구하므로 histogram을 만들 수 있음
    - proposal-MLP의 histogram ($$\hat t, \hat w$$)와 NeRF-MLP의 histogram ($$t$$, $$w$$)가 consistent하도록 함  
    - `proposal-MLP 업데이트`  
    (`weight-histogram이 consistent`하도록  
    `online distillation` of NeRF-MLP's knowledge into proposal-MLP)
    - 문제 :  
    하나의 histogram bin의 distribution에 대해 아무 것도 가정할 수가 없어서  
    (하나의 bin의 distribution이 uniform일 수도 있고 특정 지점에 몰빵된 delta function일 수도 있음...)  
    $$\hat t$$ 와 $$t$$ 의 bins가 매우 다를 수 있음  
    - 가정 :  
    두 개의 histogram이 `어떤 하나의 (true continuous underlying) single mass distribution으로 설명될 수 있다면`  
    둘의 차이인 loss는 0 이다
    - NeRF-MLP ($$t$$, $$w$$)의 구간 $$T$$ 와 겹치는 모든 proposal-MLP의 weight $$\hat w_{j}$$ 를 더해서 아래와 같이 `upper bound`를 구하자  
    $$\text{bound}(\hat t, \hat w, T) = \sum_{j: T \cap \hat T_{j} \neq \emptyset} \hat w_{j}$$  
    만약 두 개의 histogram이 consistent하다면, NeRF-MLP ($$t$$, $$w$$)의 모든 구간 ($$T_i, w_i$$)에 대해  
    $$w_i \leq \text{bound}(\hat t, \hat w, T_i)$$ 이어야 한다  
    $$\rightarrow$$  
    아래와 같이 `proposal loss는 이를 위반하는 경우`에 해당한다  
    $$L_{prop}(t, w, \hat t, \hat w) = \sum_{i}\frac{1}{w_i} \text{max}(0, w_i - \text{bound}(\hat t, \hat w, T_i))^2$$  

TBD  
This loss resembles a half-quadratic version ...

## Regularization for Interval-Based Models

TBD

## Optimization

TBD

## Results

TBD

## Conclusion

TBD

## Question

- Q&A reference : 3DGS online study
- Q1 : 아래의 문구가 이해되지 않습니다  
recall that the “bins” of those histograms $$t$$ and $$\hat t$$ need not be similar; indeed, if the proposal MLP successfully culls the set of distances where scene content exists, $$\hat t$$ and $$t$$ will be highly dissimilar
- A1 :

## Code Review

TBD

## Appendix

TBD