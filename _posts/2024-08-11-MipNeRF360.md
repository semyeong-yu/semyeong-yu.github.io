---
layout: distill
title: Mip-NeRF 360
date: 2024-08-11 01:03:00
description: Unbounded Anti-Aliased Neural Radiance Fields
tags: nerf rendering 3d multiscale antialiasing
categories: 3d-view-synthesis
thumbnail: assets/img/2024-08-11-MipNeRF360/1.png
bibliography: 2024-08-11-MipNeRF360.bib
giscus_comments: false
disqus_comments: true
related_posts: true
# toc:
#   beginning: true
#   sidebar: right
featured: true
toc:
  - name: Introduction
  - name: Scene and Ray Parameterization
    subsections:
      - name: Ray Interval Parameterization
      - name: Ray Interval Parameterization in Disparity
      - name: Scene Parameterization
  - name: Coarse-to-Fine Online Distillation
  - name: Regularization for Interval-Based Models
  - name: Optimization
  - name: Results
  - name: Conclusion
  - name: Question
  - name: Code Review
  - name: Appendix
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields

#### Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P. Srinivasan, Peter Hedman 

> paper :  
[https://arxiv.org/abs/2111.12077](https://arxiv.org/abs/2111.12077)  
project website :  
[https://jonbarron.info/mipnerf360/](https://jonbarron.info/mipnerf360/)  
pytorch code :  
[https://github.com/google-research/multinerf](https://github.com/google-research/multinerf)

> 핵심 요약 :  
0. sampling 기법 개선하고, bounded scene으로 warp
1. non-linear scene parameterization :  
disparity에 비례하도록 sampling 개선하고  
bounded space로 mapping하여  
임의의 방향과 깊이에 대한 unbounded scene 다룸
2. online-distillation :  
higher capacity MLP을 조금만 evaluate해서  
효율적으로 large scene 다룸  
3. distortion-based regularizer :  
artifacts 줄이기 위해  
step-function을 delta-function에 가깝게 regularize

## Introduction

- 임의의 `direction`(360 degrees)과 임의의 `depth`로 `unbounded` 되어있는 scene 문제 해결  
  - non-linear scene parameterization :  
  sampling 개선하고 bounded space로 mapping하여  
  임의의 방향과 깊이에 대한 unbounded scene 다룰 수 있음
  - online-distillation :  
  higher capacity MLP을 조금만 evaluate해서 효율적으로 large scene 다룰 수 있음
  - distortion-based regularizer :  
  artifacts 줄이기 위한 regularization

- NeRF model을 large unbounded scene에 적용하는 데 3가지 문제가 있다  
(자세한 내용은 스킵했는데 나중에 읽어보자)  
  - Parametrization : Mip-NeRF는 3D coordinate가 bounded domain 안에 있는 경우만 처리 가능
  - Efficiency : large-and-detailed scene은 large MLP를 필요로 해서 expensive
  - Ambiguity : scene content가 임의의 distance에 있고 이는 only 적은 수의 ray로 관찰되기 때문에 inherent ambiguity 발생

## Scene and Ray Parameterization

### Ray Interval Parameterization

- Ray Interval Parameterization :  
samples의 경우 distance가 아니라 그의 역수인 `disparity에 비례`하여 분포하도록 하면  
가까이 있는 content는 많이 sampling하고 멀리 있는 content는 덜 sampling함으로써  
`임의의 scale의 unbounded scene`을 잘 다룰 수 있음

- NeRF :  
  - NeRF에서는 distance에 비례하여 stratified uniform sampling 했음  
  - 만약 NDC parameterization을 쓰면  
  disparity (distance의 역수)에 비례하여 uniform sampling 한 것과 같은 효과를 가짐 `?????`  
  - 그런데 NDC는 single direction으로만 unbounded된 scene (front-facing camera)에 대해서만 적합하고  
  모든 방향으로 unbounded된 scene에 대해서는 적합하지 않음  

- Mip-NeRF 360 :  
  - 처음부터 ray interval을 disparity (distance의 역수)에 비례하도록 <d-cite key="LLFF">[2]</d-cite> parameterize 한다  

### Ray Interval Parameterization in Disparity

- distance along ray를 t-space 또는 s-space에서 나타내자  
  - t-space :  
  Euclidean ray distance $$t \in [t_n, t_f]$$  
  $$t = g^{-1}(s \cdot g(t_f) + (1-s) \cdot g(t_n))$$  
  - s-space :  
  normalized ray distance $$s \in [0, 1]$$  
  $$s = \frac{g(t)-g(t_n)}{g(t_f)-g(t_n)}$$  

- 사용 예시 :  
  - $$g(x) = \frac{1}{x}$$ 로 설정할 경우  
  `s-space에서 uniform sampling`하면  
  `t-space에서 disparity에 비례`하여 distributed  
  - $$g(x) = log(x)$$ 로 설정할 경우  
  s-space에서 uniform sampling하면  
  t-space에서는 logarithmic spacing <d-cite key="DONeRF">[3]</d-cite> 으로 distributed  

- 기존 NeRF 모델에서는 t-distance를 따라 uniform sampling했지만  
본 논문에서는 `s-distance`를 따라 uniform sampling하여 나타낸다

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/4.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Scene Parameterization

- Scene Parameterization :  
unbounded scene을 radius-2 내부의 `bounded space`로 mapping하기 위해 `contract 함수`를 사용  
ray parameterization을 할 때 disparity에 비례하게 sampling 했으므로  
contract 함수도 consistently `disparity에 비례`하게 bounded space로 mapping  
$$\rightarrow$$ scene origin에서 cast된 ray의 경우 contract 함수를 적용한 후에는 아래 그림의 주황색 영역에서 일정한 길이의 interval을 가진다

- Define smooth coordinate-transformation function as $$f(x) : R^3 \rightarrow R^3$$  
  - $$f(x) \approx f(\mu) + J_{f}(\mu)(x-\mu)$$ (linear approx.)  
  $$f(\mu, \Sigma) = (f(\mu), J_{f}(\mu) \Sigma J_{f}(\mu)^T)$$  
  - 이는 state transition model $$f = \text{contract}(x) = \begin{cases} x & \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) & \text{if} \| x \| \gt 1 \end{cases}$$ 에 대해  
  classic Extended Kalman filter <d-cite key="kalman">[1]</d-cite> 와 수학적으로 동일
  - MipNeRF360에서는 contract 함수를  
  `point가 아니라` Euclidean 3D-space에 있는 `Gaussian`에 적용!  
  또한  
  `모든 방향` (360 degress)에 대해 적용!  

- IPE (integrated positional encoding) :  
  - Mip-NeRF :  
  $$\gamma (\mu, \Sigma) = \left[ \begin{bmatrix} sin(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \\ cos(2^l \mu) \circledast exp(-\frac{1}{2} 4^l diag(\Sigma)) \end{bmatrix} \right]_{l=0}^{l=L-1}$$  
  - Mip-NeRF 360 :  
  $$\gamma (\text{contract}(\mu, \Sigma))$$  
  where $$\text{contract}(x) = \begin{cases} x & \text{if} \| x \| \leq 1 \\ (2 - \frac{1}{\| x \|})(\frac{x}{\| x \|}) & \text{if} \| x \| \gt 1 \end{cases}$$  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    contract 함수는 파란색 구(radius 1) 외부의 Gaussian(회색)을 주황색 영역(radius 1 ~ 2)의 Gaussian(빨간색)으로 mapping
</div>


## Coarse-to-Fine Online Distillation

- 기존 NeRF :  
coarse-MLP와 fine-MLP

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    위의 그림은 Mip-NeRF, 아래의 그림은 Mip-NeRF 360
</div>

- Mip-NeRF 360 :  
proposal-MLP와 NeRF-MLP  
  - `small` proposal-MLP는 `many` samples로 `여러 번` evaluate하고,  
  `large` NeRF-MLP는 `less` samples로 `딱 한 번` evaluate함으로써  
  Mip-NeRF보다 조금만 더 costly하지만 훨씬 더 `higher capacity`를 가진 것과 같은 효과  
  $$\rightarrow$$ 효율적으로 `large unbounded scene`을 표현하기에 적절  
  distill 효과가 좋아서 proposal-MLP의 경우 크기 줄이더라도 accuracy 감소하지 않음
  - small proposal-MLP :  
    - color 말고 volume density만 예측하여 weight $$\hat w$$ 구함
  - large NeRF-MLP :  
    - color, volume density 예측하여 weight $$w$$ 구하고 rendering
  
- Loss :  
아래 두 가지 loss로 각 MLP를 jointly train  
  - `reconstruction loss` :  
    - large NeRF-MLP에서 rendering해서 구함  
    기존 NeRF 방식과 동일  
    - `GT-image를 supervision`으로 하여 `NeRF-MLP만 업데이트`
  - `proposal loss` :  
    - 두 MLP의 `weight histogram이 consistent`하도록 함  
    (Mip-NeRF 계열은 point가 아니라 interval 별로 weight를 구하므로 histogram을 만들 수 있음)  
    - `NeRF-MLP의 weight를 supervision`으로 하여 `proposal-MLP만 업데이트`  
    (`online distillation` of NeRF-MLP's knowledge into proposal-MLP)
    - 문제 :  
    하나의 histogram bin의 distribution에 대해 아무 것도 가정할 수 없음  
    (하나의 bin의 distribution이 uniform일 수도 있고 특정 지점에 몰빵된 delta function일 수도 있음...)  
    coarse $$\hat t$$ 와 fine $$t$$ (bins)가 매우 다를 수 있음  
    - 가정 :  
    두 개의 histogram이 매우 달라보이더라도  
    둘 다 `어떤 하나의 동일한 (underlying continuous) true mass distribution으로부터 유래되었다고 설명할 수 있다면` 둘의 차이인 loss는 0 이다
    - 위의 가정에 따라  
    NeRF-MLP ($$t$$, $$w$$)의 구간 $$T$$ 와 겹치는 모든 proposal-MLP의 weight $$\hat w_{j}$$ 를 더해서 아래와 같이 NeRF-MLP weight $$w$$ 의 `upper bound`를 구하자  
    $$\text{bound}(\hat t, \hat w, T) = \sum_{j: T \cap \hat T_{j} \neq \emptyset} \hat w_{j}$$  
    ($$t$$ 와 $$\hat t$$ 가 정렬되어 있으므로 summed-area table로 효율적으로 계산 가능)
    - 만약 두 개의 histogram이 consistent하다면,  
    NeRF-MLP ($$t$$, $$w$$)의 모든 구간 ($$T_i, w_i$$)에 대해  
    $$w_i \leq \text{bound}(\hat t, \hat w, T_i)$$ 이어야 한다  
    $$\rightarrow$$  
    아래와 같이 `proposal loss는 이를 위반하는 경우`에 해당한다  
    $$L_{prop}(t, w, \hat t, \hat w) = \sum_{i}\frac{1}{w_i} \text{max}(0, w_i - \text{bound}(\hat t, \hat w, T_i))^2$$  
    - proposal loss가 asymmetirc loss인 이유 :  
    proposal-MLP가 NeRF-MLP보다 coarse하기 때문에  
    proposal-MLP weight가 NeRF-MLP weight의 upper bound를 형성하는 게 (overestimate) 당연하고,  
    proposal-MLP weight가 NeRF-MLP weight를 underestimate ($$\text{bound}(\hat t, \hat w, T_i) < w_i$$) 하는 경우에만 penalize
    - proposal loss term에서 $$w_i$$ 로 나누는 이유 :  
    bound가 0일 때 $$\frac{dL_{prop}}{d\text{bound}} = \sum_{i} \frac{1}{w_i} \cdot 2 \cdot \text{max}(0, w_i - \text{bound}) \cdot (-1) = -2\sum_{i}1$$ 와 같이  
    gradient 값이 $$w_i$$ 크기와 상관없이 상수값이 되어 균등하게 penalize하여 optimization에 도움됨 

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    fine NeRF-MLP는 점점 scene content의 surface 쪽으로 weight가 집중되고, coarse proposal-MLP는 이를 따라잡으며 upper bound를 형성
</div>


## Regularization for Interval-Based Models

- Artifacts :  
NeRF 계열은 pose 문제 때문에 두 가지 주된 artifacts가 나타난다  
  - `floater` :  
  특정 view를 너무 잘 설명하려던 나머지  
  실제로 물체가 존재하지 않는 small disconnected regions of dense volume에서 불필요하게 opacity를 예측하여  
  다른 view에서 보면 반투명한 blurry cloud처럼 보이는 부분  
  - `background collapse` :  
  멀리 있는 surface가  
  반투명한 가까운 content로 잘못 모델링된 경우  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/5.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    반투명하게 떠다니는 게 floater, 좌하단에서 background surface가 가깝게 보이는 게 background collapse
</div>

- Artifacts 완화 :  
  - 기존 NeRF : `random noise`  
  [NeRF-Code](https://semyeong-yu.github.io/blog/2024/NeRFcode/) 의 raw2outputs()에서 볼 수 있듯이  
  raw-opacity에 random noise 더해서 $$\sigma_{i}$$ 구함  
  noise 덕분에 `불필요한 특정 지점에 overfit 되는 게 아니라 일관성 있게` 학습  
  But, 부분적으로 artifacts 완화하고 reconstruction quality를 떨어뜨림
  - Mip-NeRF 360 : `regularize`  
  ray-sampling은 이미 했고 weight를 구할 때  
  `물체가 있을만한 정확한 지점에서 집중적으로 예측`하여  
  `부정확한 지점에서의 불필요한 예측을 억제`  

- Regularization for Interval-Based Models :  
  - weight-histogram (step-function) $$s, w$$ 을 regularize하기 위해  
  $$L_{dist}(s, w) = \int \int_{-\infty}^{\infty} w_s(u)w_s(v)|u-v|d_ud_v$$  
  - 위의 loss를 최소화하기 위해선  
  $$w$$ 를 매우 작은 $$|u-v|$$ 에 몰빵하면 된다  
  즉, 위의 loss term만 있을 경우 histogram(step-function)이 delta-function에 가까워지면 된다  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/6.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    TBD
</div>

- Regularization for Interval-Based Models :  
TBD

## Optimization

TBD

## Results

TBD

## Conclusion

TBD

## Question

- Q&A reference : 3DGS online study
- Q1 : 아래의 문구가 이해되지 않습니다  
recall that the “bins” of those histograms $$t$$ and $$\hat t$$ need not be similar; indeed, if the proposal MLP successfully culls the set of distances where scene content exists, $$\hat t$$ and $$t$$ will be highly dissimilar
- A1 : 아래 사진의 (c)에서처럼 충분히 optimize되어 만약 coarse proposal-MLP가 이미 scene content가 있는 곳을 성공적으로 예측하고 있다면 이를 이용한 fine NeRF-MLP의 fine-samples는 그 곳에 더 촘촘히 존재할 것이므로 bin 간격이 달라져서 두 histogram이 크게 달라보인다  
달라보이더라도 두 개의 histogram이 어떤 하나의 (true continuous underlying) mass distribution에서 유래되었다고 설명할 수 있으면 둘의 차이가 0이라고 가정하여 upper bound를 이용해서 proposal loss 만듬

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-08-11-MipNeRF360/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Q2 : 갑자기 든 생각인데 Mip-NeRF 360의 sampling 기법과 contract 함수가 background collapse의 원인이 될 수도 있지 않을까요?  
disparity에 비례하게 sampling하므로 먼 거리에 대해서는 덜 sampling한 채로 bounded space로 warp하는데,  
먼 거리의 content에 대해 정보가 부족한 채로 warp하는 과정에서 왜곡이 일어날 수 있을 것 같다
- A2 : 그럴 수 있을 것 같습니다

## Code Review

TBD

## Appendix

TBD