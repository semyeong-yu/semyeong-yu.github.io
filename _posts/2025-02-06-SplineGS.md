---
layout: distill
title: SplineGS
date: 2025-02-06 10:00:00
description: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video
tags: dynamic colmap free motion adaptive monocular
categories: 3d-view-synthesis
thumbnail: assets/img/2025-02-06-SplineGS/1.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Contribution
  - name: Related Works
  - name: Method
    subsections:
      - name: Architecture
      - name: Motion-Adaptive Spline for 3DGS
      - name: Camera Pose Estimation
      - name: Loss
  - name: Experiment
    subsections:
      - name: Implementation
      - name: Result
      - name: Ablation Study
  - name: Conclusion
  - name: Question
bibliography: 2025-02-06-SplineGS.bib
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## SplineGS - Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video

#### Jongmin Park, Minh-Quan Viet Bui, Juan Luis Gonzalez Bello, Jaeho Moon, Jihyong Oh, Munchurl Kim

> paper :  
[https://arxiv.org/abs/2412.09982](https://arxiv.org/abs/2412.09982)  
project website :  
[https://kaist-viclab.github.io/splinegs-site/](https://kaist-viclab.github.io/splinegs-site/)  

## Contribution

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-06-SplineGS/1.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- summary :  
  - per-Scene model (maybe `???`)
  - `COLMAP-free` novel-view-synthesis for `dynamic` scenes from `in-the-wild monocular` videos, `thousands` time faster than SOTA  
  by applying `spline-based` model to dynamic `3DGS trajectories`

- novelty :  
  - Motion-Adaptive Spline (MAS) :  
  continuous dynamic `3DGS trajectories` (deformation) 을 효율적으로 모델링하기 위해  
  `cubic Hermite splines` with a small number of control points 사용  
    - control point :  
      - learnable param.  
      - determines each piecewise cubic func.'s curvature and direction
  - Motion-Adaptive Control points Pruning (MACP) :  
  quality, efficiency 모두 챙기기 위해 계속 `control points를 prune`하여 수 조절
  - joint optimization strategy :  
  `photometric and geometric consistency` 이용해서  
  (external estimators 필요 X)  
  `camera param.` 와 `3DGS param.`를 jointly optimize  
  (COLMAP-free!)

## Related Works

- dynamic novel-view-synthesis :  
  - implicit representation `(MLP) 이용하여 deformation 모델링` in canonical space <d-cite key="Deform1">[1]</d-cite>, <d-cite key="Deform2">[2]</d-cite>, <d-cite key="Deform3">[3]</d-cite>, <d-cite key="Deform4">[4]</d-cite>, <d-cite key="Deform5">[5]</d-cite>
    - 단점 : 아무리 tiny MLP더라도 computational `overhead` and low speed
  - 4D space-time domain을 `multiple 2D planes로 decompose`하는 grid-based model <d-cite key="Grid1">[6]</d-cite>, [4DGS](https://semyeong-yu.github.io/blog/2024/4DGS/), <d-cite key="Grid3">[7]</d-cite>, <d-cite key="Grid4">[8]</d-cite>
    - 단점 : grid representation으로는 scene의 dynamic 특징의 `fine detail을 fully capture할 수 없음`
  - `polynomial trajectories` 적용 <d-cite key="trajectory">[9]</d-cite> 
    - 장점 : efficient
    - 단점 : polynomial trajectory의 `fixed degree`는 complex motion을 표현하는 flexibility 측면에서 제한적임

- spline :  
  - minimal number of control points로 complex shape를 smooth and continuous representation으로 표현할 수 있음

- SplineGS (본 논문) :  
  - 논문 <d-cite key="Mosca">[10]</d-cite>, <d-cite key="GauFRe">[11]</d-cite>에서처럼  
  각각 static bg와 moving object를 표현하기 위해  
  3DGS를 `static 3DGS와 dynamic 3DGS의 union`으로 확장 
    - static region :  
    diffuse and specular features는 보존한 채  
    time-encoded feature는 제거
    - dynamic region :  
    mean $$\mu_{i}$$ 는 deformation modeling에 의해 결정되는 time-dependent var.  
    rotation $$q_{i}$$ 와 scale $$s_{i}$$ 도 time-dependent var.
  - 논문 [STGS](https://semyeong-yu.github.io/blog/2025/STGS/)에서처럼  
  final pixel `color`를 예측할 때 splatted feature rendering 사용 (`SH coeff. 대신 feature`!) 

## Method

### Architecture

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-02-06-SplineGS/2.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- goal :  
jointly optimize 3DGS param. and camera param.
  - camera param. :  
  extrinsic $$[\hat R_{t} | \hat T_{t}] \in R^{3 \times 4}$$ for each time $$t$$  
  and shared intrinsic $$\hat K \in R^{3 \times 3}$$ across all $$t$$
  - how :  
  two-stage optimization  
  (warm-up stage and main traning stage)
    - `warm-up stage` :  
    optimize `coarse camera param.`  
    using photometric and geometric consistency  
    (`SfM 사용하지 않기 위해!`)
    - `main training stage` :  
    initialize 3DGS based on the estimated camera poses  
    and  
    jointly optimize 3DGS param. and camera param. with MAS and MACP

### Motion-Adaptive Spline for 3DGS

time $$t$$ 에서 each dynamic 3DGS의 mean $$\mu(t)$$ (continuous trajectory)를 모델링하기 위해  
cubic Hermite spline function with a set of learnable control points 사용 (MAS)  
즉, each dynamic Gaussian마다 a set of control points가 있고 얘네들의 spline curve로 Gaussian mean $$\mu(t)$$ 을 결정!

- Motion-Adaptive Spline (MAS) :  
$$\mu(t) = S(t, \boldsymbol P)$$  
  - input :  
    - time $$t$$
    - a set of $$N_{c}$$ learnable control points $$\boldsymbol P = \left\{ \boldsymbol p_{k} | \boldsymbol p_{k} \in R^{3} \right\}_{k \in [0, N_{c}-1]}$$
  - piece-wise cubic Hermite spline function $$S(\cdot)$$ :  
  $$S(t, \boldsymbol P) = (2t_{r}^{3} - 3t_{r}^{2} + 1) \boldsymbol p_{\lfloor t_{s} \rfloor} + (t_{r}^{3} - 2t_{r}^{2} + t_{r}) \boldsymbol m_{\lfloor t_{s} \rfloor} + (-2t_{r}^{3} + 3t_{r}^{2}) \boldsymbol p_{\lfloor t_{s} \rfloor + 1} + (t_{r}^{3} - t_{r}^{2}) \boldsymbol m_{\lfloor t_{s} \rfloor + 1}$$  
    - $$N_{f}$$ : frame (timestamp) 개수
    - $$N_{c}$$ : control point 개수 (estimated by MACP)
    - $$t \in [0, N_{f} - 1]$$
    - $$t_{s} = t \frac{N_{c} - 1}{N_{f} - 1} \in [0, N_{c} - 1]$$  
    e.g. 3.7
    - $$t_{r} = t_{s} - \lfloor t_{s} \rfloor$$  
    e.g. 0.7
    - $$\boldsymbol m_{k} = (\boldsymbol p_{k+1} - \boldsymbol p_{k-1})/2$$ : approx. tangent(기울기) of control point $$\boldsymbol p_{k}$$  
    - `piece-wise cubic Hermite spline function` :  
    $$\lfloor t_{s} \rfloor = 3$$ 에서의 control point 및 tangent와  
    $$\lfloor t_{s} \rfloor + 1 = 4$$ 에서의 control point 및 tangent와  
    그 사이 어디쯤 있는지 $$t_{r} = 0.7$$ 를 이용하여  
    $$\lfloor t_{s} \rfloor = 3$$ 과 $$\lfloor t_{s} \rfloor + 1 = 4$$ 사이의 piece-wise cubic Hermite spline function을 그림

- `Initialization of 3D Control Points`  :  
intialization은 quality에 매우 중요!  
long-range `2D track` <d-cite key="cotracker">[12]</d-cite>과 `depth` <d-cite key="unidepth">[13]</d-cite> prior 사용
  - notation :  
    - 2D track by <d-cite key="cotracker">[12]</d-cite> : $$\mathcal{T} = \left\{ \varphi_{t}^{tr} | \varphi_{t}^{tr} \in R^{2} \right\}_{t \in [0, N_{f} - 1]}$$  
    where $$\varphi_{t}^{tr}$$ : 2D track on pixel-coordinate at time $$t$$
    - projection func. from 3D camera-space to 2D image-space by intrinsic $$K$$ : $$\pi_{K}(\cdot)$$
  - Step 1)  
  `unproject 2D track` $$\mathcal{T}$$ on image-space into 3D track on world-space  
  using depth $$d_{t}$$ and extrinsic $$[\hat K_{t} | \hat T_{t}]$$  
  $$W_{t}(\varphi_{t}^{tr}) = \hat R_{t}^{T} \pi_{\hat K}^{-1}(\varphi_{t}^{tr}, d_{t}(\varphi_{t}^{tr})) - \hat R_{t}^{T} \hat T_{t}$$
    - we estimate camera param. $$\hat K, \hat R, \hat T$$ from only frames (without any GT)
  - Step 2)  
  initialize per-Gaussian control points set $$\boldsymbol P$$  
  by least-square approx. s.t. `spline curve` $$S(t, \boldsymbol P)$$ fits the initial `tracker curve` $$W_{t}(\varphi_{t}^{tr})$$  
  $$\text{min}_{\boldsymbol P} \sum_{t=0}^{N_{f} - 1} \| W_{t}(\varphi_{t}^{tr}) - S(t, \boldsymbol P) \|^{2}$$

- Motion-Adaptive Control Points Pruning (MACP) :  
  - issue :  
    - control points 수가 너무 많으면  
    spline curve가 over-fitting되고 speed가 느려짐  
    - scene마다 motion의 종류와 정도가 각기 다르므로  
    control points 수 for each dynamic 3DGS 는 scene에 맞춰서 need to be adaptively adjusted
  - solution :  
  sparser control points로 prune하기 위해  
  `every 3DGS densification이 끝날 때마다` new spline function $$\mu(t) = S(t, \boldsymbol P')$$ 계산  
  where $$\boldsymbol P' = \left\{ \boldsymbol p_{l}' | \boldsymbol p_{l}' \in R^{3} \right\}_{l \in [0, N_{c} - 2]}$$ : a set of $$N_{c} - 1$$ control points  
  (current set $$\boldsymbol P$$ 보다 control point 1개 더 적음)
  - Step 1)  
  `1개 적은 control point set`으로도 최대한 비슷한 spline curve를 만들도록 least-square approx.  
  $$\text{min}_{\boldsymbol P'} \sum_{t=0}^{N_{f}-1} \| S(t, \boldsymbol P) - S(t, \boldsymbol P') \|^{2}$$
  - Step 2)  
  $$S(t, \boldsymbol P)$$ 와 $$S(t, \boldsymbol P')$$ 간의 error $$E$$ 가 작을 때만 a set of control points 업데이트  
  $$\boldsymbol P = \begin{cases} \boldsymbol P' & \text{if} & E \lt \epsilon \\ \boldsymbol P & O.W.$$  
  where error $$E = \frac{1}{N_{f}} \sum_{t=0}^{N_{f} - 1} \| \pi_{\hat K}(\hat R_{t} S(t, \boldsymbol P) + \hat T_{t}) - \pi_{\hat K} (\hat R_{t} S(t, \boldsymbol P') + \hat T_{t} \|^{2}$$  
  (각 timestamp $$t$$ 에서 `3D mean on spline curve를 2D로 project시킨 뒤 차이` 비교)
  - 의의 :  
  each dynamic 3DGS마다 a set of control points를 따로 가지고 있는데,  
  MACP 덕분에 각 dynamic 3DGS가 각기 다른 수의 control points를 가질 수 있고,  
  `motion이 복잡한 part는 control points 수가 많고`  
  `motion이 단순한 part는 control poitns 수가 적은` 방식으로  
  scene에 adaptively adjust 가능
    
### Camera Pose Estimation

- Camera Pose :  
  - `extrinsic` :  
  $$[\hat R_{t} | \hat T_{t}] = F_{\theta}(\gamma(t))$$  
    - extrinsic 은 `time에 대한 function`
    - notation :  
      - $$\gamma(\cdot)$$ : positional encoding
      - $$F_{\theta}$$ : shallow MLP
  - intrinsic (`focal length`) :  
    - focal length $$\hat f$$ 는 learnable param. `shared across all frames` in monocular video  

- Loss for optimizing Camera Pose :  
  - Loss 1) `photometric consistency` :  
  시각적으로 align하기 위해  
  ㅇㅇㅇ
  - Loss 2) `geometric consistency` :  
  구조적으로 align하기 위해  
  ㅇㅇㅇ

### Loss

## Experiment

### Implementation

### Result

### Ablation Study

## Conclusion

## Question

아직 Figure 2. 안 봄!! TBD