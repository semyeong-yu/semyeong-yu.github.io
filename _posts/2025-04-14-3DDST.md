---
layout: distill
title: 3DDST
date: 2025-04-14 12:00:00
description: Generating Images with 3D Annotations Using Diffusion Models (ICLR 2024 Spotlight)
tags: postprocessing single step diffusion
categories: 3d-view-synthesis
thumbnail: assets/img/2025-04-14-3DDST/2.PNG
# bibliography: 2025-04-14-3DDST.bib
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Background
  - name: Method
  - name: Result
  - name: Conclusion
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## 3DDST - Generating Images with 3D Annotations Using Diffusion Models (ICLR 2024 Spotlight)

#### Wufei Ma, Qihao Liu, Jiahao Wang, Angtian Wang, Xiaoding Yuan, Yi Zhang, Zihao Xiao, Guofeng Zhang, Beijia Lu, Ruxiao Duan, Yongrui Qi, Adam Kortylewski, Yaoyao Liu, Alan Yuille

> paper :  
[https://arxiv.org/abs/2306.08103](https://arxiv.org/abs/2306.08103)  
project website :  
[https://ccvl.jhu.edu/3D-DST/](https://ccvl.jhu.edu/3D-DST/)  

> 핵심 :  
3D structure(shape) 정보를 담고 있는, CAD model로부터 render한 image의 edge map을  
ControlNet의 visual prompts (3D geometry control)로 넣어줌으로써  
Diffusion model이 특정 3D structure를 가진 image를 generate할 수 있게 함!  
즉, Diffusion model generates new images where its 3D geometry can be explicitly controlled

## Background

- ControlNet :  
  - TBD

## Method

### Overview

- Contribution :  
  - 기존 diffusion models는 generated image의 3D geometry를 control할 수 없다는 한계를 직접 해결
  - 3D shape 정보를 가진 3D geometry control을 넣어줌으로써  
  Diffusion model이 specific 3D structure를 가진 images를 generate할 수 있음  
  즉, shape-aware training process enables Diffusion model to generate new images where its 3D geometry can be explicitly controlled
  - ShapeNet, Pix3D 등 다양한 3D object dataset으로 evaluate함으로써  
  이전 diffusion model에 비해 본 논문의 3D-aware diffusion model이 generated images' 3D shape control을 얼마나 잘 하는지 보여줌  
  (3D shape similarity 등의 metrics로 평가)
    - useful for applications like 3D modeling, product design, and VR where the precise 3D object shape is important

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-04-14-3DDST/1.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### Prompt Generation

- 3D Visual Prompt Generation :  
ShapeNet, Objaverse, OmniObject3D로부터 3D CAD model을 얻은 뒤  
3D CAD model로부터 render한 image의 edge map을 visual prompt (3D geometry control)로 사용
  - rendered image by 3D CAD model from ShapeNet, Objaverse, OmniObject3D  
  $$\rightarrow$$ edge map by Canny edge filter  
  $$\rightarrow$$ 3D voxel grid representation by MLP  
  $$\rightarrow$$ combine 3D structure info. from 3D voxel grid features and 2D appearance info. from 2D image features

- Text Prompt Generation :  
not only produce images with higher realsim and diversity  
but also improve OOD robustness of models pre-trainded on our 3DDST data
  - initial text prompt : class name $$w$$ + keyword of CAD model $$k$$
  - text prompt : improve the diversity and richness by LLM

## Result

- Failure Case :  
  - 한계 :  
  image with challenging and uncommon viewpoints  
  e.g. car from below, guitar from side
  - 대응 :  
  K-fold consistency filter (KCF)를 적용하여  
  ensemble model의 predictions를 기반으로  
  good images를 일부 제거하더라도 failed images를 자동으로 제거함으로써  
  good images의 비율을 높임
    - KCF는 여전히 limited..  
    diffusion-generated dataset에서 failed samples를 감지하고 제거하는 건 여전히 challenging problem

- Data Release :  
  - Aligned CAD models from 1000 classes in ImageNet-1k [Link](https://huggingface.co/datasets/ccvl/3D-DST-models) :  
  ImageNet-1k의 각 class에 대해  
  ShapeNet, Objaverse, OmniObject3D로부터 3D CAD model을 얻은 뒤  
  CAD model의 canonical pose를 align
  - LLM-generated captions for 1000 classes in ImageNet-1k [Link](https://huggingface.co/datasets/ccvl/3D-DST-captions)
  - 3D-DST data for 1000 classes in ImageNet-1k [Link](https://huggingface.co/datasets/ccvl/3D-DST-data) :  
  위의 3D Visual Prompt, Text Prompt를 이용하여 generate한 3D-DST image

## Conclusion

- Limitation :  
  - increased computational cost, complexity, training time, model size  
  by additional 3D shape encoding
    - can be a barrier to real-world deployment
  - evaluation is focused on 비교적 간단한 3D object datasets
    - need to be generalized to more complex, real-world 3D scenes and geometires
  - 3D shape control이 다른 desired attributes(photorealism, semantic consistency, coherence 등)와 얼마나 잘 합쳐지는 지 balancing하는 건 앞으로 diffusion model architectures 및 training procedures 개선과 함께 고려되어야 함