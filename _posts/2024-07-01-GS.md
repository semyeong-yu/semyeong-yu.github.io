---
layout: distill
title: Gaussian Splatting
date: 2024-07-01 10:00:00
description: 3D GS for Real-Time Radiance Field Rendering
tags: gaussian splatting rendering 3d view synthesis
categories: 3d-view-synthesis
thumbnail: assets/img/2024-07-01-GS/1.png
giscus_comments: true
related_posts: true
bibliography: 2024-07-01-GS.bib
# toc:
#   beginning: true
#   sidebar: right
featured: true
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## 3D Gaussian Splatting for Real-Time Radiance Field Rendering

#### Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, George Drettakis

> paper :  
[https://arxiv.org/abs/2308.04079](https://arxiv.org/abs/2308.04079)  
project website :  
[https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)  
code :  
[https://github.com/graphdeco-inria/gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting)  
referenced blog :  
[https://xoft.tistory.com/51](https://xoft.tistory.com/51)


> 핵심 요약 :  
1. DD

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-01-GS/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Abstract

- novel 3D Gaussian scene representation with real-time differentiable renderer  
`수많은 3D Gaussian이 모여 scene을 구성`하고 있다!
- Very Fast rendering ($$\geq$$ 100 FPS)
- Higher Quality than SOTA Mip-NeRF360(2022)
- Faster Training than SOTA InstantNGP(2022)

## Introduction

#### Why 3D Gaussian?

3D scene representation 방법  
1. `Mesh or Point`  
  - explicit  
  - good for fast GPU/CUDA-based rasterization(3D $$\rightarrow$$ 2D)  
2. `NeRF` method  
  - implicit (MLP)  
  - ray marching  
  - continuous coordinate-based representation  
  - interpolate values stored in voxels, hash grids, or points  
  - But,,, `stochastic sampling` for rendering 때문에 `연산량이 많고 noise` 생김  
3. `3D Gaussian` method  
  - explicit  
  - differentiable volumetric representation  
  - efficient rasterization(projection and $$\alpha$$-blending)  

#### Rendering (NeRF vs 3DGS)

- NeRF :  
  - ray per pixel 쏴서 coarse(stratified) and fine(PDF) sampling하고,  
  - MLP로 sampled points의 color 및 volume density를 구하고,  
  - 이 값들을 volume rendering 식으로 summation  
- 3DGS :  
  - image를 tile(14 $$\times$$ 14 pixel)들로 나누고,  
  - tile마다 Gaussian을 Depth에 따라 정렬한 뒤  
  - 앞에서부터 뒤로 $$\alpha$$-blending

## Related Work

생략 (추후에 다시 볼 수도)

## Overview

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-01-GS/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

For unbounded and complete scenes,  
For 1080p high resolution and real-time($$\geq$$ 30 fps) rendering,  

1. `input` :  
Most point-based methods require `MVS`(Multi-View Stereo) data,  
but 3DGS only needs `SfM points` for initialization  
COLMAP 등 SfM(Structure-from-Motion) camera calibration으로 얻은 `sparse point cloud`에서 시작해서 scene을 3D Gaussians로 나타냄으로써 `empty space에서의 불필요한 계산을 하지 않도록` continuous volumetric radiance fields 정보를 저장  
NeRF-synthetic dataset의 경우 3DGS 는 random initialization으로도 좋은 퀄리티 달성  

2. `optimization` interleaved with `adaptive density control` :  
  - optimize 4 parameters : 3D position(mean), anisotropic covariance, opacity, and spherical harmonic coeff.(color)  
  `highly anisotropic volumetric splats`는 `fine structures`를 compact하게 나타낼 수 있음!!  
  `spherical harmonics`를 통해 `directional appearance(color)`를 잘 나타낼 수 있음!!<d-cite key="Plenoxels">[1]</d-cite><d-cite key="InstantNGP">[2]</d-cite>  
  - adaptive density control : gradient 기반으로 Gaussian 형태를 변화시키기 위해, add and occasionally remove 3D Gaussians during optimization  

3. differentiable visibility-aware `real-time rendering` :  
perform $$\alpha$$-blending of `anisotropic splats` respecting visibility order  
by fast `GPU sorting` algorithm and `tile-based rasterization`(projection and $$\alpha$$-blending)  
한편, accumulated $$\alpha$$ values를 tracking함으로써 `Gaussians 수에 제약 없이` 빠른 backward pass도 가능  

#### Pseudo-Code

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-01-GS/3.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

빨간 박스 : initialization  
파란 박스 : optimization  
초록 박스 : 특정 iter.마다 Gaussian을 clone, split, remove  

## Differentiable 3D Gaussian Splatting

#### 3D Gaussian

- `differentiable` volumetric representation의 특성을 가지고 있으면서도 빠른 rendering을 위해 `unstructured and explicit`한 게 무엇이 있을까?  
$$\rightarrow$$ 3D Gaussian !!  

- a point를 a small planar circle with a normal이라고 가정하는 이전 Point-based rendering 논문들 <d-cite key="Point1">[3]</d-cite> <d-cite key="Point2">[4]</d-cite> 과 달리  
`SfM points는 sparse해서 normals(법선)를 estimate하기 어려울` 뿐만 아니라, estimate 한다 해도 very noisy normals를 optimize하는 것은 매우 어렵  
$$\rightarrow$$ normals 필요 없는 3D Gaussians !!  
$$G(x) = e^{-\frac{1}{2}(x)^T\Sigma^{-1}(x)}$$  

## Parameters to train

1. `scale vector` $$s$$ and `quaternion` $$q$$ for `covariance matrix`
2. `spherical harmonics`(SH) coeff. for `color`
3. `opacity` $$\alpha$$
4. `3D position` for `mean`

#### Covariance matrix

> covariance matrix and scale vector(scale) and quaternion(rotation)  

- covariance matrix는 positive semi-definite $$x^T M x \geq 0$$ for all $$x \in R^n$$이어야만 physical meaning을 가지는데,  
$$\Sigma$$ 를 직접 바로 optimize하면 invalid covariance matrix가 될 수 있음  
그렇다면!!  
$$\Sigma$$ 가 `positive semi-definite`이도록 $$\Sigma = R S S^T R^T$$ 로 정의해서  
$$\Sigma$$ 대신 `x,y,z-axis scale`을 나타내는 `3D vector` $$s$$ 와 `rotation`을 나타내는 4 $$\times$$ 1 `quaternion` $$q$$ 를 optimize 하자!!  
quaternion에 대한 설명은 [Quaternion](https://semyeong-yu.github.io/blog/2024/) 링크 참고!!  

- `scale` matrix $$S$$ `초기값` : [GaussianModel().create_from_pcd()](https://github.com/graphdeco-inria/gaussian-splatting/blob/b2ada78a779ba0455dfdc2b718bdf1726b05a1b6/scene/gaussian_model.py#L134C1-L134C1)  
SfM sparse point cloud의 각 점에 대해 가장 가까운 점 3개까지의 거리의 평균을 각 axis별로 구한 것을 3 $$\times$$ 1 $$d$$라 할 때  
3 $$\times$$ 1 $$log(\sqrt{d})$$ 의 값을 복사하여 3 $$\times$$ 3 matrix $$S$$를 초기화  
```Python
dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)
scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3)
```

- `rotation` matrix $$R$$ `초기값` :  
각 점에 대해 $$\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix}$$ 으로 초기화  
```Python
rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")
rots[:, 0] = 1
```

- `anisotropic covariance`는 다양한 모양의 geometry를 나타내기 위해 optimize하기에 적합!  

> param. gradient 직접 유도  

training할 때 automatic differentiation으로 인한 overhead를 방지하기 위해 param. gradient를 직접 유도함!  

Appendix A. `?????`  

> Project 3D Gaussians to 2D  

- `world coordinate` :  
$$\Sigma$$ : 3 $$\times$$ 3 covariance matrix of 3D Gaussian  

- `image coordiante` :  
$$\Sigma^{\ast} = J W \Sigma W^T J^T$$ : covariance matrix of 2D splat  
where  
$$W$$ : `viewing transformation` matrix from world coordinate to camera coordinate  
$$J$$ : `Jacobian` matrix of the affine `approximation` of the `projective transformation` from camera coordinate to image coordinate  

`?????`

#### Spherical Harmonics(SH) coeff.

#### opacity

#### 3D position(mean)


## Optimization with Adaptive Density Control of 3D Gaussians

#### Optimization

#### Adaptive Control of Gaussians

## Fast Differentiable Rasterizer for Gaussians

## Results

## Discussion

