---
layout: distill
title: Deblurring 3D Gaussian Splatting
date: 2024-10-30 12:00:00
description: ECCV 2024
tags: 3DGS deblur
categories: 3d-view-synthesis
thumbnail: assets/img/2024-10-30-DeblurGS/1.png
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Introduction
  - name: Related Works
  - name: Defocus Blur
  - name: Camera motion Blur
  - name: Compensation for Sparse Point Cloud
  - name: Experiment
  - name: Limitation and Future Work
  - name: Code Review

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Deblurring 3D Gaussian Splatting (ECCV 2024)

#### Byeonghyeon Lee, Howoong Lee, Xiangyu Sun, Usman Ali, Eunbyung Park

> paper :  
[https://arxiv.org/abs/2401.00834](https://arxiv.org/abs/2401.00834)  
project website :  
[https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/](https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/)  
code :  
[https://github.com/benhenryL/Deblurring-3D-Gaussian-Splatting](https://github.com/benhenryL/Deblurring-3D-Gaussian-Splatting)  

### Introduction

- 3DGS :  
  - novel-view로 inference할 때  
  NeRF는 새로운 각도를 MLP에 넣어야만 color, opacity 얻을 수 있지만  
  3DGS는 spherical harmonics, explicit 기법이라 바로 color, opacity 얻을 수 있어서  
  volume rendering이 빠름
  - differentiable splatting-based rasterization with parallelism

- 본 논문 :  
  - 핵심 :  
  각 3DGS의 `covariance`를 수정하여 `blur(adjacent pixels의 혼합)를 모델링하는 작은 MLP` 사용  
  - 원리 :  
  training 시에는 blur를 학습하는 MLP를 사용하여 원래 값에 곱하지만  
  inference 시에는 MLP를 사용하지 않아서 real-time으로 blurred image에서 sharp detail을 reconstruct 가능
  - initial point cloud :  
  given images가 `blurry`하면 SfM은 유효한 feature를 식별하지 못해서 `매우 적은 수의 point` cloud를 추출함  
  (심지어 depth가 크면 SfM은 맨 끝에 있는 점을 거의 추출하지 않음)  
  $$\rightarrow$$  
  3DGS는 initial point cloud에 많이 의존하므로  
  sparse point cloud를 방지하고자  
  `N-nearest-neighbor interpolation으로 points 추가`  
  또한  
  먼 거리의 평면에 많은 Gaussian을 유지하기 위해  
  `위치에 따라 Gaussian pruning`
  - contribution :  
  SOTA qualtiy인데 훨씬 빠른 rendering speed ($$\gt 200$$ FPS)

### Related Works

TBD  

Related Works :
Deblur-NeRF: Neural Radiance Fields from Blurry Images (CVPR 2022)
DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors (CVPR 2023)

### Background

- 3DGS [Link](https://semyeong-yu.github.io/blog/2024/GS/) 참고

### Defocus Blur

TBD

### Camera motion Blur

### Compensation for Sparse Point Cloud

### Experiment

### Limitation and Future Work

### Code Review