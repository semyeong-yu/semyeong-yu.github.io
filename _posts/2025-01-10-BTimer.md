---
layout: distill
title: Feed-Forward Bullet-Time Reconstruction
date: 2025-01-10 12:00:00
description: Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos (CVPR 2025)
tags: general dynamic GS view synthesis
categories: 3d-view-synthesis
thumbnail: assets/img/2025-01-10-BTimer/1.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
bibliography: 2025-01-10-BTimer.bib
toc:
  - name: Contribution
  - name: Introduction
  - name: Related Works
  - name: Overview
  - name: Method
  subsections:
    - name: BTimer
    - name: NTE Module
    - name: Curriculum Training
  - name: Experiment
  - name: Ablation Study
  - name: Conclusion
  - name: Question

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos

#### Hanxue Liang, Jiawei Ren, Ashkan Mirzaei, Antonio Torralba, Ziwei Liu, Igor Gilitschenski, Sanja Fidler, Cengiz Oztireli, Huan Ling, Zan Gojcic, Jiahui Huang

> paper :  
[https://arxiv.org/abs/2412.03526](https://arxiv.org/abs/2412.03526)  
project website :  
[https://research.nvidia.com/labs/toronto-ai/bullet-timer/](https://research.nvidia.com/labs/toronto-ai/bullet-timer/)  

## Contribution

- `NTE Module` and `BulletTimer` :  
  - `motion-aware` `feed-forward` model for real-time recon. and novel-view-synthesis of `dynamic` scenes  
  - recon. at given target (bullet) timestamp by aggregating info. from all the context frames
  - obtain `scalability` and `generalization` by using both static and dynamic scene datasets
  - recon. a bullet-time scene within 150ms with SOTA performance  
  comparable to optimization-based (per-scene) approaches

## Introduction

- Dynamic scene recon. from monocular video :  
still challenging  
due to inherently ill-posed (해가 무수히 많음) nature of dynamic recon. from limited observations

- Static scene recon. :  
  - optimization-based (per-scene) :  
  NeRF, HyperNeRF
  - learning-based (feed-forward) :  
  MonoNeRF, GS-LRM

- Dynamic scene recon. :  
dynamic scene은 complex motion 때문에 ambiguity 존재  
이를 해소하는 데 도움될 data prior 필요  
  - optimization-based (per-scene) :  
    - use contraint (data prior) like depth and optical flow <d-cite key="33">[1]</d-cite>, <d-cite key="36">[2]</d-cite>, <d-cite key="37">[3]</d-cite>, <d-cite key="68">[4]</d-cite>  
    $$\rightarrow$$  
    given data와 위의 data prior 간의 싱크를 맞추는 게 challenging <d-cite key="34">[5]</d-cite>, <d-cite key="63">[6]</d-cite>  
    - per-scene approach는 time-consuming and thus scale 어렵
  - learning-based (`feed-forward`) :  
    - directly predict recon. in feed-forward manner  
    so, can `learn strong inherent prior directly from data`  
    - 근데 dynamic scene 모델링하기 복잡하고 4D supervision data 부족해서 적용하는데 한계 있었음  
    - 지금 시점 기준 L4GM이 유일한 feed-forward dynamic recon. model인데,  
    synthetic object-centric dataset으로 훈련돼서  
    fixed camera view-point와 multi-view supervision을 필요로 한다는 한계와  
    real-world scene에 generalize하기 어렵다는 한계가 있었음

1 10 12 25 53 TBD

## Related Works

TBD

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-12-23-Quark/2.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Overview

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-12-23-Quark/3.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Method

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-12-23-Quark/4.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## Method

### BTimer

### NTE Module

### Curriculum Training

## Experiment

## Ablation Study

## Conclusion

## Question

- Q1 :  
TBD

- A1 :  
TBD