---
layout: distill
title: DDIM SDS DDS PDS
date: 2025-05-01 12:00:00
description: Basic Generative Model
tags: diffusion DDIM SDS DDS PDS
categories: generative
thumbnail: assets/img/2025-05-01-GenAI/1.PNG
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: DDIM
  - name: CFG
  - name: Latent Diffusion
    subsections:
      - name: ControlNet
  - name: DDIM Inversion
  - name: SDS
  - name: DDS
  - name: PDS
  - name: Inverse Problem
  - name: Flow Matching
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Basic Generative Model

> reference :  
[Blog](https://velog.io/@guts4/Basic-Generative-Model-DDIM-Score-based-CFG1)

## DDIM

- Score Function : data 분포 내 특정 위치에서의 `prob. distribution 변화량`  
$$\nabla_{x_{t}} \text{log} q(x_{t} | x_{0}) = \nabla_{x} (- \frac{\| x_{t} - \sqrt{\bar \alpha_{t}} x_{0} \|^{2}}{2(1 - \bar \alpha_{t})}) = - \frac{x_{t} - \sqrt{\bar \alpha_{t}} x_{0}}{1 - \bar \alpha_{t}} = - \frac{\epsilon_{t}}{\sqrt{1 - \bar \alpha_{t}}}$$  
where noise $$\epsilon_{t} = \frac{1}{\sqrt{1 - \bar \alpha_{t}}}(x_{t} - \sqrt{\bar \alpha_{t}} x_{0})$$
  - 즉, `noise 예측 모델`은 `상수배 취한 score function을 예측하는 모델`과 equivalent!

- `Tweedie's Formula` :  
정규 분포에서 a sample $$x$$ 를 sampling할 때 해당 data의 `true mean 값을 estimate`하는 방법
  - a sample $$x$$ 에, 분산과 score function을 곱한 값을 더함  
  확률 밀도가 높은 방향의 보정적인 값을 더해주기 위함.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-05-01-GenAI/1.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- Langevin dynamics :  
`Score Function을 알고 있다면`, data distribution을 몰랐더라도 Langevin dynamics를 통해 `data distribution을 알아낼 수 있음`  
(Score Function이 중요한 이유!)
  - `initial sample을 점진적으로 업데이트하여 목표 확률 분포에 도달하게` 만드는 iterative process  
  $$x \leftarrow x + \eta \nabla_{x} text{log} q(x) + \sqrt{2 \eta} \epsilon$$  
  where $$\epsilon \sim N(0, I)$$
  - Annealed Langevin dynamics :  
    - 분산 $$\sigma_{t}$$ 가 작으면 high density region에서는 정확한 결과 얻을 수 있지만 low density region에서는 부정확함  
    반대로, 분산 $$\sigma_{t}$$ 가 크면 low density region에서는 어느 정도 성능 낼 수 있지만 high density region에서는 비교적 정확도가 떨어짐
    - 초기에는 큰 분산 $$\sigma_{t}$$ 값을 통해 low density region을 학습하고,  
    이후에 점점 분산 $$\sigma_{t}$$ 값을 줄여 가면서  
    나중에서는 작은 분산 $$\sigma_{t}$$ 값으로 high density region을 학습

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-05-01-GenAI/3.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-05-01-GenAI/4.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- DDIM (Denoising Diffusion Implicit Models) :  
  - Comparison :  
    - GAN : High Quality and Fast Sampling, but Mode Collapse
    - VAE : Fast Smplint and Mode Converge, but Low Quality
    - DDPM : High Quality and Mode Converge, but Slow Sampling
  - Comparison :  
    - DDPM :  
    $$q(x_{t} | x_{t-1})$$ 라는 Markov Chain이 주어지고, 이를 기반으로 $$q(x_{t} | x_{0})$$ 과 $$q(x_{t-1} | x_{t}, x_{0})$$ 계산
    - `DDIM` : non-Markov Chain을 사용하기 위해 (더 빠르게 Sampling하기 위해)  
    $$q(x_{t-1} | x_{t}, x_{0})$$ 을 먼저 정의하고, 이를 기반으로 $$q(x_{t} | x_{0})$$ 과 $$q(x_{t} | x_{t-1})$$ 정의  
    (유도 과정 : [Link](https://velog.io/@guts4/Basic-Generative-Model-DDIM-Score-based-CFG1))
  - DDIM Summary :  
    - DDPM은 DDIM의 special case이다  
    DDIM은 DDPM보다 `평균을 나타내는 수식이 복잡해졌을 뿐`, 두 모델의 Sampling 차이는 없다  
    즉, DDIM은 DDPM보다 `빠르게 Sampling`할 수 있는 거고 `Sampling 결과에는 차이가 없으므로` 다시 학습 시킬 필요가 없다
    - DDPM에서는 고정된 분산 값으로 forward process에서 동작하는데, DDIM에서는 `선택 가능한 분산 값`으로 동작한다  
    이 때, variance = 0 으로 설정할 경우 deterministic하다 (데이터들이 모두 평균에 위치하므로 경로가 정해짐)
    - 적은 수의 step으로도 좋은 결과를 얻을 수 있다

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2025-05-01-GenAI/5.PNG" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

## CFG

- CFG (Classifier-Free Guidance) :  
DDPM or DDIM을 통해 image를 generate하는데,  
원하는 특정 class의 image를 generate하고 싶을 경우 CFG 사용!
  - 핵심 idea : class label $$y$$ 를 condition으로 줘서 noise 예측  
  $$\tilde \epsilon_{\theta} (x_{t}, y, t) = \lambda \hat \epsilon_{\theta} (x_{t}, y, t) + (1 - \lambda) \hat \epsilon_{\theta} (x_{t}, \phi, t)$$  
  (증명 과정 : [Link](https://velog.io/@guts4/Basic-Generative-Model-CFG2-Latent-Diffusion-ControlNet-LoRA))
    - classifier 없이 conditional 정보 학습 가능
    - $$\lambda$$ 값이 클수록 해당 class $$y$$ 에 대한 더 정확한 image가 생성되지만 diversity가 떨어짐 (trade-off)
  - 장단점 :  
    - 장점 :  
      - classifier가 없으므로 추가 학습이 없어 적용하기 쉬움
      - text 뿐만 아니라 image 등 어떠한 정보도 condition으로 들어갈 수 있음  
      e.g. Camera Param.를 condition으로 넣은 Zero-1-to-3
      - GAN의 단점인 Mode Collapse도 없음
    - 단점 :  
      - conditional noise term과 unconditional noise term을 평가해야 해서 시간이 더 걸림
  - Negative Prompt :  
  CFG에서의 Null condition $$\phi$$ 대신  
  만들고 싶지 않은 형태의 text prompt (Negative Prompt)를 넣어주면  
  해당 text prompt와 반대되는 결과가 나옴  
  $$\tilde \epsilon_{\theta} (x_{t}, y, t) = \lambda \hat \epsilon_{\theta} (x_{t}, y_{+}, t) + (1 - \lambda) \hat \epsilon_{\theta} (x_{t}, y_{-}, t)$$  

## Latent Diffusion

### ControlNet

## DDIM Inversion

## SDS

## DDS

## PDS

## Inverse Problem

## Flow Matching