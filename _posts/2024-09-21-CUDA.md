---
layout: distill
title: CUDA Programming
date: 2024-09-21 12:00:00
description: .cu coding
tags: radiance field tensor decomposition
categories: 3d-view-synthesis
thumbnail: assets/img/2024-09-21-CUDA/1.png
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: CUDA Programming
    subsections:
      - name: Introduction to CUDA
      - name: Performance Optimization
      - name: Parallel Algorithm
      - name: GPU Accelerated Libraries
      - name: Advanced CUDA Topics
      - name: Summary
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## CUDA Programming

> reference :  
[How CUDA Programming Works](https://www.youtube.com/watch?v=n6M8R8-PlnE&t=557s)  
[Learning CUDA 10 Programming](https://www.youtube.com/watch?v=ot1wyQCutSA&list=PLTgRMOcmRb3O5Xc8PJckYdbyCr5HPGx4e)  
NeRF and 3DGS Study

### Introduction to CUDA

- API :  
  - Drive API :  
  low-level API (not conveninent)  
  shipped along with display driver
  - Runtime API :  
  high-level API (with nvcc)  
  included with the CUDA toolkit
  - standard CUDA API functions :  
  $$\#$$ include $$<$$ cuda_runtime_api.h $$>$$
  - Driver API ver.이 Runtime API ver.보다 최신꺼여야 함

- Execution Model :  
  - Kernel :  
  executed by N CUDA threads in parallel  
  threads $$\rightarrow$$ blocks $$\rightarrow$$ grid
  - Hardware Architecture :  
  스펙은 CUDA Capability version number로 확인 가능
    - Streaming multiprocessors (SMs) :  
    각 GPU 당 여러 SMs (global memory 공유)  
    각 SM 당 여러 CUDA cores (cache, registers 공유)  
    예측 (branch prediction 또는 speculative execution) 없음
    - SIMT architecture (Single-Instruction-Multiple-Thread) :  
    - warp :  
    32 threads를 그룹지어서 scheduling한 걸 하나의 unit으로 run  
    warp에 필요한 execution context는 lifetime 내내 SM에 있기 때문에 switching warps 위한 overhead 없어서 좋음
    - running a Kernel :  
    available SM에 blocks 할당  
    $$\rightarrow$$ block을 warps로 split  
    $$\rightarrow$$ SM 당 multiple warps on block 실행  
    $$\rightarrow$$ block 실행이 끝나면 SM을 free시키고 new block을 scheduling until entire grid is done 

### Performance Optimization

- NVIDIA Visual Profiler in CUDA toolkit :  
Hardware performance counters on GPU (admin user [Link](https://developer.nvidia.com/nvidia-development-tools-solutions-err_nvgpuctrperm-permission-issue-performance-counters) 자격 있어야 접근 가능) 이용해서  
device code와 CUDA API calls를 추적  

### Parallel Algorithm

### GPU Accelerated Libraries

### Advanced CUDA Topics

### Summary

