---
layout: distill
title: 4D Gaussian Splatting
date: 2024-09-14 12:00:00
description: 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering (CVPR 2024)
tags: GS 4d dynamic rendering
categories: 3d-view-synthesis
thumbnail: assets/img/2024-09-14-4DGS/1.png
bibliography: 2024-09-14-4DGS.bib
giscus_comments: false
disqus_comments: true
related_posts: true
toc:
  - name: Abstract
  - name: Contribution
  - name: Related Works
    subsections:
      - name: Novel View Synthesis
      - name: Neural Rendering w. Point Clouds
      - name: Dynamic NeRF with Deformation Fields
  - name: Method
    subsections:
      - name: Overview (Gaussian Deformation Field Network)
      - name: Spatial-Temporal Structure Encoder
      - name: Extremely Tiny Multi-head Gaussian Deformation Decoder
      - name: Optimization
  - name: Experiment
    subsections:
      - name: Dataset
      - name: Results
      - name: Ablation Study
  - name: Discussion
    subsections:
      - name: Discussion
      - name: Limitation
      - name: Conclusion
  - name: Code Flow
  - name: Question
# toc:
#   beginning: true
#   sidebar: right
# featured: true
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering

#### Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Qi Tian, Xinggang Wang

> paper :  
[https://arxiv.org/abs/2310.08528](https://arxiv.org/abs/2310.08528)  
project website :  
[https://guanjunwu.github.io/4dgs/index.html](https://guanjunwu.github.io/4dgs/index.html)  
code :  
[https://github.com/hustvl/4DGaussians](https://github.com/hustvl/4DGaussians)  

## Abstract

- spatially-temporally-sparse input으로부터  
complex point motion을 정확하게 모델링하면서  
high efficiency로 real-time dynamic scene을 rendering하는 건 매우 challenging task  

- 3DGS를 각 frame에 적용하는 게 아니라 4DGS라는 새로운 모델 제시  
  - `오직 3DGS 한 세트` 필요
  - 4DGS framework :  
    - HexPlane <d-cite key="neuralvoxel1">[Link]</d-cite> 에서 영감을 받아  
    `decomposed neural voxel encoding algorithm`을 이용해서  
    4D neural voxel로부터 `Gaussian features`를 얻음  
    - `가벼운 MLP`를 이용해서  
    `Gaussian deformation`을 예측함

- 4DGS :  
real-time (82 FPS) rendering at high (800 $$\times$$ 800) resolution on RTX 3090 GPU

## Contribution

- Gaussian `motion`과 `shape`-deformation을 모두 모델링할 수 있는 4DGS framework 제시  
w. efficient Gaussian deformation field

- `multi-resolution` encoding  
(connect nearby 3D Gaussians to build rich Gaussian features)  
by efficient spatial-temporal structure encoder

- SOTA `performance`이면서 `real-time` rendering on `dynamic` scenes  
e.g. 82 FPS at resol. 800 $$\times$$ 800 for synthetic dataset  
e.g. 30 FPS at resol. 1352 $$\times$$ 1014 for real dataset  

- 4D scenes에서의 editing 및 tracking에 활용 가능

## Related Works

### Novel View Synthesis

- static scene :  
  - light fields <d-cite key="lightfield">[1]</d-cite>, mesh <d-cite key="mesh1">[2]</d-cite> <d-cite key="mesh2">[3]</d-cite> <d-cite key="mesh3">[4]</d-cite> <d-cite key="mesh4">[5]</d-cite>, voxels <d-cite key="voxel1">[6]</d-cite> <d-cite key="voxel2">[7]</d-cite> <d-cite key="voxel3">[8]</d-cite>, multi-planes <d-cite key="multiplane">[9]</d-cite> 이용한 methods
  - NeRF-based methods [NeRF](https://semyeong-yu.github.io/blog/2024/NeRF/) [MipNeRF](https://semyeong-yu.github.io/blog/2024/MipNeRF/) <d-cite key="nerf++">[10]</d-cite>

- dynamic scene :  
  - NeRF-based methods <d-cite key="dynerf1">[11]</d-cite> <d-cite key="dynerf2">[12]</d-cite> <d-cite key="dynerf3">[13]</d-cite>
  - `explicit voxel grid` <d-cite key="voxeltemp1">[14]</d-cite> <d-cite key="voxeltemp2">[15]</d-cite> <d-cite key="voxeltemp3">[16]</d-cite> <d-cite key="voxeltemp4">[17]</d-cite> :  
  temporal info. 모델링하기 위해 explicit voxel grid 사용  
  - `flow-based` methods <d-cite key="flow1">[18]</d-cite> <d-cite key="flow2">[19]</d-cite> <d-cite key="voxeltemp3">[16]</d-cite> <d-cite key="flow3">[20]</d-cite> <d-cite key="flow4">[21]</d-cite> :  
  nearby frames를 blending하는 warping algorithm 사용
  - `decomposed neural voxels` <d-cite key="neuralvoxel1">[22]</d-cite> <d-cite key="neuralvoxel2">[23]</d-cite> <d-cite key="neuralvoxel3">[24]</d-cite> <d-cite key="neuralvoxel4">[25]</d-cite> <d-cite key="neuralvoxel5">[26]</d-cite> <d-cite key="neuralvoxel6">[27]</d-cite> :  
  빠른 training on dynamic scenes 가능  
  (밑의 그림의 (b))
  - `multi-view` setups 다루기 위한 methods <d-cite key="multi1">[28]</d-cite> <d-cite key="multi2">[29]</d-cite> <d-cite key="multi3">[30]</d-cite> <d-cite key="multi4">[31]</d-cite> <d-cite key="multi5">[32]</d-cite> <d-cite key="multi6">[33]</d-cite>
  - 본 논문 (4DGS) :  
  위에서 언급된 methods는 빠른 training은 가능했지만 real-time rendering on dynamic scenes는 여전히 어려웠음  
  $$\rightarrow$$  
  본 논문은 빠른 training 및 rendering pipeline 제시  
  (밑의 그림의 (c))

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-09-14-4DGS/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    dynamic scene rendering methods
</div>

- 위의 그림 설명 :  
dynamic scene을 rendering하는 여러 방법들 소개  
  - (a) : Deformation-based (Canonical Mapping) Volume Rendering  
  point-deformation-field를 이용해서  
  sampled points를 canonical space로 mapping
  - (b) : Time-aware Volume Rendering  
  각 timestamp에서의 각 point의 feature를 직접 개별적으로 계산  
  (path는 그대로)
  - (c) : 4DGS  
  `Gaussian-deformation-field`를 이용해서  
  기존의 3D Gaussians를 특정 timestamp의 3D Gaussians로 변환

### Neural Rendering w. Point Clouds

- 3D scenes를 나타내기 위해 meshes, point-clouds, voxels, hybrid ver. 등 여러 분야가 연구되어 왔는데  
그 중 point-cloud representation을 volume rendering과 결합하면  
dynamic novel view synthesis task도 잘 수행 가능

- 3DGS :  
`explicit` representation이라서, `differentiable` `point`-based splatting이라서, `real-time` renderer라서 주목받음  
  - Dynamic3DGS <d-cite key="dyna3DGS">[34]</d-cite> :  
  TBD

### Dynamic NeRF with Deformation Fields

## Method

### Overview (Gaussian Deformation Field Network)

### Spatial-Temporal Structure Encoder

- 각 Gaussian을 따로 변형시키는 게 아니라,  
여러 adjacent 3D Gaussians를 연결지어서 변형시킴으로써  
motion과 shape-deformation을 정확하게 예측

### Extremely Tiny Multi-head Gaussian Deformation Decoder



### Optimization

## Experiment

### Dataset

### Results

### Ablation Study

## Discussion

### Discussion

### Limitation

### Conclusion

## Code Flow

## Question