---
layout: distill
title: Normalized Device Coordinates
date: 2024-07-30 15:00:00
description: How NDC Works for Ray
tags: NDC 3d
categories: 3d-view-synthesis
thumbnail: assets/img/2024-07-30-NDC/1.png
giscus_comments: true
related_posts: true
# toc:
#   beginning: true
#   sidebar: right
# featured: true
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## NDC: Normalized Device Coordinates

> referenced blog :  
[https://yconquesty.github.io/blog/ml/nerf/nerf_ndc.html#background](https://yconquesty.github.io/blog/ml/nerf/nerf_ndc.html#background)

### Motivation

LLFF (Local Light Field Fusion) dataset 에 있는 scene 정보는 NDC space로 project되어야 한다  
NDC space로의 projection 과정을 수식적으로 알아보고자 한다.  

### From world-coordinate To NDC To pixel-coordinate

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-30-NDC/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

- camera transformation :  
  - `3D world-coordinate` (canonical-coordinate)  
  $$\rightarrow$$  
  `3D camera-coordinate`  
  - extrinsic matrix $$\begin{bmatrix} R & t \\ 0 & 1 \end{bmatrix}$$  

- projection transformation :  
  - `3D camera-coordinate`  
  $$\rightarrow$$  
  `2D image-coordinate` (= canonical view volume = `normalized-device-coordinate (NDC)`)  
  - normalized-device-coordinate (NDC) :  
  camera 원점이 중앙에 있는 $$[-1, 1]^3$$ cube  
  - depth Z 로 나누기

- viewport transformation :  
  - `2D image-coordinate`  
  $$\rightarrow$$  
  `2D pixel-coordinate`  
  - $$[-1, 1]^3$$ 의 NDC를 flatten하여 2 $$\times$$ 2 square를 raster image로 mapping `?????`  
  - 초점거리 곱하고 원점 이동  

### Transformation in NeRF

NeRF에서는  
MLP의 input이 3D world-coordinate에서의 3D 좌표이고,  
MLP의 output인 $$c, \sigma$$ 를 accumulate해서 2D pixel-coordinate에서의 2D 좌표를 얻어내므로  
NeRF는 camera transformation과 viewport transformation이 필요 없다 `?????`  
NeRF는 LLFF dataset의 3D world-coordinate에서 NDC로 `projection transformation`만 하면 된다!!

### Projection Transformation

Step 1. `Perspection Projection`  
frustum을 bounded cuboid로 변환  

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2024-07-30-NDC/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

Step 2. `Orthographic Projection`  
ddd

